{
    "docs": [
        {
            "location": "/",
            "text": "Essential skills for reproducible research computing\n\n\nA five-day, intensive, hands-on workshop on the foundational skills that everyone using computers in the pursuit of scientific research should have.\n\n\nOffered for the first time 2\u20136 January 2017, at Universidad T\u00e9cnica Federico Santa Mar\u00eda, Valpara\u00edso, Chile.\n\n\n\n\nEvery student today (graduate or undergraduate) is using computers on a daily basis.\nBut to be proficient with computers as a tool for science, you need professional-grade skills.\nThis workshop teaches the computing skills that we\u2014as a research group in computational science and engineering\u2014think everyone should have.\n\n\nIn recent years, the concern for reproducibility in computational science has gained traction.\nOur research group has been pushing for several years the adoption of better standards for reproducible research.\nThese standards include treating scientific software as a core intellectual product, adding automation to our data handling and analysis, and the open sharing of our digital objects.\n\n\nThis course provides an introduction to the tools and techniques that we consider fundamental for responsible use of computers in scientific research. They include the following:\n\n\n\n\ncommand line utilities in Unix/Linux \n\n\nan open-source scientific software ecosystem (our favorite is Python's)\n\n\nsoftware version control (we advocate the distributed kind: our favorite is git)\n\n\ngood practices for scientific software development: code hygiene and testing\n\n\nknowledge of licensing options for sharing software \n\n\n\n\nReproducible Computational Research\n\n\nThe weeklong workshop also includes a presentation and discussion of the \n\"Barba-group Reproducibility Syllabus\"\n\u2014an annotated bibliography of our Top-10 readings on the topic of reproducibility.\nNumber 7 in the list of readings is an article titled \"Ten simple rules for reproducible research\" (Sandve et al., 2013).\nTwo unifying ideas run through the \"ten simple rules\":\n(1) that automation is a key device for reproducibility, and\n(2) that version control is the core technology for dealing with software as a living, changing thing.\nThese ideas justify insisting that \ncommand-line skills are a must.\n\n\nThe skeleton for our practice of reproducible research is the pledge \n\"Reproducibility PI Manifesto\"\n (2012).\nIt consists of a commitment to:\n(1) teach group members about reproducibility; \n(2) keep all code and writing under version-control; \n(3) complete code verification and validation, and publish openly the results; \n(4) for main results in a publication, share data, plotting scripts, and figures under CC-BY; \n(5) upload preprints to \narXiv\n at the time of submission of a paper; \n(6) release code no later than the time of submission of a paper; \n(7) add a \"Reproducibility\" statement to each publication; \n(8) keep an up-to-date web presence.\n\n\nWith this workshop, we propel the first commitment beyond our research group: \nwe take responsibility for not only teaching our group members, but broadly disseminating the know-how to our community. \nThe second commitment helps for what University of Washington professor Randall LeVeque\n1\n called \n\"private reproducibility\"\n: \nwe can rebuild our own past research results from the precise version of the code that was used to create them.\nPrivate reproducibility also demands fully automating the analysis and visualization of data.\nStanford professor Jon Claerbout\n2\n said:\n\n\u201cI\u2019ve learned that interactive programs are slavery (unless they include the ability to arrive in any previous state by means of a script).\u201d\n\nWith this in mind, two technologies are enemies of reproducible research:\nGUI-based image manipulation, and spreadsheets.\nFigures that visualize data, or image processing applied to photographs, can only be reproducible if made with scripts.\nAnd spreadsheets impair reproducibility because they conflate input, output, code and presentation\u2014as noted by Berkeley professor Philip Stark.\n3\n\nThis situation calls for adopting a scientific software stack for programmatic analysis and visualization.\nOur favorite environment to accomplish this is Scientific Python.\n\n\nGenuine reproducible research is not only privately reproducible, but publicly so.\nThat's why all our subsequent reproducibility commitments deal with open access to data, code and publications.\nThe American Physical Society issued a policy statement under the Ethics and Values category, titled \n\"What is Science?\"\n (1999). \nIt reads:\n\n\"The success and credibility of science are anchored in the willingness of scientists to [\u2026] Expose their ideas and results to independent testing and replication by others. This requires the open exchange of data, procedures and materials.\"\n\nIn computational research, we and many others maintain that this tenet calls for open-source software, and open data.\n\n\nOpen-source software and open data\n\n\nThe Yale Law School Roundtable on Data and Code Sharing\n4\n (November 2009) made an unambiguous statement urging for more transparency in computational sciences. \nTheir recommendations include: assigning a unique identifier to every version of the data and code, describing within each publication the computing environment used, using open licenses and non-proprietary formats, and publishing under open-access conditions (or posting pre-prints).\n\n\nSubscribing to the recommendations of the Yale roundtable means we need to learn about software licensing and data management.\nThis workshop will present and discuss the essential material and tools that open scientists need command of.\n\n\nDefinitions\n\n\nReproducible research:\n  Authors provide all the necessary data and the computer codes to run the analysis again, re-creating the results.\n\n\nReplication:\n Arriving at the same scientific findings as another study, collecting new data (possibly with different methods) and completing new analyses. A full replication study is sometimes impossible to do, but reproducible research is only limited by the time and effort we are willing to invest.\n\n\nReferences\n\n\n1\n LeVeque, Randall J. (2012), \"Issues in Reproducibility,\" talk given at the ICERM Workshop on Reproducibility in Computational and Experimental Mathematics, Brown University; \nslides PDF\n.\n\n\n2\n Claerbout, Jon; cited in Fomel, S. and Claerbout, J.F. (2009), Guest Editors' Introduction: Reproducible Research, \nComputing in Science and Engineering\n, Vol. 11(1):5\u20137, \ndoi:10.1109/MCSE.2009.14\n\n\n3\n Stark, Philip B. (2016), \"A noob's guide to reproducibility and open science,\" talk given at the Nuclear Engineering/BIDS/BITSS joint seminar, UC Berkeley, 25 January 2016; \nslides HTML\n and \ntalk video\n.\n\n\n4\n CiSE Reproducible Research By the Yale Law School Roundtable on Data and Code Sharing, \nComputing in Science and Engineering\n, Vol. 12(5): 8\u201313 (Sept.-Oct. 2010), \ndoi:10.1109/mcse.2010.113",
            "title": "Home"
        },
        {
            "location": "/#essential-skills-for-reproducible-research-computing",
            "text": "A five-day, intensive, hands-on workshop on the foundational skills that everyone using computers in the pursuit of scientific research should have.  Offered for the first time 2\u20136 January 2017, at Universidad T\u00e9cnica Federico Santa Mar\u00eda, Valpara\u00edso, Chile.   Every student today (graduate or undergraduate) is using computers on a daily basis.\nBut to be proficient with computers as a tool for science, you need professional-grade skills.\nThis workshop teaches the computing skills that we\u2014as a research group in computational science and engineering\u2014think everyone should have.  In recent years, the concern for reproducibility in computational science has gained traction.\nOur research group has been pushing for several years the adoption of better standards for reproducible research.\nThese standards include treating scientific software as a core intellectual product, adding automation to our data handling and analysis, and the open sharing of our digital objects.  This course provides an introduction to the tools and techniques that we consider fundamental for responsible use of computers in scientific research. They include the following:   command line utilities in Unix/Linux   an open-source scientific software ecosystem (our favorite is Python's)  software version control (we advocate the distributed kind: our favorite is git)  good practices for scientific software development: code hygiene and testing  knowledge of licensing options for sharing software",
            "title": "Essential skills for reproducible research computing"
        },
        {
            "location": "/#reproducible-computational-research",
            "text": "The weeklong workshop also includes a presentation and discussion of the  \"Barba-group Reproducibility Syllabus\" \u2014an annotated bibliography of our Top-10 readings on the topic of reproducibility.\nNumber 7 in the list of readings is an article titled \"Ten simple rules for reproducible research\" (Sandve et al., 2013).\nTwo unifying ideas run through the \"ten simple rules\":\n(1) that automation is a key device for reproducibility, and\n(2) that version control is the core technology for dealing with software as a living, changing thing.\nThese ideas justify insisting that  command-line skills are a must.  The skeleton for our practice of reproducible research is the pledge  \"Reproducibility PI Manifesto\"  (2012).\nIt consists of a commitment to:\n(1) teach group members about reproducibility; \n(2) keep all code and writing under version-control; \n(3) complete code verification and validation, and publish openly the results; \n(4) for main results in a publication, share data, plotting scripts, and figures under CC-BY; \n(5) upload preprints to  arXiv  at the time of submission of a paper; \n(6) release code no later than the time of submission of a paper; \n(7) add a \"Reproducibility\" statement to each publication; \n(8) keep an up-to-date web presence.  With this workshop, we propel the first commitment beyond our research group: \nwe take responsibility for not only teaching our group members, but broadly disseminating the know-how to our community. \nThe second commitment helps for what University of Washington professor Randall LeVeque 1  called  \"private reproducibility\" : \nwe can rebuild our own past research results from the precise version of the code that was used to create them.\nPrivate reproducibility also demands fully automating the analysis and visualization of data.\nStanford professor Jon Claerbout 2  said: \u201cI\u2019ve learned that interactive programs are slavery (unless they include the ability to arrive in any previous state by means of a script).\u201d \nWith this in mind, two technologies are enemies of reproducible research:\nGUI-based image manipulation, and spreadsheets.\nFigures that visualize data, or image processing applied to photographs, can only be reproducible if made with scripts.\nAnd spreadsheets impair reproducibility because they conflate input, output, code and presentation\u2014as noted by Berkeley professor Philip Stark. 3 \nThis situation calls for adopting a scientific software stack for programmatic analysis and visualization.\nOur favorite environment to accomplish this is Scientific Python.  Genuine reproducible research is not only privately reproducible, but publicly so.\nThat's why all our subsequent reproducibility commitments deal with open access to data, code and publications.\nThe American Physical Society issued a policy statement under the Ethics and Values category, titled  \"What is Science?\"  (1999). \nIt reads: \"The success and credibility of science are anchored in the willingness of scientists to [\u2026] Expose their ideas and results to independent testing and replication by others. This requires the open exchange of data, procedures and materials.\" \nIn computational research, we and many others maintain that this tenet calls for open-source software, and open data.",
            "title": "Reproducible Computational Research"
        },
        {
            "location": "/#open-source-software-and-open-data",
            "text": "The Yale Law School Roundtable on Data and Code Sharing 4  (November 2009) made an unambiguous statement urging for more transparency in computational sciences. \nTheir recommendations include: assigning a unique identifier to every version of the data and code, describing within each publication the computing environment used, using open licenses and non-proprietary formats, and publishing under open-access conditions (or posting pre-prints).  Subscribing to the recommendations of the Yale roundtable means we need to learn about software licensing and data management.\nThis workshop will present and discuss the essential material and tools that open scientists need command of.",
            "title": "Open-source software and open data"
        },
        {
            "location": "/#definitions",
            "text": "Reproducible research:   Authors provide all the necessary data and the computer codes to run the analysis again, re-creating the results.  Replication:  Arriving at the same scientific findings as another study, collecting new data (possibly with different methods) and completing new analyses. A full replication study is sometimes impossible to do, but reproducible research is only limited by the time and effort we are willing to invest.",
            "title": "Definitions"
        },
        {
            "location": "/#references",
            "text": "1  LeVeque, Randall J. (2012), \"Issues in Reproducibility,\" talk given at the ICERM Workshop on Reproducibility in Computational and Experimental Mathematics, Brown University;  slides PDF .  2  Claerbout, Jon; cited in Fomel, S. and Claerbout, J.F. (2009), Guest Editors' Introduction: Reproducible Research,  Computing in Science and Engineering , Vol. 11(1):5\u20137,  doi:10.1109/MCSE.2009.14  3  Stark, Philip B. (2016), \"A noob's guide to reproducibility and open science,\" talk given at the Nuclear Engineering/BIDS/BITSS joint seminar, UC Berkeley, 25 January 2016;  slides HTML  and  talk video .  4  CiSE Reproducible Research By the Yale Law School Roundtable on Data and Code Sharing,  Computing in Science and Engineering , Vol. 12(5): 8\u201313 (Sept.-Oct. 2010),  doi:10.1109/mcse.2010.113",
            "title": "References"
        },
        {
            "location": "/nix/navigation/",
            "text": "Navigating the Command Line\n\n\nWelcome!\n\n\nThe command line can be a little intimidating at first, but it is a powerful and\nefficient way of interacting with your computer. It's also the lingua franca\nwhen dealing with computing clusters and remote machines.\n\n\nwhoami\n\n\nBefore we do anything else, let's figure out who we are. We can ask on the\ncommand line:\n\n\n$ whoami\n\n\n\n\ngil\n\n\n\n\nThat's my username!\n\n\npwd\n\n\nNow that we know who we are, time to figure out \nwhere\n we are.  To do that, we ask the terminal to \nprint working directory\n or \npwd\n\n\n$ pwd\n\n\n\n\n/home/gil/\n\n\n\n\nWe're in the \"home directory\" for our user. To understand the \"home directory\",\nlet's take a brief moment to look at how the file system is organized.\n\n\nInverted tree diagram a la software carpentry\n\n\nls\n\n\nLet's look around\n\n\n$ ls\n\n\n\n\nDesktop  Documents  Downloads  Music  Pictures  Public  Templates  Videos\n\n\n\n\nI think those are folders?  How can we tell? Use the \n-F\n flag\n\n\n$ ls -F\n\n\n\n\nDesktop/  Documents/  Downloads/  Music/  Pictures/  Public/  Templates/  Videos/\n\n\n\n\nThey all have a trailing slash, so they're all folders.\nWhat other options does \nls\n have?\n\n\n$ ls --help\n\n\n\n\nUsage: ls [OPTION]... [FILE]...\nList information about the FILEs (the current directory by default).\nSort entries alphabetically if none of -cftuvSUX nor --sort is specified.\n\nMandatory arguments to long options are mandatory for short options too.\n  -a, --all                  do not ignore entries starting with .\n  -A, --almost-all           do not list implied . and ..\n      --author               with -l, print the author of each file\n  -b, --escape               print C-style escapes for nongraphic characters\n      --block-size=SIZE      scale sizes by SIZE before printing them; e.g.,\n                               '--block-size=M' prints sizes in units of\n                               1,048,576 bytes; see SIZE format below\n  -B, --ignore-backups       do not list implied entries ending with ~\n  -c                         with -lt: sort by, and show, ctime (time of last\n                               modification of file status information);\n                               with -l: show ctime and sort by name;\n                               otherwise: sort by ctime, newest first\n  -C                         list entries by columns\n      --color[=WHEN]         colorize the output; WHEN can be 'always' (default\n                               if omitted), 'auto', or 'never'; more info below\n  -d, --directory            list directories themselves, not their contents\n  -D, --dired                generate output designed for Emacs' dired mode\n  -f                         do not sort, enable -aU, disable -ls --color\n  -F, --classify             append indicator (one of */=>@|) to entries\n      --file-type            likewise, except do not append '*'\n      --format=WORD          across -x, commas -m, horizontal -x, long -l,\n                               single-column -1, verbose -l, vertical -C\n      --full-time            like -l --time-style=full-iso\n  -g                         like -l, but do not list owner\n      --group-directories-first\n                             group directories before files;\n                               can be augmented with a --sort option, but any\n                               use of --sort=none (-U) disables grouping\n  -G, --no-group             in a long listing, don't print group names\n  -h, --human-readable       with -l and/or -s, print human readable sizes\n     recommonmark                          (e.g., 1K 234M 2G)\n      --si                   likewise, but use powers of 1000 not 1024\n  -H, --dereference-command-line\n                             follow symbolic links listed on the command line\n      --dereference-command-line-symlink-to-dir\n                             follow each command line symbolic link\n                               that points to a directory\n      --hide=PATTERN         do not list implied entries matching shell PATTERN\n                               (overridden by -a or -A)\n      --indicator-style=WORD  append indicator with style WORD to entry names:\n                               none (default), slash (-p),\n                               file-type (--file-type), classify (-F)\n  -i, --inode                print the index number of each file\n  -I, --ignore=PATTERN       do not list implied entries matching shell PATTERN\n  -k, --kibibytes            default to 1024-byte blocks for disk usage\n  -l                         use a long listing format\n  -L, --dereference          when showing file information for a symbolic\n                               link, show information for the file the link\n                               references rather than for the link itself\n  -m                         fill width with a comma separated list of entries\n  -n, --numeric-uid-gid      like -l, but list numeric user and group IDs\n  -N, --literal              print raw entry names (don't treat e.g. control\n                               characters specially)\n  -o                         like -l, but do not list group information\n  -p, --indicator-style=slash\n                             append / indicator to directories\n  -q, --hide-control-chars   print ? instead of nongraphic characters\n      --show-control-chars   show nongraphic characters as-is (the default,\n                               unless program is 'ls' and output is a terminal)\n  -Q, --quote-name           enclose entry names in double quotes\n      --quoting-style=WORD   use quoting style WORD for entry names:\n                               literal, locale, shell, shell-always,\n                               shell-escape, shell-escape-always, c, escape\n  -r, --reverse              reverse order while sorting\n  -R, --recursive            list subdirectories recursively\n  -s, --size                 print the allocated size of each file, in blocks\n  -S                         sort by file size, largest first\n      --sort=WORD            sort by WORD instead of name: none (-U), size (-S),\n                               time (-t), version (-v), extension (-X)\n      --time=WORD            with -l, show time as WORD instead of default\n                               modification time: atime or access or use (-u);\n                               ctime or status (-c); also use specified time\n                               as sort key if --sort=time (newest first)\n      --time-style=STYLE     with -l, show times using style STYLE:\n                               full-iso, long-iso, iso, locale, or +FORMAT;\n                               FORMAT is interpreted like in 'date'; if FORMAT\n                               is FORMAT1<newline>FORMAT2, then FORMAT1 applies\n                               to non-recent files and FORMAT2 to recent files;\n                               if STYLE is prefixed with 'posix-', STYLE\n                               takes effect only outside the POSIX locale\n  -t                         sort by modification time, newest first\n  -T, --tabsize=COLS         assume tab stops at each COLS instead of 8\n  -u                         with -lt: sort by, and show, access time;\n                               with -l: show access time and sort by name;\n                               otherwise: sort by access time, newest first\n  -U                         do not sort; list entries in directory order\n  -v                         natural sort of (version) numbers within text\n  -w, --width=COLS           set output width to COLS.  0 means no limit\n  -x                         list entries by lines instead of by columns\n  -X                         sort alphabetically by entry extension\n  -Z, --context              print any security context of each file\n  -1                         list one file per line.  Avoid '\\n' with -q or -b\n      --help     display this help and exit\n      --version  output version information and exit\n\nThe SIZE argument is an integer and optional unit (example: 10K is 10*1024).\nUnits are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000).\n\nUsing color to distinguish file types is disabled both by default and\nwith --color=never.  With --color=auto, ls emits color codes only when\nstandard output is connected to a terminal.  The LS_COLORS environment\nvariable can change the settings.  Use the dircolors command to set it.\n\nExit status:\n 0  if OK,\n 1  if minor problems (e.g., cannot access subdirectory),\n 2  if serious trouble (e.g., cannot access command-line argument).\n\nGNU coreutils online help: <http://www.gnu.org/software/coreutils/>\nFull documentation at: <http://www.gnu.org/software/coreutils/ls>\nor available locally via: info '(coreutils) ls invocation'\n\n\n\n\nOh...  lots... but we aren't going to worry about that.\n\n\nFor now, let's look inside the \nDesktop/\n folder where we downloaded that zip\nfile at the beginning of the workshop.\n\n\nIf we want to use \nls\n on a different folder than the \ncurrent\n folder, just\npass the name of the folder you want to look in:\n\n\n$ ls -F Desktop/\n\n\n\n\nworkshop_data.zip\n\n\n\n\nThere it is!\n\n\ncd\n\n\nOk, we know where the zip file is, time to \nchange directory\n to the folder \nDesktop/\n.  To do this, we use the \ncd\n command:\n\n\n$ cd Desktop\n\n\n\n\nNow let's check in with \npwd\n again:\n\n\n$ pwd\n\n\n\n\n/home/gil/Desktop\n\n\n\n\nOk! Cool! We moved! Now if we run \nls\n we should see the zip file in here.\n\n\n$ ls -F\n\n\n\n\nworkshop_data.zip\n\n\n\n\nAnd there it is! Ok. We'll come back here in a second, but first let's explore a\nlittle more. Let's go back to the \"home directory\".\n\n\nHow do we do that...?\n\n\nThe home directory has the same name as our username. Let's try that!\n\n\n$ cd gil\n\n\n\n\ncd: no such file or directory: gil\n\n\n\n\nThat doesn't work. We're at the end of a branch of the tree that makes up the\nfilesystem. There has to be a way to go back -- what are we missing?\n\n\nLet's use \nls\n again, but this time add in the \n-a\n flag for \"show all\"\n\n\n$ ls -a\n\n\n\n\n.  ..  workshop_data.zip\n\n\n\n\nAHA! There are two more entries that we didn't see before: \n.\n and \n..\n\nWhat are those? Learn by doing, I say:\n\n\n$ cd .\n\n\n\n\n$ pwd\n\n\n\n\n/home/gil/Desktop\n\n\n\n\nWe're in the same spot. The \n.\n directory is a special directory in every folder\non the filesystem and it points to the current working directory.\n\n\n$ cd ..\n\n\n\n\n$ pwd\n\n\n\n\n/home/gil/\n\n\n\n\nWe made it back \nhome\n! The \n..\n directory is another special directory, but this one always points to the \nparent\n of the current directory.\n\n\nLet's try moving up a few more times!\n\n\n$ cd ..\n\n\n\n\n$ pwd\n\n\n\n\n/home\n\n\n\n\n$ cd ..\n\n\n\n\n$ pwd\n\n\n\n\n/\n\n\n\n\n$ cd ..\n\n\n\n\n$ pwd\n\n\n\n\n/\n\n\n\n\nWe can't go back any further because we are at the \nroot\n of the file \ntree\n.\n\n\nNow that we've had a look around, time to go back to the home directory.\nLet's use a little shortcut:\n\n\n$ cd\n\n\n\n\n$ pwd\n\n\n\n\n/home/gil/\n\n\n\n\nIf you don't pass a target to \ncd\n it will always take you back to your home\ndirectory by default. This is a nice option if you're looking around in a very\ndeep directory tree.\n\n\nAbsolute vs. relative paths\n\n\nAll of the navigation so far has been \nrelative\n. We are in the home directory,\nwe want to go to \nDesktop\n and so we type \ncd Desktop\n. This wouldn't work if we\nwere in a different directory.\n\n\nOne option when you need to jump around is to use \nabsolute\n paths, like this:\n\n\n$ cd /home/gil/Desktop\n\n\n\n\n$ pwd\n\n\n\n\n/home/gil/Desktop\n\n\n\n\nThe benefit of an absolute path is that it will work no matter where you start\nfrom, which can be helpful if you are deep in a directory tree.\n\n\nOne useful shortcut when typing out absolute paths is the \n~\n. The \n~\n is a\nshortcut for your home directory, so you don't need to explicitly write out\n\n/home/<username>/\n all the time.\n\n\n$ cd ~/Desktop\n\n\n\n\n$ pwd\n\n\n\n\n/home/gil/Desktop\n\n\n\n\nTab completion\n\n\nBefore we go any further, let's take a look at one of the most useful features\nof the *nix command line: tab completion\n\n\nReturn to the home directory if you aren't there already.\n\n\n$ cd\n\n\n\n\nType\n\n\n$ cd T\n\n\n\n\nthen hit the TAB key. Pretty cool, huh?\n\n\nWhenever you hit the TAB key, the shell will try to complete the remainder of\nthe line for you! It can't read minds, though. Since \nTemplates\n is the only\ndirectory beginning with \nT\n, the shell knew what to do. Let's try a different\nexample.\n\n\nType\n\n\n$ cd Do\n\n\n\n\nthen hit the TAB key.\n\n\nNothing. But hit it again\n\n\nDocuments/  Downloads/\n\n\n\n\nThere are two possible answers based on a prefix \nDo\n. In this case, tab\ncompletion will only complete up to the common prefix, which is just \nDo\n. It\nneeds a little more information to finish the completion. Try adding a \nc\n and\nhitting TAB again.\n\n\n$ cd Doc\n\n\n\n\n$ cd Documents/",
            "title": "Navigation"
        },
        {
            "location": "/nix/navigation/#navigating-the-command-line",
            "text": "Welcome!  The command line can be a little intimidating at first, but it is a powerful and\nefficient way of interacting with your computer. It's also the lingua franca\nwhen dealing with computing clusters and remote machines.",
            "title": "Navigating the Command Line"
        },
        {
            "location": "/nix/navigation/#whoami",
            "text": "Before we do anything else, let's figure out who we are. We can ask on the\ncommand line:  $ whoami  gil  That's my username!",
            "title": "whoami"
        },
        {
            "location": "/nix/navigation/#pwd",
            "text": "Now that we know who we are, time to figure out  where  we are.  To do that, we ask the terminal to  print working directory  or  pwd  $ pwd  /home/gil/  We're in the \"home directory\" for our user. To understand the \"home directory\",\nlet's take a brief moment to look at how the file system is organized.  Inverted tree diagram a la software carpentry",
            "title": "pwd"
        },
        {
            "location": "/nix/navigation/#ls",
            "text": "Let's look around  $ ls  Desktop  Documents  Downloads  Music  Pictures  Public  Templates  Videos  I think those are folders?  How can we tell? Use the  -F  flag  $ ls -F  Desktop/  Documents/  Downloads/  Music/  Pictures/  Public/  Templates/  Videos/  They all have a trailing slash, so they're all folders.\nWhat other options does  ls  have?  $ ls --help  Usage: ls [OPTION]... [FILE]...\nList information about the FILEs (the current directory by default).\nSort entries alphabetically if none of -cftuvSUX nor --sort is specified.\n\nMandatory arguments to long options are mandatory for short options too.\n  -a, --all                  do not ignore entries starting with .\n  -A, --almost-all           do not list implied . and ..\n      --author               with -l, print the author of each file\n  -b, --escape               print C-style escapes for nongraphic characters\n      --block-size=SIZE      scale sizes by SIZE before printing them; e.g.,\n                               '--block-size=M' prints sizes in units of\n                               1,048,576 bytes; see SIZE format below\n  -B, --ignore-backups       do not list implied entries ending with ~\n  -c                         with -lt: sort by, and show, ctime (time of last\n                               modification of file status information);\n                               with -l: show ctime and sort by name;\n                               otherwise: sort by ctime, newest first\n  -C                         list entries by columns\n      --color[=WHEN]         colorize the output; WHEN can be 'always' (default\n                               if omitted), 'auto', or 'never'; more info below\n  -d, --directory            list directories themselves, not their contents\n  -D, --dired                generate output designed for Emacs' dired mode\n  -f                         do not sort, enable -aU, disable -ls --color\n  -F, --classify             append indicator (one of */=>@|) to entries\n      --file-type            likewise, except do not append '*'\n      --format=WORD          across -x, commas -m, horizontal -x, long -l,\n                               single-column -1, verbose -l, vertical -C\n      --full-time            like -l --time-style=full-iso\n  -g                         like -l, but do not list owner\n      --group-directories-first\n                             group directories before files;\n                               can be augmented with a --sort option, but any\n                               use of --sort=none (-U) disables grouping\n  -G, --no-group             in a long listing, don't print group names\n  -h, --human-readable       with -l and/or -s, print human readable sizes\n     recommonmark                          (e.g., 1K 234M 2G)\n      --si                   likewise, but use powers of 1000 not 1024\n  -H, --dereference-command-line\n                             follow symbolic links listed on the command line\n      --dereference-command-line-symlink-to-dir\n                             follow each command line symbolic link\n                               that points to a directory\n      --hide=PATTERN         do not list implied entries matching shell PATTERN\n                               (overridden by -a or -A)\n      --indicator-style=WORD  append indicator with style WORD to entry names:\n                               none (default), slash (-p),\n                               file-type (--file-type), classify (-F)\n  -i, --inode                print the index number of each file\n  -I, --ignore=PATTERN       do not list implied entries matching shell PATTERN\n  -k, --kibibytes            default to 1024-byte blocks for disk usage\n  -l                         use a long listing format\n  -L, --dereference          when showing file information for a symbolic\n                               link, show information for the file the link\n                               references rather than for the link itself\n  -m                         fill width with a comma separated list of entries\n  -n, --numeric-uid-gid      like -l, but list numeric user and group IDs\n  -N, --literal              print raw entry names (don't treat e.g. control\n                               characters specially)\n  -o                         like -l, but do not list group information\n  -p, --indicator-style=slash\n                             append / indicator to directories\n  -q, --hide-control-chars   print ? instead of nongraphic characters\n      --show-control-chars   show nongraphic characters as-is (the default,\n                               unless program is 'ls' and output is a terminal)\n  -Q, --quote-name           enclose entry names in double quotes\n      --quoting-style=WORD   use quoting style WORD for entry names:\n                               literal, locale, shell, shell-always,\n                               shell-escape, shell-escape-always, c, escape\n  -r, --reverse              reverse order while sorting\n  -R, --recursive            list subdirectories recursively\n  -s, --size                 print the allocated size of each file, in blocks\n  -S                         sort by file size, largest first\n      --sort=WORD            sort by WORD instead of name: none (-U), size (-S),\n                               time (-t), version (-v), extension (-X)\n      --time=WORD            with -l, show time as WORD instead of default\n                               modification time: atime or access or use (-u);\n                               ctime or status (-c); also use specified time\n                               as sort key if --sort=time (newest first)\n      --time-style=STYLE     with -l, show times using style STYLE:\n                               full-iso, long-iso, iso, locale, or +FORMAT;\n                               FORMAT is interpreted like in 'date'; if FORMAT\n                               is FORMAT1<newline>FORMAT2, then FORMAT1 applies\n                               to non-recent files and FORMAT2 to recent files;\n                               if STYLE is prefixed with 'posix-', STYLE\n                               takes effect only outside the POSIX locale\n  -t                         sort by modification time, newest first\n  -T, --tabsize=COLS         assume tab stops at each COLS instead of 8\n  -u                         with -lt: sort by, and show, access time;\n                               with -l: show access time and sort by name;\n                               otherwise: sort by access time, newest first\n  -U                         do not sort; list entries in directory order\n  -v                         natural sort of (version) numbers within text\n  -w, --width=COLS           set output width to COLS.  0 means no limit\n  -x                         list entries by lines instead of by columns\n  -X                         sort alphabetically by entry extension\n  -Z, --context              print any security context of each file\n  -1                         list one file per line.  Avoid '\\n' with -q or -b\n      --help     display this help and exit\n      --version  output version information and exit\n\nThe SIZE argument is an integer and optional unit (example: 10K is 10*1024).\nUnits are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000).\n\nUsing color to distinguish file types is disabled both by default and\nwith --color=never.  With --color=auto, ls emits color codes only when\nstandard output is connected to a terminal.  The LS_COLORS environment\nvariable can change the settings.  Use the dircolors command to set it.\n\nExit status:\n 0  if OK,\n 1  if minor problems (e.g., cannot access subdirectory),\n 2  if serious trouble (e.g., cannot access command-line argument).\n\nGNU coreutils online help: <http://www.gnu.org/software/coreutils/>\nFull documentation at: <http://www.gnu.org/software/coreutils/ls>\nor available locally via: info '(coreutils) ls invocation'  Oh...  lots... but we aren't going to worry about that.  For now, let's look inside the  Desktop/  folder where we downloaded that zip\nfile at the beginning of the workshop.  If we want to use  ls  on a different folder than the  current  folder, just\npass the name of the folder you want to look in:  $ ls -F Desktop/  workshop_data.zip  There it is!",
            "title": "ls"
        },
        {
            "location": "/nix/navigation/#cd",
            "text": "Ok, we know where the zip file is, time to  change directory  to the folder  Desktop/ .  To do this, we use the  cd  command:  $ cd Desktop  Now let's check in with  pwd  again:  $ pwd  /home/gil/Desktop  Ok! Cool! We moved! Now if we run  ls  we should see the zip file in here.  $ ls -F  workshop_data.zip  And there it is! Ok. We'll come back here in a second, but first let's explore a\nlittle more. Let's go back to the \"home directory\".  How do we do that...?  The home directory has the same name as our username. Let's try that!  $ cd gil  cd: no such file or directory: gil  That doesn't work. We're at the end of a branch of the tree that makes up the\nfilesystem. There has to be a way to go back -- what are we missing?  Let's use  ls  again, but this time add in the  -a  flag for \"show all\"  $ ls -a  .  ..  workshop_data.zip  AHA! There are two more entries that we didn't see before:  .  and  .. \nWhat are those? Learn by doing, I say:  $ cd .  $ pwd  /home/gil/Desktop  We're in the same spot. The  .  directory is a special directory in every folder\non the filesystem and it points to the current working directory.  $ cd ..  $ pwd  /home/gil/  We made it back  home ! The  ..  directory is another special directory, but this one always points to the  parent  of the current directory.  Let's try moving up a few more times!  $ cd ..  $ pwd  /home  $ cd ..  $ pwd  /  $ cd ..  $ pwd  /  We can't go back any further because we are at the  root  of the file  tree .  Now that we've had a look around, time to go back to the home directory.\nLet's use a little shortcut:  $ cd  $ pwd  /home/gil/  If you don't pass a target to  cd  it will always take you back to your home\ndirectory by default. This is a nice option if you're looking around in a very\ndeep directory tree.",
            "title": "cd"
        },
        {
            "location": "/nix/navigation/#absolute-vs-relative-paths",
            "text": "All of the navigation so far has been  relative . We are in the home directory,\nwe want to go to  Desktop  and so we type  cd Desktop . This wouldn't work if we\nwere in a different directory.  One option when you need to jump around is to use  absolute  paths, like this:  $ cd /home/gil/Desktop  $ pwd  /home/gil/Desktop  The benefit of an absolute path is that it will work no matter where you start\nfrom, which can be helpful if you are deep in a directory tree.  One useful shortcut when typing out absolute paths is the  ~ . The  ~  is a\nshortcut for your home directory, so you don't need to explicitly write out /home/<username>/  all the time.  $ cd ~/Desktop  $ pwd  /home/gil/Desktop",
            "title": "Absolute vs. relative paths"
        },
        {
            "location": "/nix/navigation/#tab-completion",
            "text": "Before we go any further, let's take a look at one of the most useful features\nof the *nix command line: tab completion  Return to the home directory if you aren't there already.  $ cd  Type  $ cd T  then hit the TAB key. Pretty cool, huh?  Whenever you hit the TAB key, the shell will try to complete the remainder of\nthe line for you! It can't read minds, though. Since  Templates  is the only\ndirectory beginning with  T , the shell knew what to do. Let's try a different\nexample.  Type  $ cd Do  then hit the TAB key.  Nothing. But hit it again  Documents/  Downloads/  There are two possible answers based on a prefix  Do . In this case, tab\ncompletion will only complete up to the common prefix, which is just  Do . It\nneeds a little more information to finish the completion. Try adding a  c  and\nhitting TAB again.  $ cd Doc  $ cd Documents/",
            "title": "Tab completion"
        },
        {
            "location": "/nix/file_handling/",
            "text": "Creating, editing, removing files\n\n\nUse a text editor\n\n\nThere are a \nlot\n of different text editors and a \nlot\n of strong\nfeelings about which of them is the best.\n\n\nYou can use any editor you like, but you \nmust\n know how to use at least one\nterminal-friendly editor. In this workshop we are going to use \nnano\n. It's\nsimple and easy to use.\n\n\nMake sure you're in your home directory (use \ncd\n and \npwd\n to confirm) then type\n\n\n$ nano\n\n\n\n\nThis is a no-frills editor. Type something! How about a TODO list?\n\n\nTODO\n* [x] Learn how to navigate using the terminal\n* [ ] Learn how to create files\n* [ ] Learn about pipes and redirects\n\n\n\n\nAt the bottom you'll notice a bunch of different options but we are concerned\nwith only two of them: \nWrite Out\n (save) and \nExit\n.\n\n\nThe caret (\n^\n) means the Control key. To save the TODO list, hit \nCtrl+o\n, type\nin a name (how about \"TODO\") and then hit \nEnter\n. \nnano\n will report that it\nwrote some number of lines.\n\n\nNow exit \nnano\n by typing \nCtrl+x\n.\n\n\nUse \nls\n to see what happened:\n\n\n$ ls -F\n\n\n\n\nDesktop/  Documents/  Downloads/  Music/  Pictures/  Public/  TODO  Templates/  Videos/\n\n\n\n\nThere's the TODO list! If you want to edit the todo list, you can open it up in\n\nnano\n (you can use tab completion for the filename, too!)\n\n\n$ nano TODO\n\n\n\n\nCheck off the second item on the todo list and then save and exit \nnano\n. Notice\nthat when you hit \nCtrl+o\n to save an existing file, \nnano\n will automatically\nfill in the name of the existing file. If you wanted to \"Save As...\", you can\nsimply change the name in the \nWrite Out\n bar.\n\n\nCreate an empty file\n\n\nThere are a few ways to create files on the command line. If you want to create\nan \"empty\" file, you can use \ntouch\n. Try it!\n\n\n$ touch newfile\n\n\n\n\n$ ls -F\n\n\n\n\nDesktop/    Downloads/  Pictures/  TODO        Videos/\nDocuments/  Music/      Public/    Templates/  newfile\n\n\n\n\nYou can open \nnewfile\n in \nnano\n to confirm that it's empty. Then just exit out\nusing \nCtrl+x\n since there's nothing to save!\n\n\nCreate a directory\n\n\nTo create a new directory, use the \nmkdir\n command. We can create a \nResearch/\n\nfolder in the home directory.\n\n\n$ mkdir Research\n\n\n\n\n$ ls -F\n\n\n\n\nDesktop/    Downloads/  Pictures/  Research/  Templates/  newfile\nDocuments/  Music/      Public/    TODO       Videos/\n\n\n\n\nRemove a file\n\n\nWe don't need that empty file sitting around, we can remove it. To remove a\nfile, use the \nrm\n command:\n\n\n$ rm newfile\n\n\n\n\nDid anything happen?\n\n\n$ ls -F\n\n\n\n\nDesktop/    Downloads/  Pictures/  Research/  Templates/\nDocuments/  Music/      Public/    TODO       Videos/\n\n\n\n\nYes, \nnewfile\n is gone. And this is something to be aware of: there is no\n\"Recycle Bin\". There is no \"Undo\". That file is gone.\n\n\nRemove a directory\n\n\nLet's try to remove the \nResearch\n directory we created earlier.\n\n\n$ rm Research\n\n\n\n\nrm: cannot remove 'Research': Is a directory\n\n\n\n\nrm\n only works with files by default. If you want to remove the directory you\nneed to use the \n-r\n flag to specify a \nrecursive\n removal.\n\n\nThis will delete the directory and ALL of its contents. BE CAREFUL WHEN USING\nTHIS\n\n\n$ rm -r Research\n\n\n\n\n$ ls -F\n\n\n\n\nDesktop/    Downloads/  Pictures/  TODO        Videos/\nDocuments/  Music/      Public/    Templates/\n\n\n\n\nMove/Rename a file\n\n\nWe know how to create and delete files and folders now. What about renaming a\nfile?\n\n\nTo rename a file, we use the \nmv\n command, which is short for \"move\". This may\nseem a little bit odd at first, but renaming a file is the same as moving it to\na different location.\n\n\nTo start, let's make the file \nTODO\n lowercase. The syntax is \nmv <old location>\n<new location>\n\n\n$ mv TODO todo\n\n\n\n\n$ ls -F\n\n\n\n\nDesktop/    Downloads/  Pictures/  Templates/  todo\nDocuments/  Music/      Public/    Videos/\n\n\n\n\nWe \nmoved\n the file \nTODO\n from \n/home/<user>/TODO\n to a new location, called\n\n/home/<user>/todo\n. Since the directory doesn't change, the result is a\n\nrenamed\n file. \n\n\nWe can also move the \ntodo\n list to a different folder:\n\n\n$ mv todo Desktop/\n\n\n\n\n$ ls -F\n\n\n\n\nDesktop/  Documents/  Downloads/  Music/  Pictures/  Public/  Templates/  Videos/\n\n\n\n\nWe specified \nDesktop/\n as the \n<new location>\n in the \nmv\n command. Since\n\nDesktop/\n is a folder, \ntodo\n will move inside that folder. \n\n\n$ ls -F Desktop/\n\n\n\n\ntodo workshop_data.zip\n\n\n\n\nNote:\n As we see, if \n<new location>\n is a folder, then the file is moved\ninside the folder. However, if \n<new location>\n is an existing \nfile\n, then that\nfile will be overwritten.\n\n\nTODO exercises",
            "title": "File Creation and Editing"
        },
        {
            "location": "/nix/file_handling/#creating-editing-removing-files",
            "text": "",
            "title": "Creating, editing, removing files"
        },
        {
            "location": "/nix/file_handling/#use-a-text-editor",
            "text": "There are a  lot  of different text editors and a  lot  of strong\nfeelings about which of them is the best.  You can use any editor you like, but you  must  know how to use at least one\nterminal-friendly editor. In this workshop we are going to use  nano . It's\nsimple and easy to use.  Make sure you're in your home directory (use  cd  and  pwd  to confirm) then type  $ nano  This is a no-frills editor. Type something! How about a TODO list?  TODO\n* [x] Learn how to navigate using the terminal\n* [ ] Learn how to create files\n* [ ] Learn about pipes and redirects  At the bottom you'll notice a bunch of different options but we are concerned\nwith only two of them:  Write Out  (save) and  Exit .  The caret ( ^ ) means the Control key. To save the TODO list, hit  Ctrl+o , type\nin a name (how about \"TODO\") and then hit  Enter .  nano  will report that it\nwrote some number of lines.  Now exit  nano  by typing  Ctrl+x .  Use  ls  to see what happened:  $ ls -F  Desktop/  Documents/  Downloads/  Music/  Pictures/  Public/  TODO  Templates/  Videos/  There's the TODO list! If you want to edit the todo list, you can open it up in nano  (you can use tab completion for the filename, too!)  $ nano TODO  Check off the second item on the todo list and then save and exit  nano . Notice\nthat when you hit  Ctrl+o  to save an existing file,  nano  will automatically\nfill in the name of the existing file. If you wanted to \"Save As...\", you can\nsimply change the name in the  Write Out  bar.",
            "title": "Use a text editor"
        },
        {
            "location": "/nix/file_handling/#create-an-empty-file",
            "text": "There are a few ways to create files on the command line. If you want to create\nan \"empty\" file, you can use  touch . Try it!  $ touch newfile  $ ls -F  Desktop/    Downloads/  Pictures/  TODO        Videos/\nDocuments/  Music/      Public/    Templates/  newfile  You can open  newfile  in  nano  to confirm that it's empty. Then just exit out\nusing  Ctrl+x  since there's nothing to save!",
            "title": "Create an empty file"
        },
        {
            "location": "/nix/file_handling/#create-a-directory",
            "text": "To create a new directory, use the  mkdir  command. We can create a  Research/ \nfolder in the home directory.  $ mkdir Research  $ ls -F  Desktop/    Downloads/  Pictures/  Research/  Templates/  newfile\nDocuments/  Music/      Public/    TODO       Videos/",
            "title": "Create a directory"
        },
        {
            "location": "/nix/file_handling/#remove-a-file",
            "text": "We don't need that empty file sitting around, we can remove it. To remove a\nfile, use the  rm  command:  $ rm newfile  Did anything happen?  $ ls -F  Desktop/    Downloads/  Pictures/  Research/  Templates/\nDocuments/  Music/      Public/    TODO       Videos/  Yes,  newfile  is gone. And this is something to be aware of: there is no\n\"Recycle Bin\". There is no \"Undo\". That file is gone.",
            "title": "Remove a file"
        },
        {
            "location": "/nix/file_handling/#remove-a-directory",
            "text": "Let's try to remove the  Research  directory we created earlier.  $ rm Research  rm: cannot remove 'Research': Is a directory  rm  only works with files by default. If you want to remove the directory you\nneed to use the  -r  flag to specify a  recursive  removal.  This will delete the directory and ALL of its contents. BE CAREFUL WHEN USING\nTHIS  $ rm -r Research  $ ls -F  Desktop/    Downloads/  Pictures/  TODO        Videos/\nDocuments/  Music/      Public/    Templates/",
            "title": "Remove a directory"
        },
        {
            "location": "/nix/file_handling/#moverename-a-file",
            "text": "We know how to create and delete files and folders now. What about renaming a\nfile?  To rename a file, we use the  mv  command, which is short for \"move\". This may\nseem a little bit odd at first, but renaming a file is the same as moving it to\na different location.  To start, let's make the file  TODO  lowercase. The syntax is  mv <old location>\n<new location>  $ mv TODO todo  $ ls -F  Desktop/    Downloads/  Pictures/  Templates/  todo\nDocuments/  Music/      Public/    Videos/  We  moved  the file  TODO  from  /home/<user>/TODO  to a new location, called /home/<user>/todo . Since the directory doesn't change, the result is a renamed  file.   We can also move the  todo  list to a different folder:  $ mv todo Desktop/  $ ls -F  Desktop/  Documents/  Downloads/  Music/  Pictures/  Public/  Templates/  Videos/  We specified  Desktop/  as the  <new location>  in the  mv  command. Since Desktop/  is a folder,  todo  will move inside that folder.   $ ls -F Desktop/  todo workshop_data.zip  Note:  As we see, if  <new location>  is a folder, then the file is moved\ninside the folder. However, if  <new location>  is an existing  file , then that\nfile will be overwritten.",
            "title": "Move/Rename a file"
        },
        {
            "location": "/nix/file_handling/#todo-exercises",
            "text": "",
            "title": "TODO exercises"
        },
        {
            "location": "/nix/redirection/",
            "text": "Redirection\n\n\nWhat happens when we run \nls\n? This isn't a trick question. \n\n\n$ ls -F\n\n\n\n\nDesktop/  Documents/  Downloads/  Music/  Pictures/  Public/  Templates/  Videos/\n\n\n\n\nWe get a list of the files and folders in the current directory \nprinted\n to the\nscreen. But what if we didn't want it to print to the screen but instead wanted\nto save it to a file somewhere?\n\n\nEasy! \n\n\nBy default, commands run on the command line print to \nstdout\n (standard\noutput). If we want to specify a different location to print to, we use the \n>\n\nsymbol.\n\n\nTry it out:\n\n\n$ ls -F > filelist\n\n\n\n\nNo output appeared on the screen (\nstdout\n). Let's check what's in \nfilelist\n\n\n$ nano filelist\n\n\n\n\nThere it is! \n\n\nNow, what do we do with it...? How about we try counting the number of lines in\n\nfilelist\n? \n\n\nImagine we have a MUCH bigger directory and we want to know how many files and\nfolders are in it. When we redirect \nls\n to a file, every file and folder is\nwritten to a separate line; if we count the number of lines, we know how many\nfiles there are!\n\n\nHow do we count the number of lines? We use \nwc\n (wordcount)\n\n\nwc\n\n\nYes, it's \nword_count, but it counts words, characters, lines and more! We'll\nplay with \nwc\n more later, but for now, let's just count the number of lines in\n\nfilelist\n. To specify that we want the number of _lines\n in a file we use the\n\n-l\n flag.\n\n\n$ wc -l filelist\n\n\n\n\n8 filelist\n\n\n\n\nCool! \nwc\n tells us that \nfilelist\n has 8 lines, which means we have 8\nfiles/folders in the HOME directory. (Yes, we already knew that since we can\ncount, but still...)",
            "title": "Redirection"
        },
        {
            "location": "/nix/redirection/#redirection",
            "text": "What happens when we run  ls ? This isn't a trick question.   $ ls -F  Desktop/  Documents/  Downloads/  Music/  Pictures/  Public/  Templates/  Videos/  We get a list of the files and folders in the current directory  printed  to the\nscreen. But what if we didn't want it to print to the screen but instead wanted\nto save it to a file somewhere?  Easy!   By default, commands run on the command line print to  stdout  (standard\noutput). If we want to specify a different location to print to, we use the  > \nsymbol.  Try it out:  $ ls -F > filelist  No output appeared on the screen ( stdout ). Let's check what's in  filelist  $ nano filelist  There it is!   Now, what do we do with it...? How about we try counting the number of lines in filelist ?   Imagine we have a MUCH bigger directory and we want to know how many files and\nfolders are in it. When we redirect  ls  to a file, every file and folder is\nwritten to a separate line; if we count the number of lines, we know how many\nfiles there are!  How do we count the number of lines? We use  wc  (wordcount)",
            "title": "Redirection"
        },
        {
            "location": "/nix/redirection/#wc",
            "text": "Yes, it's  word_count, but it counts words, characters, lines and more! We'll\nplay with  wc  more later, but for now, let's just count the number of lines in filelist . To specify that we want the number of _lines  in a file we use the -l  flag.  $ wc -l filelist  8 filelist  Cool!  wc  tells us that  filelist  has 8 lines, which means we have 8\nfiles/folders in the HOME directory. (Yes, we already knew that since we can\ncount, but still...)",
            "title": "wc"
        },
        {
            "location": "/nix/pipes/",
            "text": "Pipes and intro to unix utilities\n\n\nWe just learned about redirecting output to files using the \n>\n operator. In\naddition to redirecting a data stream to a file, we can also \nintercept\n that\nstream of information and perform another operation on it. \n\n\nTo do this we use the \n|\n operator which we call a pipe. \n\n\nPipes allow a user to string together a series of commands, a \"command\npipeline\", and there are many useful utilites that are commonly installed on\nUNIX systems. \n\n\nThe use of these many small programs is only clear when we use it in concert\nwith pipes, so we're going to learn about them at the same time.\n\n\ncat\n\n\nIn the redirection exercise we wrote the contents of the command \nls -F\n into a\nfile called \nfilelist\n. When we checked to see if it worked, we opened the file\nup in \nnano\n. That didn't take very long, but it can be a pain if you need to\nlook through the contents of a number of files.\n\n\nNow, we didn't need to \nedit\n \nfilelist\n, right? We just wanted to look at it. \nThis is the perfect job for \ncat\n!\n\n\ncat\n dumps the contents of a file into \nstdout\n (by default). \n\n\nTry it out on \nfilelist\n to see what happens.\n\n\n$ cat filelist\n\n\n\n\nDesktop/\nDocuments/\nDownloads/\nMusic/\nPictures/\nPublic/\nTemplates/\nVideos/\n\n\n\n\nTime to pipe!\n\n\nRemember \nwc -l\n? We used it to count the lines in \nfilelist\n. We did:\n\n\n$ wc -l filelist\n\n\n\n\n8 filelist\n\n\n\n\nBut instead of doing it this way, we can also \npipe\n the \ncontents\n of\n\nfilelist\n to \nwc\n.\n\n\nTry it out!\n\n\n$ cat filelist | wc -l\n\n\n\n\n8\n\n\n\n\nWhat just happened? \n\n\nWe used \ncat\n to dump the contents of \nfilelist\n to the screen (\nstdout\n). But\nthen, instead of printing the contents, we intercepted them with the pipe and\ninstead fed them into \nwc\n. \n\n\nSkip \nfilelist\n\n\nWe used \n>\n to redirect the contents of \nls -F\n, then used \ncat\n to dump the\ncontents of \nfilelist\n and then piped those contents to \nwc\n. Are all of these\nsteps necessary?\n\n\nNo! How about: \n\n\nls -F | wc -l\n\n\n\n\n9\n\n\n\n\nAny output can be piped to (nearly) any other program. \n\n\ngrep\n\n\ngrep\n is your best friend, you just don't know it yet. \ngrep\n does stand for\nsomething, but it's long and confusing, so just accept that \ngrep\n is \ngrep\n. \n\n\ngrep\n searches through text files and streams for matches. It is one of the\nmost powerful tools in the UNIX toolbox. It's also \n42 years old\n. And we still\nuse it. It's that good.\n\n\nTry it out by piping the contents of \nls -F\n and \ngrep\nping for \"Do\"\n\n\n$ ls -F | grep Do\n\n\n\n\nDocuments/\nDownloads/\n\n\n\n\nExercise\n\n\nThere are obviously two files/folders that contain \nDo\n that \ngrep\n has matched.\nBut what if there were hundreds? How can we count the number of results from a\n\ngrep\n? \n\n\nUse \nls\n, \ngrep\n and any tools we've already learned about to get the command\nline to spit out the number of files/folders that contain \nDo\n in their title.\n\n\nsort\n\n\nwget https://raw.githubusercontent.com/barbagroup/essential_skills_RRC/master/copa_america_goals\n\n\n\n\nOk! We have downloaded a list of goals scored in the 2016 Copa America, let's\ntake a look at what the file contains:\n\n\n$ cat copa_america_goals \n\n\n\n\n1 Miku\n1 Neymar\n1 Robinho\n3 Sergio Aguero\n2 Charles Aranguiz\n3 Lucas Barrios\n1 Edgar Benitez\n2 Miller Bolanos\n1 Andrew Carrillo\n1 Douglas Costa\n1 Christian Cueva\n2 Angel Di Maria\n1 Roberto Firmino\n1 Jose Gimenez\n1 Derlis Gonzalez\n4 Paolo Guerrero\n1 Nelson Haedo Valdez\n2 Gonzalo Higuain\n1 Mauricio Isla\n2 Raul Jimenez\n2 Marcelo Martins Moreno\n1 Gary Medel\n1 Lionel Messi\n1 Jeison Murillo\n1 Javier pastore\n1 Claudio Pizarro\n1 Ronald Raldes\n1 Cristian Rodriguez\n1 Marcos Rojo\n1 Salomon Rondon\n1 Alexis Sanchez\n1 Thiago Silva\n1 Martis Smedberg-Dalence\n2 Enner Valencia\n4 Eduardo Vargas\n3 Arturo Vidal\n2 Matias Vuoso\n\n\n\n\nThe first column is goals, then first names, then last names. And of course,\nsome players only have one name. How many players scored 4 goals? We can \ngrep\n\nfor that, which will definitely work, but we can also sort the list easily using\nthe \nsort\n command.  Try it out!\n\n\n$ cat copa_america_goals | sort\n\n\n\n\n1 Alexis Sanchez\n1 Andrew Carrillo\n1 Christian Cueva\n1 Claudio Pizarro\n1 Cristian Rodriguez\n1 Derlis Gonzalez\n1 Douglas Costa\n1 Edgar Benitez\n1 Gary Medel\n1 Javier pastore\n1 Jeison Murillo\n1 Jose Gimenez\n1 Lionel Messi\n1 Marcos Rojo\n1 Martis Smedberg-Dalence\n1 Mauricio Isla\n1 Miku\n1 Nelson Haedo Valdez\n1 Neymar\n1 Roberto Firmino\n1 Robinho\n1 Ronald Raldes\n1 Salomon Rondon\n1 Thiago Silva\n2 Angel Di Maria\n2 Charles Aranguiz\n2 Enner Valencia\n2 Gonzalo Higuain\n2 Marcelo Martins Moreno\n2 Matias Vuoso\n2 Miller Bolanos\n2 Raul Jimenez\n3 Arturo Vidal\n3 Lucas Barrios\n3 Sergio Aguero\n4 Eduardo Vargas\n4 Paolo Guerrero\n\n\n\n\nAnd we see that at the bottom of the sorted list there are two players who\nscored 4 goals in the Copa. \n\n\nNow, sorting goal scorers by last name seems a little strange if we care about\nthe number of goals scored. Let's save the list of goals but sort it by the\nnumber of goals. How should we do that?\n\n\n$ cat copa_america_goals | sort > copa_goals_sorted\n\n\n\n\nAnd remember, there's no output to the screen (\nstdout\n) because we \nredirected\n\nit to a new file. We can \ncat\n the new file to make sure it worked as we expect.\n\n\n$ cat copa_goals_sorted \n\n\n\n\n1 Alexis Sanchez\n1 Andrew Carrillo\n1 Christian Cueva\n1 Claudio Pizarro\n1 Cristian Rodriguez\n1 Derlis Gonzalez\n1 Douglas Costa\n1 Edgar Benitez\n1 Gary Medel\n1 Javier pastore\n1 Jeison Murillo\n1 Jose Gimenez\n1 Lionel Messi\n1 Marcos Rojo\n1 Martis Smedberg-Dalence\n1 Mauricio Isla\n1 Miku\n1 Nelson Haedo Valdez\n1 Neymar\n1 Roberto Firmino\n1 Robinho\n1 Ronald Raldes\n1 Salomon Rondon\n1 Thiago Silva\n2 Angel Di Maria\n2 Charles Aranguiz\n2 Enner Valencia\n2 Gonzalo Higuain\n2 Marcelo Martins Moreno\n2 Matias Vuoso\n2 Miller Bolanos\n2 Raul Jimenez\n3 Arturo Vidal\n3 Lucas Barrios\n3 Sergio Aguero\n4 Eduardo Vargas\n4 Paolo Guerrero\n\n\n\n\n$ cat copa_goals_sorted | grep Alexis\n\n\n\n\n1 Alexis Sanchez",
            "title": "Piping"
        },
        {
            "location": "/nix/pipes/#pipes-and-intro-to-unix-utilities",
            "text": "We just learned about redirecting output to files using the  >  operator. In\naddition to redirecting a data stream to a file, we can also  intercept  that\nstream of information and perform another operation on it.   To do this we use the  |  operator which we call a pipe.   Pipes allow a user to string together a series of commands, a \"command\npipeline\", and there are many useful utilites that are commonly installed on\nUNIX systems.   The use of these many small programs is only clear when we use it in concert\nwith pipes, so we're going to learn about them at the same time.",
            "title": "Pipes and intro to unix utilities"
        },
        {
            "location": "/nix/pipes/#cat",
            "text": "In the redirection exercise we wrote the contents of the command  ls -F  into a\nfile called  filelist . When we checked to see if it worked, we opened the file\nup in  nano . That didn't take very long, but it can be a pain if you need to\nlook through the contents of a number of files.  Now, we didn't need to  edit   filelist , right? We just wanted to look at it. \nThis is the perfect job for  cat !  cat  dumps the contents of a file into  stdout  (by default).   Try it out on  filelist  to see what happens.  $ cat filelist  Desktop/\nDocuments/\nDownloads/\nMusic/\nPictures/\nPublic/\nTemplates/\nVideos/",
            "title": "cat"
        },
        {
            "location": "/nix/pipes/#time-to-pipe",
            "text": "Remember  wc -l ? We used it to count the lines in  filelist . We did:  $ wc -l filelist  8 filelist  But instead of doing it this way, we can also  pipe  the  contents  of filelist  to  wc .  Try it out!  $ cat filelist | wc -l  8  What just happened?   We used  cat  to dump the contents of  filelist  to the screen ( stdout ). But\nthen, instead of printing the contents, we intercepted them with the pipe and\ninstead fed them into  wc .",
            "title": "Time to pipe!"
        },
        {
            "location": "/nix/pipes/#skip-filelist",
            "text": "We used  >  to redirect the contents of  ls -F , then used  cat  to dump the\ncontents of  filelist  and then piped those contents to  wc . Are all of these\nsteps necessary?  No! How about:   ls -F | wc -l  9  Any output can be piped to (nearly) any other program.",
            "title": "Skip filelist"
        },
        {
            "location": "/nix/pipes/#grep",
            "text": "grep  is your best friend, you just don't know it yet.  grep  does stand for\nsomething, but it's long and confusing, so just accept that  grep  is  grep .   grep  searches through text files and streams for matches. It is one of the\nmost powerful tools in the UNIX toolbox. It's also  42 years old . And we still\nuse it. It's that good.  Try it out by piping the contents of  ls -F  and  grep ping for \"Do\"  $ ls -F | grep Do  Documents/\nDownloads/",
            "title": "grep"
        },
        {
            "location": "/nix/pipes/#exercise",
            "text": "There are obviously two files/folders that contain  Do  that  grep  has matched.\nBut what if there were hundreds? How can we count the number of results from a grep ?   Use  ls ,  grep  and any tools we've already learned about to get the command\nline to spit out the number of files/folders that contain  Do  in their title.",
            "title": "Exercise"
        },
        {
            "location": "/nix/pipes/#sort",
            "text": "wget https://raw.githubusercontent.com/barbagroup/essential_skills_RRC/master/copa_america_goals  Ok! We have downloaded a list of goals scored in the 2016 Copa America, let's\ntake a look at what the file contains:  $ cat copa_america_goals   1 Miku\n1 Neymar\n1 Robinho\n3 Sergio Aguero\n2 Charles Aranguiz\n3 Lucas Barrios\n1 Edgar Benitez\n2 Miller Bolanos\n1 Andrew Carrillo\n1 Douglas Costa\n1 Christian Cueva\n2 Angel Di Maria\n1 Roberto Firmino\n1 Jose Gimenez\n1 Derlis Gonzalez\n4 Paolo Guerrero\n1 Nelson Haedo Valdez\n2 Gonzalo Higuain\n1 Mauricio Isla\n2 Raul Jimenez\n2 Marcelo Martins Moreno\n1 Gary Medel\n1 Lionel Messi\n1 Jeison Murillo\n1 Javier pastore\n1 Claudio Pizarro\n1 Ronald Raldes\n1 Cristian Rodriguez\n1 Marcos Rojo\n1 Salomon Rondon\n1 Alexis Sanchez\n1 Thiago Silva\n1 Martis Smedberg-Dalence\n2 Enner Valencia\n4 Eduardo Vargas\n3 Arturo Vidal\n2 Matias Vuoso  The first column is goals, then first names, then last names. And of course,\nsome players only have one name. How many players scored 4 goals? We can  grep \nfor that, which will definitely work, but we can also sort the list easily using\nthe  sort  command.  Try it out!  $ cat copa_america_goals | sort  1 Alexis Sanchez\n1 Andrew Carrillo\n1 Christian Cueva\n1 Claudio Pizarro\n1 Cristian Rodriguez\n1 Derlis Gonzalez\n1 Douglas Costa\n1 Edgar Benitez\n1 Gary Medel\n1 Javier pastore\n1 Jeison Murillo\n1 Jose Gimenez\n1 Lionel Messi\n1 Marcos Rojo\n1 Martis Smedberg-Dalence\n1 Mauricio Isla\n1 Miku\n1 Nelson Haedo Valdez\n1 Neymar\n1 Roberto Firmino\n1 Robinho\n1 Ronald Raldes\n1 Salomon Rondon\n1 Thiago Silva\n2 Angel Di Maria\n2 Charles Aranguiz\n2 Enner Valencia\n2 Gonzalo Higuain\n2 Marcelo Martins Moreno\n2 Matias Vuoso\n2 Miller Bolanos\n2 Raul Jimenez\n3 Arturo Vidal\n3 Lucas Barrios\n3 Sergio Aguero\n4 Eduardo Vargas\n4 Paolo Guerrero  And we see that at the bottom of the sorted list there are two players who\nscored 4 goals in the Copa.   Now, sorting goal scorers by last name seems a little strange if we care about\nthe number of goals scored. Let's save the list of goals but sort it by the\nnumber of goals. How should we do that?  $ cat copa_america_goals | sort > copa_goals_sorted  And remember, there's no output to the screen ( stdout ) because we  redirected \nit to a new file. We can  cat  the new file to make sure it worked as we expect.  $ cat copa_goals_sorted   1 Alexis Sanchez\n1 Andrew Carrillo\n1 Christian Cueva\n1 Claudio Pizarro\n1 Cristian Rodriguez\n1 Derlis Gonzalez\n1 Douglas Costa\n1 Edgar Benitez\n1 Gary Medel\n1 Javier pastore\n1 Jeison Murillo\n1 Jose Gimenez\n1 Lionel Messi\n1 Marcos Rojo\n1 Martis Smedberg-Dalence\n1 Mauricio Isla\n1 Miku\n1 Nelson Haedo Valdez\n1 Neymar\n1 Roberto Firmino\n1 Robinho\n1 Ronald Raldes\n1 Salomon Rondon\n1 Thiago Silva\n2 Angel Di Maria\n2 Charles Aranguiz\n2 Enner Valencia\n2 Gonzalo Higuain\n2 Marcelo Martins Moreno\n2 Matias Vuoso\n2 Miller Bolanos\n2 Raul Jimenez\n3 Arturo Vidal\n3 Lucas Barrios\n3 Sergio Aguero\n4 Eduardo Vargas\n4 Paolo Guerrero  $ cat copa_goals_sorted | grep Alexis  1 Alexis Sanchez",
            "title": "sort"
        },
        {
            "location": "/nix/man_and_less/",
            "text": "vi\n movement commands\n\n\nvi\n or \nvim\n is a popular and powerful command line text editor. It's also\nnotoriously difficult for beginners. It's too much to try to learn \nvi\n on top\nof everything else we're going to look at, but we do need to look at a few \nvi\n\ncommands.\n\n\nWhy? Because a lot of *nix programs inherited parts of their interface from \nvi\n\nand you'll need to know how to interact with them.\n\n\n\n\n\n\n\n\nCommand\n\n\nAction\n\n\n\n\n\n\n\n\n\n\nj or Down Arrow\n\n\nDown\n\n\n\n\n\n\nk or Up Arrow\n\n\nUp\n\n\n\n\n\n\nq\n\n\nQuit\n\n\n\n\n\n\ng or <\n\n\nGo to top\n\n\n\n\n\n\nG or >\n\n\nGo to bottom",
            "title": "man and less"
        },
        {
            "location": "/nix/man_and_less/#vi-movement-commands",
            "text": "vi  or  vim  is a popular and powerful command line text editor. It's also\nnotoriously difficult for beginners. It's too much to try to learn  vi  on top\nof everything else we're going to look at, but we do need to look at a few  vi \ncommands.  Why? Because a lot of *nix programs inherited parts of their interface from  vi \nand you'll need to know how to interact with them.     Command  Action      j or Down Arrow  Down    k or Up Arrow  Up    q  Quit    g or <  Go to top    G or >  Go to bottom",
            "title": "vi movement commands"
        },
        {
            "location": "/nix/uber/",
            "text": "uber example\n\n\nDownload and unzip file from here:\n\n\nShould have folder \nuber-trip-data\n.  \ncd\n to that directory and take a look.\n\n\n$ cd uber-trip-data/\n\n\n\n\n$ ls\n\n\n\n\ntaxi-zone-lookup.csv     uber-raw-data-janjune-15.csv.zip  uber-raw-data-may14.csv\nuber-raw-data-apr14.csv  uber-raw-data-jul14.csv           uber-raw-data-sep14.csv\nuber-raw-data-aug14.csv  uber-raw-data-jun14.csv\n\n\n\n\nWe have several raw data files (so named). \ncsv\n files divided by month and also\na zip file. We'll leave the zip file alone for the moment. What questions can we\nanswer about this dataset from the command line?\n\n\nFirst, it would help to know what these files contain. We can use \nhead\n to\ndisplay the first ten lines of one of the raw files.\n\n\n$ head uber-raw-data-apr14.csv\n\n\n\n\n\"Date/Time\",\"Lat\",\"Lon\",\"Base\"\n\"4/1/2014 0:11:00\",40.769,-73.9549,\"B02512\"\n\"4/1/2014 0:17:00\",40.7267,-74.0345,\"B02512\"\n\"4/1/2014 0:21:00\",40.7316,-73.9873,\"B02512\"\n\"4/1/2014 0:28:00\",40.7588,-73.9776,\"B02512\"\n\"4/1/2014 0:33:00\",40.7594,-73.9722,\"B02512\"\n\"4/1/2014 0:33:00\",40.7383,-74.0403,\"B02512\"\n\"4/1/2014 0:39:00\",40.7223,-73.9887,\"B02512\"\n\"4/1/2014 0:45:00\",40.762,-73.979,\"B02512\"\n\"4/1/2014 0:55:00\",40.7524,-73.996,\"B02512\"\n\n\n\n\nThey weren't kidding when they said \"raw\" data. What do we have here? Looks like\na date and time (these are pickup times), the lat-long of the pickup location\nand some \"Base\" id that we don't care about right now.\n\n\nWhat can we take away from this?\n\n\nFor one, that the number of lines in this file is how many pickups Uber made\nduring the month of April, 2014. That sounds like interesting information. We\ncan use \nwc\n or \nwordcount\n to count the number of \nlines\n in a file by using\nthe \n-l\n flag.\n\n\n$ wc -l uber-raw-data-apr14.csv\n\n\n\n\n564517 uber-raw-data-apr14.csv\n\n\n\n\nWe know now that Uber provided more than half a million rides in New York City\nin April of 2014. Let's take a look at how that figure changes month-to-month!\n\n\nWe can run the same \nwc\n command but now use the \n*\n wildcard to get the\nlinecount of every file in the directory.\n\n\n$ wc -l *\n\n\n\n\n        0 taxi-zone-lookup.csv\n   564517 uber-raw-data-apr14.csv\n   829276 uber-raw-data-aug14.csv\n   284595 uber-raw-data-janjune-15.csv.zip\n   796122 uber-raw-data-jul14.csv\n   663845 uber-raw-data-jun14.csv\n   652436 uber-raw-data-may14.csv\n  1028137 uber-raw-data-sep14.csv\n  4818928 total\n\n\n\n\nCool, but the linecount of a zip file doesn't really make any sense. To be a\nlittle more specific, restrict \nwc\n to only look at \ncsv\n files.\n\n\n$ wc -l *.csv\n\n\n\n\n        0 taxi-zone-lookup.csv\n   564517 uber-raw-data-apr14.csv\n   829276 uber-raw-data-aug14.csv\n   796122 uber-raw-data-jul14.csv\n   663845 uber-raw-data-jun14.csv\n   652436 uber-raw-data-may14.csv\n  1028137 uber-raw-data-sep14.csv\n  4534333 total\n\n\n\n\nBetter. \nwc\n outputs files in the order it gets them, which in this case is the\norder they exist in the directory. And that's alphabetical order. The names of\nmonths aren't hugely useful when sorting alphabetically.\n\n\nLet's use the \nsort\n command to sort the results from \nwc\n. We can pipe the\noutput of \nwc\n to \nsort\n using the \n|\n character. Remember, the pipe takes the\noutput from the previous command and hands it off to the following command.\n\n\n$ wc -l *.csv | sort\n\n\n\n\n        0 taxi-zone-lookup.csv\n  1028137 uber-raw-data-sep14.csv\n  4534333 total\n   564517 uber-raw-data-apr14.csv\n   652436 uber-raw-data-may14.csv\n   663845 uber-raw-data-jun14.csv\n   796122 uber-raw-data-jul14.csv\n   829276 uber-raw-data-aug14.csv\n\n\n\n\nHmmm.  That looks a little funny.  Can you see what \nsort\n did?\n\n\nYeah, it sorted things alphanumerically, which isn't helpful since it only looks\nat leading digits. We want to use the number of lines in each file as the\nsorting criteria.\n\n\nTo do this, we can use the \n-n\n flag with \nsort\n to specify a \"numerical\" sort.\n\n\nThis may start to look a little confusing, but remember, we're just building up\na command using smaller commands. We use the \n-l\n flag with \nwc\n to count the\nnumber of lines, then pipe that output to \nsort\n where we use the \n-n\n flag to\nrequire numerical sorting.\n\n\n$ wc -l *.csv | sort -n\n\n\n\n\n        0 taxi-zone-lookup.csv\n   564517 uber-raw-data-apr14.csv\n   652436 uber-raw-data-may14.csv\n   663845 uber-raw-data-jun14.csv\n   796122 uber-raw-data-jul14.csv\n   829276 uber-raw-data-aug14.csv\n  1028137 uber-raw-data-sep14.csv\n  4534333 total\n\n\n\n\nOk! Now we have the raw data files sorted by number of lines, which we know is\nequivalent to number of rides. And look, now the months are in the correct\norder. That wasn't necessarily expected, but looking at this output we can see\nthat Uber is expanding at a pretty fast pace in 2014; they nearly doubled their\nusage numbers in 5 months!\n\n\nThis data set is missing the last quarter of 2014, but we have the first half of\n2015 available, so we can check if the trend continues (is there a ceiling for\nUber requests in NYC?)\n\n\nFirst, unzip the file containing the 2015 data.\n\n\n$ unzip uber-raw-data-janjune-15.csv.zip\n\n\n\n\nArchive:  uber-raw-data-janjune-15.csv.zip\n  inflating: uber-raw-data-janjune-15.csv\n   creating: __MACOSX/\n  inflating: __MACOSX/._uber-raw-data-janjune-15.csv\n\n\n\n\nNow we know that whoever created this zip file uses a Mac. But that's not really\nimportant. Let's take another look at the line counts.\n\n\n$ wc -l *.csv | sort -n\n\n\n\n\n        0 taxi-zone-lookup.csv\n   564517 uber-raw-data-apr14.csv\n   652436 uber-raw-data-may14.csv\n   663845 uber-raw-data-jun14.csv\n   796122 uber-raw-data-jul14.csv\n   829276 uber-raw-data-aug14.csv\n  1028137 uber-raw-data-sep14.csv\n 14270480 uber-raw-data-janjune-15.csv\n 18804813 total\n\n\n\n\nWow! 14+ million rides! Impressive! But this data layout is different from the\n2014 data. The six months are all in the same file. Not cool. So what now?\n\n\nFirst, let's see what the data looks like in the combined file.\n\n\n$ head uber-raw-data-janjune-15.csv\n\n\n\n\nDispatching_base_num,Pickup_date,Affiliated_base_num,locationID\nB02617,2015-05-17 09:47:00,B02617,141\nB02617,2015-05-17 09:47:00,B02617,65\nB02617,2015-05-17 09:47:00,B02617,100\nB02617,2015-05-17 09:47:00,B02774,80\nB02617,2015-05-17 09:47:00,B02617,90\nB02617,2015-05-17 09:47:00,B02617,228\nB02617,2015-05-17 09:47:00,B02617,7\nB02617,2015-05-17 09:47:00,B02764,74\nB02617,2015-05-17 09:47:00,B02617,249\n\n\n\n\nVery uncool. First, the data is in a different format than the previous files we\nlooked at. Worse, the first pickup listed is in May? Either the file is\nmislabeled (bad) or it isn't even sorted (bad).\n\n\nLet's look at a few more lines to see if we can figure out which bad scenario we\nhave.\n\n\nWe can use \ntail\n to peek at the \nlast\n 10 lines in the file. How do those look?\n\n\n$ tail uber-raw-data-janjune-15.csv\n\n\n\n\nB02765,2015-05-08 15:42:00,B02764,79\nB02765,2015-05-08 15:42:00,B02765,37\nB02765,2015-05-08 15:42:00,B02765,161\nB02765,2015-05-08 15:42:00,B02765,7\nB02765,2015-05-08 15:43:00,B02711,25\nB02765,2015-05-08 15:43:00,B02765,186\nB02765,2015-05-08 15:43:00,B02765,263\nB02765,2015-05-08 15:43:00,B02765,90\nB02765,2015-05-08 15:44:00,B01899,45\nB02765,2015-05-08 15:44:00,B02682,144\n\n\n\n\nNot looking good.  Is this all just in May?  Let's look through a larger number of lines using \nhead\n and see if we can find a ride that wasn't in May.  Use the \n-n\n flag with \nhead\n to specify the number of lines to show (the default is 10).\n\n\n$ head -n 500 uber-raw-data-janjune-15.csv\n\n\n\n\n[snip]\nB02598,2015-01-18 11:06:58,B02598,7\nB02598,2015-01-18 18:55:46,B02598,141\nB02598,2015-01-18 14:54:28,B02598,249\nB02598,2015-01-18 20:48:57,B02598,90\nB02598,2015-01-18 09:28:20,B02682,234\nB02598,2015-01-18 19:31:14,B02764,13\nB02598,2015-01-18 14:13:38,B02598,163\nB02598,2015-01-18 22:53:57,B02598,90\nB02598,2015-01-18 19:13:00,B02617,246\nB02598,2015-01-18 14:53:36,B02598,161\nB02598,2015-01-18 02:37:00,B02598,114\nB02598,2015-01-18 18:47:01,B02598,113\nB02598,2015-01-18 16:06:11,B02598,233\nB02598,2015-01-18 15:36:12,B02598,162\nB02598,2015-01-18 02:10:39,B02598,50\nB02598,2015-01-18 12:18:57,B02764,142\nB02598,2015-01-18 14:03:01,B02598,37\n\n\n\n\nOk. 500 lines in, we can see some January pickups. It looks like we have bad\noption #2. The data is labeled correctly but isn't sorted. Time to sort it!\n\n\nSorting can be expensive, so rather than trying to sort the whole file at once,\nlet's copy a portion of the big file into a separate file.\n\n\nUse the same \nhead\n command we just used, but now, instead of writing it to the\nscreen, we can \nredirect\n that output to another file using \n>\n. We'll just call\nthat file \ntest.csv\n.\n\n\n$ head -n 500 uber-raw-data-janjune-15.csv > test.csv\n\n\n\n\nNow it's time to figure out how to sort this data. We can use \nsort\n the way we\ndid with \nwc\n because the information we want to use as the sort key (the date\nand time) are embedded in the middle of every line.\n\n\nHere's one line from \ntest.csv\n:\n\n\nB02598,2015-01-18 14:03:01,B02598,37\n\n\nWe already looked at using \nsort\n with \nfields\n and the \n-k\n flag. Let's try it\nhere:\n\n\nWe're going to \ncat\n all of \ntest.csv\n, pipe that into \nsort\n and then use the\n\n-k2\n flag, which will sort the lines of \ntest.csv\n based on the first character\nof the \nsecond\n field/column.\n\n\n$ cat test.csv | sort -k2 | less\n\n\n\n\nThat... didn't work. The default field delimiter in \nsort\n is whitespace, so the\nprevious command sorted everything based on pickup time, but ignored pickup\ndate.\n\n\nHow can we change the delimiter character that \nsort\n uses? Let's check the\n\nman\n page.\n\n\n$ man sort\n\n\n\n\n$ cat test.csv | sort -t \",\" -k2 | less\n\n\n\n\n$ cat test.csv | sort -t \",\" -k2 > test_sort.csv\n\n\n\n\n$ head test_sort.csv\n\n\n\n\nB02598,2015-01-18 00:02:54,,144\n\nB02598,2015-01-18 00:05:05,B02598,50\n\nB02598,2015-01-18 00:06:19,B02598,107\n\nB02598,2015-01-18 00:08:14,B02598,142\n\nB02598,2015-01-18 00:16:58,B02598,107\n\nB02598,2015-01-18 00:30:59,B02598,50\n\nB02598,2015-01-18 00:36:16,B02598,211\n\nB02598,2015-01-18 00:37:16,B02774,141\n\nB02598,2015-01-18 00:45:16,,48\n\nB02598,2015-01-18 00:47:08,B02617,68",
            "title": "Uber exercise"
        },
        {
            "location": "/nix/uber/#uber-example",
            "text": "Download and unzip file from here:  Should have folder  uber-trip-data .   cd  to that directory and take a look.  $ cd uber-trip-data/  $ ls  taxi-zone-lookup.csv     uber-raw-data-janjune-15.csv.zip  uber-raw-data-may14.csv\nuber-raw-data-apr14.csv  uber-raw-data-jul14.csv           uber-raw-data-sep14.csv\nuber-raw-data-aug14.csv  uber-raw-data-jun14.csv  We have several raw data files (so named).  csv  files divided by month and also\na zip file. We'll leave the zip file alone for the moment. What questions can we\nanswer about this dataset from the command line?  First, it would help to know what these files contain. We can use  head  to\ndisplay the first ten lines of one of the raw files.  $ head uber-raw-data-apr14.csv  \"Date/Time\",\"Lat\",\"Lon\",\"Base\"\n\"4/1/2014 0:11:00\",40.769,-73.9549,\"B02512\"\n\"4/1/2014 0:17:00\",40.7267,-74.0345,\"B02512\"\n\"4/1/2014 0:21:00\",40.7316,-73.9873,\"B02512\"\n\"4/1/2014 0:28:00\",40.7588,-73.9776,\"B02512\"\n\"4/1/2014 0:33:00\",40.7594,-73.9722,\"B02512\"\n\"4/1/2014 0:33:00\",40.7383,-74.0403,\"B02512\"\n\"4/1/2014 0:39:00\",40.7223,-73.9887,\"B02512\"\n\"4/1/2014 0:45:00\",40.762,-73.979,\"B02512\"\n\"4/1/2014 0:55:00\",40.7524,-73.996,\"B02512\"  They weren't kidding when they said \"raw\" data. What do we have here? Looks like\na date and time (these are pickup times), the lat-long of the pickup location\nand some \"Base\" id that we don't care about right now.  What can we take away from this?  For one, that the number of lines in this file is how many pickups Uber made\nduring the month of April, 2014. That sounds like interesting information. We\ncan use  wc  or  wordcount  to count the number of  lines  in a file by using\nthe  -l  flag.  $ wc -l uber-raw-data-apr14.csv  564517 uber-raw-data-apr14.csv  We know now that Uber provided more than half a million rides in New York City\nin April of 2014. Let's take a look at how that figure changes month-to-month!  We can run the same  wc  command but now use the  *  wildcard to get the\nlinecount of every file in the directory.  $ wc -l *          0 taxi-zone-lookup.csv\n   564517 uber-raw-data-apr14.csv\n   829276 uber-raw-data-aug14.csv\n   284595 uber-raw-data-janjune-15.csv.zip\n   796122 uber-raw-data-jul14.csv\n   663845 uber-raw-data-jun14.csv\n   652436 uber-raw-data-may14.csv\n  1028137 uber-raw-data-sep14.csv\n  4818928 total  Cool, but the linecount of a zip file doesn't really make any sense. To be a\nlittle more specific, restrict  wc  to only look at  csv  files.  $ wc -l *.csv          0 taxi-zone-lookup.csv\n   564517 uber-raw-data-apr14.csv\n   829276 uber-raw-data-aug14.csv\n   796122 uber-raw-data-jul14.csv\n   663845 uber-raw-data-jun14.csv\n   652436 uber-raw-data-may14.csv\n  1028137 uber-raw-data-sep14.csv\n  4534333 total  Better.  wc  outputs files in the order it gets them, which in this case is the\norder they exist in the directory. And that's alphabetical order. The names of\nmonths aren't hugely useful when sorting alphabetically.  Let's use the  sort  command to sort the results from  wc . We can pipe the\noutput of  wc  to  sort  using the  |  character. Remember, the pipe takes the\noutput from the previous command and hands it off to the following command.  $ wc -l *.csv | sort          0 taxi-zone-lookup.csv\n  1028137 uber-raw-data-sep14.csv\n  4534333 total\n   564517 uber-raw-data-apr14.csv\n   652436 uber-raw-data-may14.csv\n   663845 uber-raw-data-jun14.csv\n   796122 uber-raw-data-jul14.csv\n   829276 uber-raw-data-aug14.csv  Hmmm.  That looks a little funny.  Can you see what  sort  did?  Yeah, it sorted things alphanumerically, which isn't helpful since it only looks\nat leading digits. We want to use the number of lines in each file as the\nsorting criteria.  To do this, we can use the  -n  flag with  sort  to specify a \"numerical\" sort.  This may start to look a little confusing, but remember, we're just building up\na command using smaller commands. We use the  -l  flag with  wc  to count the\nnumber of lines, then pipe that output to  sort  where we use the  -n  flag to\nrequire numerical sorting.  $ wc -l *.csv | sort -n          0 taxi-zone-lookup.csv\n   564517 uber-raw-data-apr14.csv\n   652436 uber-raw-data-may14.csv\n   663845 uber-raw-data-jun14.csv\n   796122 uber-raw-data-jul14.csv\n   829276 uber-raw-data-aug14.csv\n  1028137 uber-raw-data-sep14.csv\n  4534333 total  Ok! Now we have the raw data files sorted by number of lines, which we know is\nequivalent to number of rides. And look, now the months are in the correct\norder. That wasn't necessarily expected, but looking at this output we can see\nthat Uber is expanding at a pretty fast pace in 2014; they nearly doubled their\nusage numbers in 5 months!  This data set is missing the last quarter of 2014, but we have the first half of\n2015 available, so we can check if the trend continues (is there a ceiling for\nUber requests in NYC?)  First, unzip the file containing the 2015 data.  $ unzip uber-raw-data-janjune-15.csv.zip  Archive:  uber-raw-data-janjune-15.csv.zip\n  inflating: uber-raw-data-janjune-15.csv\n   creating: __MACOSX/\n  inflating: __MACOSX/._uber-raw-data-janjune-15.csv  Now we know that whoever created this zip file uses a Mac. But that's not really\nimportant. Let's take another look at the line counts.  $ wc -l *.csv | sort -n          0 taxi-zone-lookup.csv\n   564517 uber-raw-data-apr14.csv\n   652436 uber-raw-data-may14.csv\n   663845 uber-raw-data-jun14.csv\n   796122 uber-raw-data-jul14.csv\n   829276 uber-raw-data-aug14.csv\n  1028137 uber-raw-data-sep14.csv\n 14270480 uber-raw-data-janjune-15.csv\n 18804813 total  Wow! 14+ million rides! Impressive! But this data layout is different from the\n2014 data. The six months are all in the same file. Not cool. So what now?  First, let's see what the data looks like in the combined file.  $ head uber-raw-data-janjune-15.csv  Dispatching_base_num,Pickup_date,Affiliated_base_num,locationID\nB02617,2015-05-17 09:47:00,B02617,141\nB02617,2015-05-17 09:47:00,B02617,65\nB02617,2015-05-17 09:47:00,B02617,100\nB02617,2015-05-17 09:47:00,B02774,80\nB02617,2015-05-17 09:47:00,B02617,90\nB02617,2015-05-17 09:47:00,B02617,228\nB02617,2015-05-17 09:47:00,B02617,7\nB02617,2015-05-17 09:47:00,B02764,74\nB02617,2015-05-17 09:47:00,B02617,249  Very uncool. First, the data is in a different format than the previous files we\nlooked at. Worse, the first pickup listed is in May? Either the file is\nmislabeled (bad) or it isn't even sorted (bad).  Let's look at a few more lines to see if we can figure out which bad scenario we\nhave.  We can use  tail  to peek at the  last  10 lines in the file. How do those look?  $ tail uber-raw-data-janjune-15.csv  B02765,2015-05-08 15:42:00,B02764,79\nB02765,2015-05-08 15:42:00,B02765,37\nB02765,2015-05-08 15:42:00,B02765,161\nB02765,2015-05-08 15:42:00,B02765,7\nB02765,2015-05-08 15:43:00,B02711,25\nB02765,2015-05-08 15:43:00,B02765,186\nB02765,2015-05-08 15:43:00,B02765,263\nB02765,2015-05-08 15:43:00,B02765,90\nB02765,2015-05-08 15:44:00,B01899,45\nB02765,2015-05-08 15:44:00,B02682,144  Not looking good.  Is this all just in May?  Let's look through a larger number of lines using  head  and see if we can find a ride that wasn't in May.  Use the  -n  flag with  head  to specify the number of lines to show (the default is 10).  $ head -n 500 uber-raw-data-janjune-15.csv  [snip]\nB02598,2015-01-18 11:06:58,B02598,7\nB02598,2015-01-18 18:55:46,B02598,141\nB02598,2015-01-18 14:54:28,B02598,249\nB02598,2015-01-18 20:48:57,B02598,90\nB02598,2015-01-18 09:28:20,B02682,234\nB02598,2015-01-18 19:31:14,B02764,13\nB02598,2015-01-18 14:13:38,B02598,163\nB02598,2015-01-18 22:53:57,B02598,90\nB02598,2015-01-18 19:13:00,B02617,246\nB02598,2015-01-18 14:53:36,B02598,161\nB02598,2015-01-18 02:37:00,B02598,114\nB02598,2015-01-18 18:47:01,B02598,113\nB02598,2015-01-18 16:06:11,B02598,233\nB02598,2015-01-18 15:36:12,B02598,162\nB02598,2015-01-18 02:10:39,B02598,50\nB02598,2015-01-18 12:18:57,B02764,142\nB02598,2015-01-18 14:03:01,B02598,37  Ok. 500 lines in, we can see some January pickups. It looks like we have bad\noption #2. The data is labeled correctly but isn't sorted. Time to sort it!  Sorting can be expensive, so rather than trying to sort the whole file at once,\nlet's copy a portion of the big file into a separate file.  Use the same  head  command we just used, but now, instead of writing it to the\nscreen, we can  redirect  that output to another file using  > . We'll just call\nthat file  test.csv .  $ head -n 500 uber-raw-data-janjune-15.csv > test.csv  Now it's time to figure out how to sort this data. We can use  sort  the way we\ndid with  wc  because the information we want to use as the sort key (the date\nand time) are embedded in the middle of every line.  Here's one line from  test.csv :  B02598,2015-01-18 14:03:01,B02598,37  We already looked at using  sort  with  fields  and the  -k  flag. Let's try it\nhere:  We're going to  cat  all of  test.csv , pipe that into  sort  and then use the -k2  flag, which will sort the lines of  test.csv  based on the first character\nof the  second  field/column.  $ cat test.csv | sort -k2 | less  That... didn't work. The default field delimiter in  sort  is whitespace, so the\nprevious command sorted everything based on pickup time, but ignored pickup\ndate.  How can we change the delimiter character that  sort  uses? Let's check the man  page.  $ man sort  $ cat test.csv | sort -t \",\" -k2 | less  $ cat test.csv | sort -t \",\" -k2 > test_sort.csv  $ head test_sort.csv  B02598,2015-01-18 00:02:54,,144\n\nB02598,2015-01-18 00:05:05,B02598,50\n\nB02598,2015-01-18 00:06:19,B02598,107\n\nB02598,2015-01-18 00:08:14,B02598,142\n\nB02598,2015-01-18 00:16:58,B02598,107\n\nB02598,2015-01-18 00:30:59,B02598,50\n\nB02598,2015-01-18 00:36:16,B02598,211\n\nB02598,2015-01-18 00:37:16,B02774,141\n\nB02598,2015-01-18 00:45:16,,48\n\nB02598,2015-01-18 00:47:08,B02617,68",
            "title": "uber example"
        },
        {
            "location": "/python/",
            "text": "Python (IPython)\n\n\nPython is a dynamic and high-level language that is easy to learn and fun to use. \n\n\nThe classic Hello World program is as simple as:\n\n\nprint(\"Hello World!!\")\n\n\nPython itself is an \ninterpreter\n, it translates Python \nsource code\n into\ninstructions that the computer can understand. It's a dynamic language (duck\ntyping), i.e you don't need a type to invoke an existing method on an object.\n\n\n\"If it looks like a duck, swims like a duck, and quacks like a duck, then it\nprobably is a duck.\"\n\n\nIf you come from different languages you probably code by doing scripts, with\nPython we can do the same but we have other tools that allows us to work\ninteractively.\n\n\nLet's work with one of these tools (IPython).\n\n\nType in a terminal :\n\n\nipython\n\n\nPython is awesome!\n\n\nimport this \nimport antigravity\n\n\n\n\nVariable assignment, types and  duck typing\n\n\nIn Python is perfectly legal to do:\n\n\nIn [1]: x = 3\n\n\n\n\nTry:\n\n\nIn [2]: x\nOut[2]: 3\n\n\n\n\nIn [3]: print(x)\n3\n\n\n\n\nIn [4]: type(x)\nOut[4]: int\n\n\n\n\nIn [5]: float(x)\nOut[5]: 3.0\n\n\n\n\nIn [6]: complex(x)\nOut[6]: (3+0j)\n\n\n\n\nIn [7]: z = complex(x)\nIn [8]: z = z + 1j\nIn [9]: print(z)\n(3+1j)\n\n\n\n\nRegular arithmetic symbols are preserved except for the \"power\" operator.\n\n\nFor example, raising \nx\n to the power of 2 would be:\n\n\nx**2\n\n\nWhat about strings?\n\n\nIn [9]: y = \"hello\"\n\nIn [10]: y\nOut[10]: 'hello'\n\nIn [11]: print(y)\nhello\n\nIn [12]: type(y)\nOut[12]: str\n\nIn [13]: s = \"world\"\n\n\n\n\nWhat if we try to \"sum\" strings? \n\n\nIn [14]: my_string = y+s\n\nIn [15]: print(my_string)\nhelloworld\n\n\n\n\nLet's add a space in between:\n\n\nIn [16]: my_string = y +' '+ s\n\nIn [17]: print(my_string)\nhello world\n\n\n\n\nWe can access the different elements of a string and slices of it, for example:\n\n\nIn [18]: my_string[0]\nOut[18]: 'h'\n\nIn [19]: my_string[8]\nOut[19]: 'r'\n\nIn [20]: my_string[-1]\nOut[20]: 'd'\n\nIn [21]: my_string[2:5]\nOut[21]: 'llo'\n\nIn [22]: my_string[2:]\nOut[22]: 'llo world'\n\nIn [23]: my_string[1:-1]\nOut[23]: 'ello worl'\n\n\n\n\n Note that the start index is inclusive and the end one is exclusive!!\n\n\nSlices also allow us to pick specific elements from specific slices, for example:\n\n\nIn [24]: my_string[::2]\nOut[24]: 'hlowrd'\n\nIn [25]: my_string[1:-1:2]\nOut[25]: 'el ol'\n\nIn [26]: my_string[2::3]\nOut[26]: 'l r'\n\nIn [27]: my_string[::-1]\nOut[27]: 'dlrow olleh'\n\n\n\n\n\nStrings have different methods that we can apply to them, for example:\n\n\nMake all uppercase:\n\n\nIn [28]: my_string.upper()\nOut[28]: 'HELLO WORLD'\n\n\n\n\nFind where a character is or starts:\n\n\nIn [29]: my_string.find('hello')\nOut[29]: 0\n\nIn [30]: my_string.find('l')\nOut[30]: 2\n\n\n\n\nIf you want to know all of the available methods for a certain object, there is\na simple command that will give you that information:\n\n\ndir(my_string)\n\n\nSpecial variables\n\n\nPython has special variables that are built into the language: namely \nTrue\n,\n\nFalse\n, \nNone\n and \nNotImplemented\n.\n\n\nBoolean variables\n\n\nTrue\n and \nFalse\n.\n\n\nIn general, if the value is zero or empty, then it's converted to \nFalse\n.\nOtherwise, it'll be converted to \nTrue\n.\n\n\nIn [31]: bool(0)\nOut[31]: False\n\nIn [32]: bool(\"Do we need oxygen?\")\nOut[32]: True\n\n\n\n\nIt also applies to logic statements, for example:\n\n\nIn [33]: x = 3\nIn [34]: y = 5\nIn [35]: z = x > y\n\nIn [36]: z\nOut[36]: False\n\nIn [37]: type(z)\nOut[37]: bool\n\n\n\n\n\nNone is not Zero\n\n\nIt is used to indicate that no value was given or that the behavior was\nundefined. This is different than zero, an empty string, or some other nil\nvalue.\n\n\nNotImplemented is not None\n\n\nNotImplemented\n is used to indicate that a behavior is not defined or that the\naction we are trying to execute is impossible. For example, \nNotImplemented\n is\nused under the covers when you try to divide a string by a float. We will end up\nwith a \nTypeError\n. (Try it on the shell)\n\n\nImportant notes\n:\n\n\n\n\n\n\nVariables names can be upper- or lower-case letters, and we can put digits\n  (0-9) and underscores. However, they can not start with a digit.\n\n\n\n\n\n\nThere are reserved words you can't use and you can find them in\n  this \nlink\n\n\n\n\n\n\nVariables are mutable.\n\n\n\n\n\n\nStandard data types: Numerical, String, \nList\n, Tuple, Dictionaries. (list\n  are the default in Python)\n\n\n\n\n\n\nNumerical types: \nint\n, \nlong\n (long integers), \nfloat\n and \ncomplex\n.\n\n\n\n\n\n\nData structures\n\n\nLists, dictionaries and tuples are kinds of \nCollections\n\n\n\n\nA \ncollection\n allows us to put many values in a single \"variable\".\n\n\nThey are convenient because we can carry many values around in one\n  convenient package.\n\n\nSimple variables are not collections.\n\n\n\n\nLists\n\n\n\n\nThe beginning and end of a list is denoted by square brackets \n[]\n and its\n  elements are separated by commas.\n\n\nA list element can be any Python object, even another list.\n\n\nList are MUTABLE, strings are NOT MUTABLE. (Note: there is a method called\n  replace for strings but it creates a copy)\n\n\n\n\nIn [38]: my_list = [2, 50, 4, 61]\nIn [39]: print(my_list)\n[2, 50, 4, 61]\n\nIn [40]: my_list[1] = 1\n\nIn [41]: print(my_list)\n[2, 1, 4, 61]                 #Now we have a 1 instead of a 50 in the second place.\n\n\n\n\n\n\n\n\nlen()\n function gives us the number of elements in the list.\n\n\n\n\n\n\nWe can \nconcatenate\n lists by using the operator \n+\n: \n\n\n\n\n\n\nIn [42]: lst1 = [0,1,2,3]\n\nIn [43]: lst2 = ['a','b','c']\n\nIn [44]: conc = lst1 + lst2\n\nIn [45]: print(conc)\n[0, 1, 2, 3, 'a', 'b', 'c']\n\n\n\n\n\n\n\nThere are different methods to apply to a list (check them by typing\n  \ndir(lst1)\n), an example is \nappend()\n.\n\n\n\n\nIn [46]: lst1.append(4)\n\nIn [47]: print(lst1)\n[0, 1, 2, 3, 4]\n\nIn [48]: lst1.append('five')\n\nIn [49]: lst1\nOut[49]: [0, 1, 2, 3, 4, 'five']\n\nIn [50]: lst1.append([6, 7, 8])\n\nIn [51]: lst1\nOut[51]: [0, 1, 2, 3, 4, 'five', [6, 7, 8]]\n\n\n\n\n\n\nSimilar to strings we can access elements of a list by doing \nlist[i]\n and\n  also we can do slices.\n\n\n\n\nIn [52]: lst1[-1]\nOut[52]: [6, 7, 8]\n\nIn [53]: lst1[5:]\nOut[53]: ['five', [6, 7, 8]]\n\n\n\n\n\n\nWe can check if something is or not in a list.\n\n\n\n\nIn [54]: my_numbers = [3, 17, 27, 19]\n\nIn [55]: 17 in my_numbers\nOut[55]: True\n\nIn [56]: 2 in my_numbers\nOut[56]: False\n\nIn [57]: 13 not in my_numbers\nOut[57]: True\n\n\n\n\nNote: This operators does NOT modify the list.\n\n\n\n\nA \nlist\n is an ordered sequence. We can change the order by sorting the list. \n\n\n\n\nIn [58]: names = ['Naty', 'Gil', 'Lorena', 'Chris']\n\nIn [59]: names.sort()\n\nIn [60]: print(names)\n['Chris', 'Gil', 'Lorena', 'Naty']\n\n\n\n\n\n\nStrings\n and \nlists\n. The \nsplit()\n function.\n\n\n\n\nIn [61]: string = 'Just three words'\n\nIn [62]: str_list = string.split()\n\nIn [63]: print(str_list)\n['Just', 'three', 'words']\n\n\n\n\nPython takes care of long spaces, for example:\n\n\nIn [64]: line = 'A lot of       space'\n\nIn [65]: stuff = line.split()\n\nIn [66]: print(stuff)\n['A', 'lot', 'of', 'space']\n\n\n\n\nIf we specify the delimiter (it can be a space \n' '\n, a \n;\n, a \n:\n, whatever you want).\n\n\nIn [67]: line = 'A lot of       space'\n\nIn [68]: stuff = line.split(' ')\n\nIn [69]: print(stuff)\n['A', 'lot', 'of', '', '', '', '', '', '', 'space']\n\n\n\n\n;\n and many other characters are not delimiters by default:\n\n\nIn [70]: s = 'a;b;c'\n\nIn [71]: thing  = s.split()\n\nIn [72]: print(thing)\na;b;c\n\nIn [73]: thing = s.split(';')\n\nIn [74]: print(thing)\n['a', 'b', 'c']\n\n\n\n\nDictionaries\n\n\n\n\nDictionaries are also a type of collections and they are MUTABLE too. \n\n\n\n\nDifference between lists and dictionaries:\n\n\n\n\nList: a linear collection of values that stay in order.\n\n\nDictionary: A \"bag\" of values, each with it's own label (key).\n\n\nDictionaries don't maintain order, we index the the things we put in the\n  dictionary with a \"look up\" tag. For example:\n\n\n\n\nIn [75]: bag = {}\n\nIn [76]: bag['money'] = 12\n\nIn [77]: bag['candy'] = 5 \n\nIn [78]: bag['tissues'] = 7 \n\nIn [79]: print(bag)\n{'tissues': 7, 'money': 12, 'candy': 5}\n\nIn [80]: print(bag['money'])\n12\n\nIn [81]: bag['money'] += 2\n\nIn [82]: print(bag)\n{'tissues': 7, 'money': 14, 'candy': 5}\n\n\n\n\n\n\n\nWe can use the operators \nin\n and \nnot in\n to check if a key is or not in a\n  dictionary.\n\n\n\n\nIn [83]: 'book' in bag\nOut[83]: False\n\nIn [84]: 'candy' in bag\nOut[84]: True\n\nIn [85]: 'cigarette' not in bag\nOut[85]: True\n\n\n\n\n\n\nRetrieving keys and values.\n\n\n\n\nIn [86]: ages = {'John': 30, 'Maria': 28, 'Lucas': 23}\n\nIn [87]: print(ages.keys())\ndict_keys(['Maria', 'Lucas', 'John'])\n\nIn [88]: print(ages.values())\ndict_values([28, 23, 30])\n\n\n\n\nNote\n: If we don't change the dictionary in between these operations, the keys\nand values are displayed in order.\n\n\n\n\nWe can get a list with pairs (key, value) by doing:\n\n\n\n\nIn [89]: print(ages.items())\ndict_items([('Maria', 28), ('Lucas', 23), ('John', 30)])\n\n\n\n\n\n\nDictionaries are good for counting how often we \"see\" something. \n\n\n\n\nThere are another two built in data structures: tuples and sets. You can read\nabout them in the\nPython\n\ndocumentation\n.\n\n\nA quick insight into them:\n\n\n\n\nTuples\n are like lists but they are IMMUTABLE, which saves time in\n  accessing memory. (Syntax \n(element1, element2, ...)\n)\n\n\nSets\n are collections that have no order, no duplicate elements and their\n  elements are \nhashable\n\n  which saves time when accessing memory. We can do operations like union,\n  intersection, difference, and symmetric difference. (Syntax \n{element1,\n  element2, ...}\n and an empty set is created by doing \nset()\n)\n\n\n\n\n Example: look for an element in a list and in a set (%timeit)\n\n\nIn [90]: rg = range(50000)\n\nIn [91]: lst = list(rg)\n\nIn [92]: %time (40035 in lst)\nCPU times: user 4 ms, sys: 0 ns, total: 4 ms\nWall time: 1.91 ms\nOut[92]: True\n\nIn [93]: st = set(rg)\n\nIn [94]: %time (40035 in st)\nCPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 14.3 \u00b5s\nOut[94]: True\n\nIn [95]: %time (51000 in lst)\nCPU times: user 4 ms, sys: 0 ns, total: 4 ms\nWall time: 2.36 ms\nOut[95]: False\n\nIn [96]: %time (51000 in st)\nCPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 12.9 \u00b5s\nOut[96]: False\n\n\n\n\nControl Flow\n\n\nConditionals\n\n\nThe syntax is \"If \nx\n true, then do something; otherwise, do something else.\"\n\n\nIf\n statement on its own:\n\n\nIn [97]: a = 8\n\nIn [98]: b = 3 \n\nIn [99]: if a > b :\n    ...:     print('a is bigger than b')\n    ...:\na is bigger than b\n\n\n\n\nIf-else\n statement: \n\n\nIn [100]: x = float(input('Insert your number: '))\nInsert your number: 711457\n\nIn [101]: if x % 17 == 0:\n     ...:     print('Your number is a multiple of 17.')\n     ...: else :\n     ...:     print('Your number is not a multiple of 17.')\n\nYour number is not a multiple of 17.\n\n\n\n\nIf-elif-else\n statement:\n\n\nIn [102]: a = 3\n\nIn [103]: b = 5\n\nIn [104]: if a > b:\n     ...:     print('a is bigger than b.')\n     ...: elif a < b:\n     ...:     print('a is smaller than b.')\n     ...: else:\n     ...:     print('a is equal to b.')\n     ...:\na is smaller than b.\n\n\n\n\nNote:\n We can have as many \nelif\n as we want.\n\n\nLoops\n\n\nLoops are useful for executing the same block multiple times. In Python we have\nmultiple looping formats: \nwhile\n loops, \nfor\n loops, and comprehensions.\n\n\nWhile loops\n\n\nThey are related to an \nif\n statement, they will compute \nwhile\n a condition is true.\n\n\nIn [105]: sec = 5\nIn [106]: while 0 < sec :\n     ...:     print('You have {} seconds'.format(sec))\n     ...:     sec -= 1\n     ...: print('Boom!!!')\n    ...:\nYou have 5 seconds\nYou have 4 seconds\nYou have 3 seconds\nYou have 2 seconds\nYou have 1 seconds\nBoom!!!\n\n\n\n\nNote:\n You have to be careful to not generate an infinite loop. \n\n\nFor loops\n\nIt is usually more useful to iterate over a certain group of things or an \"iterable\".\n\n\nIn [107]: for i in range(5,0,-1):\n    ...:     print('You have {} seconds'.format(i))\n    ...: print('Boom!!!')\n    ...: \nYou have 5 seconds\nYou have 4 seconds\nYou have 3 seconds\nYou have 2 seconds\nYou have 1 seconds\nBoom!!!\n\n\n\n\nAnother example:\n\n\nIn [108]: name = input('Insert your name: ')\nInsert your name: Naty\n\nIn [109]: name\nOut[109]: 'Naty'\n\nIn [110]: count = 1\n\nIn [111]: for letter in name:\n    ...:     print('The {} letter is {}'.format(count,letter))\n    ...:     count +=1\n    ...:\nThe 1 letter is N\nThe 2 letter is a\nThe 3 letter is t\nThe 4 letter is y\n\n\n\n\nWe can loop over dictionaries too:\n\n\nIn [112]: d = {\"name\":\"Lionel\", \"last_name\": \"Messi\", \"birthday\": [6, 24, 1987]}\n\nIn [113]: for item in d.items():\n     ...:     print(item)\n     ...:\n('birthday', [6, 24, 1987])\n('name', 'Lionel')\n('last_name', 'Messi')\n\nIn [114]: for key, value in d.items():\n     ...:     print(key, value)\n     ...:\nbirthday [6, 24, 1987]\nname Lionel\nlast_name Messi\n\n\n\n\nComprehensions\n\n\nfor\n and \nwhile\n loops are really useful but they take at least \"two lines\",\nand if you need to save the result of each loop in the iteration in a list, set,\netc. This takes at least \"three lines\". Thankfully, Python is so great that in\nsome cases we can reduce these cases to just ONE line! Let's see this with an\nexample:\n\n\nNormal loop:\n\n\nIn [114]: fruits = ['apple', 'orange', 'grape', 'banana', 'pineapple', 'strawberry', 'watermelon']\n\nIn [115]: upper_fruits = []\n\nIn [116]: for fruit in fruits:\n    ...:     upper_fruits.append(fruit.upper())\n\nIn [117]: upper_fruits\nOut[117]: ['APPLE', 'ORANGE', 'GRAPE', 'BANANA', 'PINEAPPLE', 'STRAWBERRY', 'WATERMELON']\n\n\n\n\nPythonic way:\n\n\nIn [118]: upper_pythonic = [fruit.upper() for fruit in fruits]\n\nIn [119]: upper_pythonic\nOut[119]: ['APPLE', 'ORANGE', 'GRAPE', 'BANANA', 'PINEAPPLE', 'STRAWBERRY', 'WATERMELON']\n\n\n\n\nWe can add a filter, for example:\n\n\nIn [120]: entries = [2, 11, 49, 3, 57, 33, 9]\n\nIn [121]: entries\nOut[121]: [2, 11, 49, 3, 57, 33, 9]\n\nIn [122]: some = [x**2 for x in entries if x%3==0]\n\nIn [123]: some\nOut[123]: [9, 3249, 1089, 81]\n\nIn [124]: orig = [int(x**(1/2)) for x in some]\n\nIn [125]: orig\nOut[125]: [3, 57, 33, 9]\n\n\n\n\nIPython Magics\n\n\nSometimes when we are working on IPython we would like to select certain lines\nand save them into a Python script. We can do that!\n\n\nWe can check the history of what we've done in the current session of IPython by\ntyping:\n\n\n%hist -n\n\n\nIf we want to select certain lines and put them into a script, the command\n\n%edit\n allow us to do this. Let's suppose we want lines 1, 3 and from 5-10; \nthen we should do:\n\n\n%edit 1 3 5-10\n\n\nand this will open the default editor with the lines we want. \n\n\nOnce we have that script saved if we want to run it we can use the command\n\n%run\n:\n\n\n%run my_script.py\n\n\nExercises\n\n\nSlicing\n \n\n\n1- Write code using \nfind()\n and string slicing to extract the number at the end\nof the line below. Convert the extracted value to a floating point number and\nprint it out. (Content taken from online course \"Python Data Structures\" by Dr.\nCharles Severance)\n\n\ntext = \"X-DSPAM-Confidence:    0.8475\"\n\n\n\n\nSolution:\n\n\nsolu\n\n\nSlicing and for loop\n \n\n\n2- Write a code that grabs, from each word, all the letters except 'ball' at the\nend of each one. Save the output in a list and print it out.\n\n\nThe original list is:\n\n\nsports = ['Football', 'Volleyball', 'Basketball', 'Baseball', 'Handball', 'Softball']\n\n\n\n\nAnd your output should look like:\n\n\n['Foot', 'Volley', 'Basket', 'Base', 'Hand', 'Soft']\n\n\n\n\nSolution\n:\n\n\nIn [131]: sports = ['Football', 'Volleyball', 'Basketball', 'Baseball', 'Handball', 'Softball']\n\nIn [132]: random = []\n\nIn [133]: for sport in sports:\n     ...:     word = sport[:-4]\n     ...:     random.append(word)\n     ...:\n\nIn [134]: print(random)\n['Foot', 'Volley', 'Basket', 'Base', 'Hand', 'Soft']\n\n\n\n\n\nDictionaries for counting\n\n\n3- Write a code that counts the frequency of each word that we have in the\nphrase provided.\n\n\nTips: split the text and put the words in a list, use a dictionary to count the\nrepetitions.\n\n\n(The idea of the following two exercises was inspired by content from the online\ncourse \"Python Data Structures\" by Dr. Charles Severance)\n\n\nhappy = \"I felt happy because I saw the others were happy and because I knew I should feel happy but I was not really happy\"\n\n\n\n\nYour output should look like:\n\n\n{'happy': 4, 'really': 1, 'and': 1, 'feel': 1, 'others': 1, 'felt': 1, 'not': 1, 'the': 1, 'should': 1, 'knew': 1, 'was': 1, 'saw': 1, 'I': 5, 'but': 1, 'were': 1, 'because': 2}\n\n\n\n\nRemember that dictionaries don't preserve order, therefore the items in your\noutput might be in a different order. However, you can still check if your\noutput is equal to the one we provide by doing a logical comparison using the\n\n==\n operation, which should return \nTrue\n if you get it right.\n\n\nOptional\n: Rewrite exercise 3 using the method \nget()\n. \n\n\nSolution\n\n\nIn [135]: happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy\n    ...:  but I was not really happy\"\n\nIn [136]: words = happy.split()\n\nIn [137]: counts = {}\n\nIn [138]: for word in words:\n     ...:     if word not in counts:\n     ...:         counts[word] = 1\n     ...:     else:\n     ...:         counts[word] += 1\n     ...: \n\nIn [139]: print(counts)\n{'happy': 4, 'really': 1, 'and': 1, 'feel': 1, 'others': 1, 'felt': 1, 'not': 1, 'the': 1, 'should': 1, 'knew': 1, 'was': 1, 'saw': 1, 'I': 5, 'but': 1, 'were': 1, 'because': 2}\n\n\n\n\n\nSolution using \nget()\n\n\nIn [140]: happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy\n    ...:  but I was not really happy\"\n\nIn [141]: words = happy.split()\n\nIn [142]: counts = {}\nIn [143]: for word in words:\n     ...:     counts[word] = counts.get(word, 0) +1 \n     ...:\n\nIn [144]: print(counts)\n{'happy': 4, 'really': 1, 'and': 1, 'feel': 1, 'others': 1, 'felt': 1, 'not': 1, 'the': 1, 'should': 1, 'knew': 1, 'was': 1, 'saw': 1, 'I': 5, 'but': 1, 'were': 1, 'because': 2}",
            "title": "Python"
        },
        {
            "location": "/python/#python-ipython",
            "text": "Python is a dynamic and high-level language that is easy to learn and fun to use.   The classic Hello World program is as simple as:  print(\"Hello World!!\")  Python itself is an  interpreter , it translates Python  source code  into\ninstructions that the computer can understand. It's a dynamic language (duck\ntyping), i.e you don't need a type to invoke an existing method on an object.  \"If it looks like a duck, swims like a duck, and quacks like a duck, then it\nprobably is a duck.\"  If you come from different languages you probably code by doing scripts, with\nPython we can do the same but we have other tools that allows us to work\ninteractively.  Let's work with one of these tools (IPython).  Type in a terminal :  ipython",
            "title": "Python (IPython)"
        },
        {
            "location": "/python/#python-is-awesome",
            "text": "import this \nimport antigravity",
            "title": "Python is awesome!"
        },
        {
            "location": "/python/#variable-assignment-types-and-duck-typing",
            "text": "In Python is perfectly legal to do:  In [1]: x = 3  Try:  In [2]: x\nOut[2]: 3  In [3]: print(x)\n3  In [4]: type(x)\nOut[4]: int  In [5]: float(x)\nOut[5]: 3.0  In [6]: complex(x)\nOut[6]: (3+0j)  In [7]: z = complex(x)\nIn [8]: z = z + 1j\nIn [9]: print(z)\n(3+1j)  Regular arithmetic symbols are preserved except for the \"power\" operator.  For example, raising  x  to the power of 2 would be:  x**2",
            "title": "Variable assignment, types and  duck typing"
        },
        {
            "location": "/python/#what-about-strings",
            "text": "In [9]: y = \"hello\"\n\nIn [10]: y\nOut[10]: 'hello'\n\nIn [11]: print(y)\nhello\n\nIn [12]: type(y)\nOut[12]: str\n\nIn [13]: s = \"world\"  What if we try to \"sum\" strings?   In [14]: my_string = y+s\n\nIn [15]: print(my_string)\nhelloworld  Let's add a space in between:  In [16]: my_string = y +' '+ s\n\nIn [17]: print(my_string)\nhello world  We can access the different elements of a string and slices of it, for example:  In [18]: my_string[0]\nOut[18]: 'h'\n\nIn [19]: my_string[8]\nOut[19]: 'r'\n\nIn [20]: my_string[-1]\nOut[20]: 'd'\n\nIn [21]: my_string[2:5]\nOut[21]: 'llo'\n\nIn [22]: my_string[2:]\nOut[22]: 'llo world'\n\nIn [23]: my_string[1:-1]\nOut[23]: 'ello worl'   Note that the start index is inclusive and the end one is exclusive!!  Slices also allow us to pick specific elements from specific slices, for example:  In [24]: my_string[::2]\nOut[24]: 'hlowrd'\n\nIn [25]: my_string[1:-1:2]\nOut[25]: 'el ol'\n\nIn [26]: my_string[2::3]\nOut[26]: 'l r'\n\nIn [27]: my_string[::-1]\nOut[27]: 'dlrow olleh'  Strings have different methods that we can apply to them, for example:  Make all uppercase:  In [28]: my_string.upper()\nOut[28]: 'HELLO WORLD'  Find where a character is or starts:  In [29]: my_string.find('hello')\nOut[29]: 0\n\nIn [30]: my_string.find('l')\nOut[30]: 2  If you want to know all of the available methods for a certain object, there is\na simple command that will give you that information:  dir(my_string)",
            "title": "What about strings?"
        },
        {
            "location": "/python/#special-variables",
            "text": "Python has special variables that are built into the language: namely  True , False ,  None  and  NotImplemented .  Boolean variables  True  and  False .  In general, if the value is zero or empty, then it's converted to  False .\nOtherwise, it'll be converted to  True .  In [31]: bool(0)\nOut[31]: False\n\nIn [32]: bool(\"Do we need oxygen?\")\nOut[32]: True  It also applies to logic statements, for example:  In [33]: x = 3\nIn [34]: y = 5\nIn [35]: z = x > y\n\nIn [36]: z\nOut[36]: False\n\nIn [37]: type(z)\nOut[37]: bool  None is not Zero  It is used to indicate that no value was given or that the behavior was\nundefined. This is different than zero, an empty string, or some other nil\nvalue.  NotImplemented is not None  NotImplemented  is used to indicate that a behavior is not defined or that the\naction we are trying to execute is impossible. For example,  NotImplemented  is\nused under the covers when you try to divide a string by a float. We will end up\nwith a  TypeError . (Try it on the shell)  Important notes :    Variables names can be upper- or lower-case letters, and we can put digits\n  (0-9) and underscores. However, they can not start with a digit.    There are reserved words you can't use and you can find them in\n  this  link    Variables are mutable.    Standard data types: Numerical, String,  List , Tuple, Dictionaries. (list\n  are the default in Python)    Numerical types:  int ,  long  (long integers),  float  and  complex .",
            "title": "Special variables"
        },
        {
            "location": "/python/#data-structures",
            "text": "Lists, dictionaries and tuples are kinds of  Collections   A  collection  allows us to put many values in a single \"variable\".  They are convenient because we can carry many values around in one\n  convenient package.  Simple variables are not collections.",
            "title": "Data structures"
        },
        {
            "location": "/python/#lists",
            "text": "The beginning and end of a list is denoted by square brackets  []  and its\n  elements are separated by commas.  A list element can be any Python object, even another list.  List are MUTABLE, strings are NOT MUTABLE. (Note: there is a method called\n  replace for strings but it creates a copy)   In [38]: my_list = [2, 50, 4, 61]\nIn [39]: print(my_list)\n[2, 50, 4, 61]\n\nIn [40]: my_list[1] = 1\n\nIn [41]: print(my_list)\n[2, 1, 4, 61]                 #Now we have a 1 instead of a 50 in the second place.    len()  function gives us the number of elements in the list.    We can  concatenate  lists by using the operator  + :     In [42]: lst1 = [0,1,2,3]\n\nIn [43]: lst2 = ['a','b','c']\n\nIn [44]: conc = lst1 + lst2\n\nIn [45]: print(conc)\n[0, 1, 2, 3, 'a', 'b', 'c']   There are different methods to apply to a list (check them by typing\n   dir(lst1) ), an example is  append() .   In [46]: lst1.append(4)\n\nIn [47]: print(lst1)\n[0, 1, 2, 3, 4]\n\nIn [48]: lst1.append('five')\n\nIn [49]: lst1\nOut[49]: [0, 1, 2, 3, 4, 'five']\n\nIn [50]: lst1.append([6, 7, 8])\n\nIn [51]: lst1\nOut[51]: [0, 1, 2, 3, 4, 'five', [6, 7, 8]]   Similar to strings we can access elements of a list by doing  list[i]  and\n  also we can do slices.   In [52]: lst1[-1]\nOut[52]: [6, 7, 8]\n\nIn [53]: lst1[5:]\nOut[53]: ['five', [6, 7, 8]]   We can check if something is or not in a list.   In [54]: my_numbers = [3, 17, 27, 19]\n\nIn [55]: 17 in my_numbers\nOut[55]: True\n\nIn [56]: 2 in my_numbers\nOut[56]: False\n\nIn [57]: 13 not in my_numbers\nOut[57]: True  Note: This operators does NOT modify the list.   A  list  is an ordered sequence. We can change the order by sorting the list.    In [58]: names = ['Naty', 'Gil', 'Lorena', 'Chris']\n\nIn [59]: names.sort()\n\nIn [60]: print(names)\n['Chris', 'Gil', 'Lorena', 'Naty']   Strings  and  lists . The  split()  function.   In [61]: string = 'Just three words'\n\nIn [62]: str_list = string.split()\n\nIn [63]: print(str_list)\n['Just', 'three', 'words']  Python takes care of long spaces, for example:  In [64]: line = 'A lot of       space'\n\nIn [65]: stuff = line.split()\n\nIn [66]: print(stuff)\n['A', 'lot', 'of', 'space']  If we specify the delimiter (it can be a space  ' ' , a  ; , a  : , whatever you want).  In [67]: line = 'A lot of       space'\n\nIn [68]: stuff = line.split(' ')\n\nIn [69]: print(stuff)\n['A', 'lot', 'of', '', '', '', '', '', '', 'space']  ;  and many other characters are not delimiters by default:  In [70]: s = 'a;b;c'\n\nIn [71]: thing  = s.split()\n\nIn [72]: print(thing)\na;b;c\n\nIn [73]: thing = s.split(';')\n\nIn [74]: print(thing)\n['a', 'b', 'c']",
            "title": "Lists"
        },
        {
            "location": "/python/#dictionaries",
            "text": "Dictionaries are also a type of collections and they are MUTABLE too.    Difference between lists and dictionaries:   List: a linear collection of values that stay in order.  Dictionary: A \"bag\" of values, each with it's own label (key).  Dictionaries don't maintain order, we index the the things we put in the\n  dictionary with a \"look up\" tag. For example:   In [75]: bag = {}\n\nIn [76]: bag['money'] = 12\n\nIn [77]: bag['candy'] = 5 \n\nIn [78]: bag['tissues'] = 7 \n\nIn [79]: print(bag)\n{'tissues': 7, 'money': 12, 'candy': 5}\n\nIn [80]: print(bag['money'])\n12\n\nIn [81]: bag['money'] += 2\n\nIn [82]: print(bag)\n{'tissues': 7, 'money': 14, 'candy': 5}   We can use the operators  in  and  not in  to check if a key is or not in a\n  dictionary.   In [83]: 'book' in bag\nOut[83]: False\n\nIn [84]: 'candy' in bag\nOut[84]: True\n\nIn [85]: 'cigarette' not in bag\nOut[85]: True   Retrieving keys and values.   In [86]: ages = {'John': 30, 'Maria': 28, 'Lucas': 23}\n\nIn [87]: print(ages.keys())\ndict_keys(['Maria', 'Lucas', 'John'])\n\nIn [88]: print(ages.values())\ndict_values([28, 23, 30])  Note : If we don't change the dictionary in between these operations, the keys\nand values are displayed in order.   We can get a list with pairs (key, value) by doing:   In [89]: print(ages.items())\ndict_items([('Maria', 28), ('Lucas', 23), ('John', 30)])   Dictionaries are good for counting how often we \"see\" something.    There are another two built in data structures: tuples and sets. You can read\nabout them in the\nPython documentation .  A quick insight into them:   Tuples  are like lists but they are IMMUTABLE, which saves time in\n  accessing memory. (Syntax  (element1, element2, ...) )  Sets  are collections that have no order, no duplicate elements and their\n  elements are  hashable \n  which saves time when accessing memory. We can do operations like union,\n  intersection, difference, and symmetric difference. (Syntax  {element1,\n  element2, ...}  and an empty set is created by doing  set() )    Example: look for an element in a list and in a set (%timeit)  In [90]: rg = range(50000)\n\nIn [91]: lst = list(rg)\n\nIn [92]: %time (40035 in lst)\nCPU times: user 4 ms, sys: 0 ns, total: 4 ms\nWall time: 1.91 ms\nOut[92]: True\n\nIn [93]: st = set(rg)\n\nIn [94]: %time (40035 in st)\nCPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 14.3 \u00b5s\nOut[94]: True\n\nIn [95]: %time (51000 in lst)\nCPU times: user 4 ms, sys: 0 ns, total: 4 ms\nWall time: 2.36 ms\nOut[95]: False\n\nIn [96]: %time (51000 in st)\nCPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 12.9 \u00b5s\nOut[96]: False",
            "title": "Dictionaries"
        },
        {
            "location": "/python/#control-flow",
            "text": "",
            "title": "Control Flow"
        },
        {
            "location": "/python/#conditionals",
            "text": "The syntax is \"If  x  true, then do something; otherwise, do something else.\"  If  statement on its own:  In [97]: a = 8\n\nIn [98]: b = 3 \n\nIn [99]: if a > b :\n    ...:     print('a is bigger than b')\n    ...:\na is bigger than b  If-else  statement:   In [100]: x = float(input('Insert your number: '))\nInsert your number: 711457\n\nIn [101]: if x % 17 == 0:\n     ...:     print('Your number is a multiple of 17.')\n     ...: else :\n     ...:     print('Your number is not a multiple of 17.')\n\nYour number is not a multiple of 17.  If-elif-else  statement:  In [102]: a = 3\n\nIn [103]: b = 5\n\nIn [104]: if a > b:\n     ...:     print('a is bigger than b.')\n     ...: elif a < b:\n     ...:     print('a is smaller than b.')\n     ...: else:\n     ...:     print('a is equal to b.')\n     ...:\na is smaller than b.  Note:  We can have as many  elif  as we want.",
            "title": "Conditionals"
        },
        {
            "location": "/python/#loops",
            "text": "Loops are useful for executing the same block multiple times. In Python we have\nmultiple looping formats:  while  loops,  for  loops, and comprehensions.  While loops  They are related to an  if  statement, they will compute  while  a condition is true.  In [105]: sec = 5\nIn [106]: while 0 < sec :\n     ...:     print('You have {} seconds'.format(sec))\n     ...:     sec -= 1\n     ...: print('Boom!!!')\n    ...:\nYou have 5 seconds\nYou have 4 seconds\nYou have 3 seconds\nYou have 2 seconds\nYou have 1 seconds\nBoom!!!  Note:  You have to be careful to not generate an infinite loop.   For loops \nIt is usually more useful to iterate over a certain group of things or an \"iterable\".  In [107]: for i in range(5,0,-1):\n    ...:     print('You have {} seconds'.format(i))\n    ...: print('Boom!!!')\n    ...: \nYou have 5 seconds\nYou have 4 seconds\nYou have 3 seconds\nYou have 2 seconds\nYou have 1 seconds\nBoom!!!  Another example:  In [108]: name = input('Insert your name: ')\nInsert your name: Naty\n\nIn [109]: name\nOut[109]: 'Naty'\n\nIn [110]: count = 1\n\nIn [111]: for letter in name:\n    ...:     print('The {} letter is {}'.format(count,letter))\n    ...:     count +=1\n    ...:\nThe 1 letter is N\nThe 2 letter is a\nThe 3 letter is t\nThe 4 letter is y  We can loop over dictionaries too:  In [112]: d = {\"name\":\"Lionel\", \"last_name\": \"Messi\", \"birthday\": [6, 24, 1987]}\n\nIn [113]: for item in d.items():\n     ...:     print(item)\n     ...:\n('birthday', [6, 24, 1987])\n('name', 'Lionel')\n('last_name', 'Messi')\n\nIn [114]: for key, value in d.items():\n     ...:     print(key, value)\n     ...:\nbirthday [6, 24, 1987]\nname Lionel\nlast_name Messi  Comprehensions  for  and  while  loops are really useful but they take at least \"two lines\",\nand if you need to save the result of each loop in the iteration in a list, set,\netc. This takes at least \"three lines\". Thankfully, Python is so great that in\nsome cases we can reduce these cases to just ONE line! Let's see this with an\nexample:  Normal loop:  In [114]: fruits = ['apple', 'orange', 'grape', 'banana', 'pineapple', 'strawberry', 'watermelon']\n\nIn [115]: upper_fruits = []\n\nIn [116]: for fruit in fruits:\n    ...:     upper_fruits.append(fruit.upper())\n\nIn [117]: upper_fruits\nOut[117]: ['APPLE', 'ORANGE', 'GRAPE', 'BANANA', 'PINEAPPLE', 'STRAWBERRY', 'WATERMELON']  Pythonic way:  In [118]: upper_pythonic = [fruit.upper() for fruit in fruits]\n\nIn [119]: upper_pythonic\nOut[119]: ['APPLE', 'ORANGE', 'GRAPE', 'BANANA', 'PINEAPPLE', 'STRAWBERRY', 'WATERMELON']  We can add a filter, for example:  In [120]: entries = [2, 11, 49, 3, 57, 33, 9]\n\nIn [121]: entries\nOut[121]: [2, 11, 49, 3, 57, 33, 9]\n\nIn [122]: some = [x**2 for x in entries if x%3==0]\n\nIn [123]: some\nOut[123]: [9, 3249, 1089, 81]\n\nIn [124]: orig = [int(x**(1/2)) for x in some]\n\nIn [125]: orig\nOut[125]: [3, 57, 33, 9]",
            "title": "Loops"
        },
        {
            "location": "/python/#ipython-magics",
            "text": "Sometimes when we are working on IPython we would like to select certain lines\nand save them into a Python script. We can do that!  We can check the history of what we've done in the current session of IPython by\ntyping:  %hist -n  If we want to select certain lines and put them into a script, the command %edit  allow us to do this. Let's suppose we want lines 1, 3 and from 5-10; \nthen we should do:  %edit 1 3 5-10  and this will open the default editor with the lines we want.   Once we have that script saved if we want to run it we can use the command %run :  %run my_script.py",
            "title": "IPython Magics"
        },
        {
            "location": "/python/#exercises",
            "text": "Slicing    1- Write code using  find()  and string slicing to extract the number at the end\nof the line below. Convert the extracted value to a floating point number and\nprint it out. (Content taken from online course \"Python Data Structures\" by Dr.\nCharles Severance)  text = \"X-DSPAM-Confidence:    0.8475\"  Solution:  solu  Slicing and for loop    2- Write a code that grabs, from each word, all the letters except 'ball' at the\nend of each one. Save the output in a list and print it out.  The original list is:  sports = ['Football', 'Volleyball', 'Basketball', 'Baseball', 'Handball', 'Softball']  And your output should look like:  ['Foot', 'Volley', 'Basket', 'Base', 'Hand', 'Soft']  Solution :  In [131]: sports = ['Football', 'Volleyball', 'Basketball', 'Baseball', 'Handball', 'Softball']\n\nIn [132]: random = []\n\nIn [133]: for sport in sports:\n     ...:     word = sport[:-4]\n     ...:     random.append(word)\n     ...:\n\nIn [134]: print(random)\n['Foot', 'Volley', 'Basket', 'Base', 'Hand', 'Soft']  Dictionaries for counting  3- Write a code that counts the frequency of each word that we have in the\nphrase provided.  Tips: split the text and put the words in a list, use a dictionary to count the\nrepetitions.  (The idea of the following two exercises was inspired by content from the online\ncourse \"Python Data Structures\" by Dr. Charles Severance)  happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy but I was not really happy\"  Your output should look like:  {'happy': 4, 'really': 1, 'and': 1, 'feel': 1, 'others': 1, 'felt': 1, 'not': 1, 'the': 1, 'should': 1, 'knew': 1, 'was': 1, 'saw': 1, 'I': 5, 'but': 1, 'were': 1, 'because': 2}  Remember that dictionaries don't preserve order, therefore the items in your\noutput might be in a different order. However, you can still check if your\noutput is equal to the one we provide by doing a logical comparison using the ==  operation, which should return  True  if you get it right.  Optional : Rewrite exercise 3 using the method  get() .   Solution  In [135]: happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy\n    ...:  but I was not really happy\"\n\nIn [136]: words = happy.split()\n\nIn [137]: counts = {}\n\nIn [138]: for word in words:\n     ...:     if word not in counts:\n     ...:         counts[word] = 1\n     ...:     else:\n     ...:         counts[word] += 1\n     ...: \n\nIn [139]: print(counts)\n{'happy': 4, 'really': 1, 'and': 1, 'feel': 1, 'others': 1, 'felt': 1, 'not': 1, 'the': 1, 'should': 1, 'knew': 1, 'was': 1, 'saw': 1, 'I': 5, 'but': 1, 'were': 1, 'because': 2}  Solution using  get()  In [140]: happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy\n    ...:  but I was not really happy\"\n\nIn [141]: words = happy.split()\n\nIn [142]: counts = {}\nIn [143]: for word in words:\n     ...:     counts[word] = counts.get(word, 0) +1 \n     ...:\n\nIn [144]: print(counts)\n{'happy': 4, 'really': 1, 'and': 1, 'feel': 1, 'others': 1, 'felt': 1, 'not': 1, 'the': 1, 'should': 1, 'knew': 1, 'was': 1, 'saw': 1, 'I': 5, 'but': 1, 'were': 1, 'because': 2}",
            "title": "Exercises"
        },
        {
            "location": "/git/git/",
            "text": "Intro to \ngit\n and GitHub\n\n\nWhy version control?\n\n\n\n\nInitial configuration\n\n\ngit config\n to set editor, colors, email, name, etc... (use \nnano\n)\n\n\nUser settings\n\n\nThe first time we use \ngit\n on a new computer we need to configure a few details.\nWe want \ngit\n to know who we are and how to reach us (we'll see why later!).\n\n\nWe're also going to specify a text editor to use with \ngit\n and we want git\noutput to be colorized.\n\n\n$ git config --global user.name \"Gil Forsyth\"\n$ git config --global user.email \"gilforsyth@gmail.com\"\n$ git config --global color.ui \"auto\"\n$ git config --global core.editor \"nano -w\"\n\n\n\n\nCreate\n\n\nLet's create a directory for our work and then move into that directory\n\n\n$ mkdir wordcount\n\n\n\n\n$ cd wordcount/\n\n\n\n\nNow we can use \nwget\n to download a Python script into the \nwordcount\n folder.\n\n\n$ wget ...\n\n\n\n\n$ ls\n\n\n\n\nword_count.py\n\n\n\n\nNow we tell \ngit\n to make \nwordcount\n a repository--a place where \ngit\n can\nstore versions of our files:\n\n\n$ git init\n\n\n\n\nInitialized empty Git repository in /home/gil/wordcount/.git/\n\n\n\n\nIf we use \nls\n to check the directory's contents, it appears that nothing has\nchanged:\n\n\n$ ls\n\n\n\n\nword_count.py\n\n\n\n\nBut if we add the \n-a\n flag to show everything, we can see that \ngit\n has\ncreated a hidden directory called \n.git\n\n\n$ ls -a\n\n\n\n\n.  ..  .git  word_count.py\n\n\n\n\nThis folder contains the entire history of the repository. This means that you\ncan move the repository around on your computer simply by moving the folder. It\nalso means that if you delete the \n.git\n folder, your history is gone.\n\n\ngit status\n\n\nThis is the most used command in \ngit\n.  Let's try it out!\n\n\n$ git status\n\n\n\n\nOn branch master\n\nInitial commit\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\n    word_count.py\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n\n\n\n\nWhat is \ngit\n telling us? Quite a bit! We're \nOn branch master\n. We'll ignore\nthat for now and come back to it later on.\n\n\nWe are on the \nInitial commit\n. What's a commit? A commit is a granular change\nmade to a file (or set of files) that is logged in the history of the\nrepository.\n\n\nWhat about that last line? We can use \ngit add\n to track. Let's try that.\n\n\ngit add\n\n\nWe have a file in the new repo and we want to start tracking any changes\nmade to that file. \ngit\n ignores files until you tell it to look after them. To\nbegin tracking, we have to \nadd\n the file to the repository:\n\n\n$ git add word_count.py\n\n\n\n\nDid anything happen? Let's check! What command should we use?\n\n\n$ git status\n\n\n\n\nOn branch master\n\nInitial commit\n\nChanges to be committed:\n  (use \"git rm --cached <file>...\" to unstage)\n\n    new file:   word_count.py\n\n\n\n\n\nAgain, let's review the information that \ngit status\n gives us:\n\n\n\n\nWe are still \nOn branch master\n (and still ignoring this)\n\n\nIt is still the \nInitial commit\n (which makes sense, we haven't made any\n  commits yet...)\n\n\nThere are \nChanges to be committed\n\n\n\n\nNote that we haven't actually made a commit yet. We haven't finalized the\nsnapshot of the repo. Right now, we have a file called \nword_count.py\n located in\nwhat is called the \"Staging Area\".\n\n\nThe \"Staging Area\" is where we stage changes. It's a place to gather changes\nbefore committing those changes to the permanent history of the repository.\n\n\nWe'll talk more about the staging area later, but for now, let's finalize the\naddition of our new file by creating our first commit!\n\n\ngit commit\n\n\nIt's time!  Let's commit the changes to the repo history.\n\n\n$ git commit\n\n\n\n\nThis command will open up your text editor (\nnano\n) with the following text.\n\n\n\n# Please enter the commit message for your changes. Lines starting\n# with '#' will be ignored, and an empty message aborts the commit.\n# On branch master\n#\n# Initial commit\n#\n# Changes to be committed:\n#       new file:   word_count.py\n#\n\n\n\n\nAgain, \ngit\n has a bunch of helpful information. We can enter a commit message\non the first line and then save and quit.\n\n\n[master (root-commit) 47f748f] Add initial version of word count script\n 1 file changed, 9 insertions(+)\n create mode 100644 word_count.py\n\n\n\n\nGreat! We have created a snapshot of our file in the repo history. Now, even if\nwe make changes, we'll be able to roll them back if we don't like them.\n\n\nDid we miss anything? Check \ngit status\n to find out the state of the repository\nnow.\n\n\n$ git status \n\n\n\n\nOn branch master nothing to commit, working tree clean \n\n\n\n\nImprove the script\n\n\nHow does the script work right now? Let's run it and find out.\n\n\n$ python word_count.py \n\n\n\n\n{'not': 1, 'but': 1, 'because': 2, 'the': 1, 'was': 1, 'others': 1, 'happy': 4, 'I': 5, 'really': 1, 'knew': 1, 'feel': 1, 'and': 1, 'felt': 1, 'should': 1, 'saw': 1, 'were': 1}\n\n\n\n\nOk. This would be more useful if the user could decide what to input, don't you\nthink? Edit \nword_count.py\n and make it accept user input instead of a hardcoded\nsentence.\n\n\n$ nano word_count.py \n\n\n\n\nWith those changes saved, let's first see if the script works as expected!\n\n\n$ python word_count.py \nI can't quite tell if this is working.  Is it working?\n\n\n\n\n{'tell': 1, 'is': 1, 'working.': 1, 'if': 1, 'working?': 1, \"can't\": 1, 'quite': 1, 'Is': 1, 'it': 1, 'I': 1, 'this': 1}\n\n\n\n\nIt is working! Time to check in with \ngit\n.\n\n\n$ git status\n\n\n\n\nOn branch master\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n    modified:   word_count.py\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\n\n\n\nOk, this is different than before. The first time we added a file, it was \"new\"\nand \ngit\n told us that. Now we have modified an \nexisting\n file and \ngit\n is\ntelling us it detected changes made to that file.\n\n\nNow we know what changes were made since we just made them, but what if we want to check?\n\n\ngit diff\n\n\ngit diff\n examines the \ndifference\n between the current state of a file and the\nlast committed version of the file (by default).\n\n\n$ git diff word_count.py\n\n\n\n\ndiff --git a/word_count.py b/word_count.py\nindex 3326ac7..1ac2be0 100644\n--- a/word_count.py\n+++ b/word_count.py\n@@ -1,4 +1,4 @@\n-happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy but I was not really happy\"\n+happy = input()\n\n words = happy.split()\n\n\n\n\nHandy! \ngit\n shows which line(s) was changed and colors the replacement text\ngreen and the old text red. This looks ready to go. Time to stage the changes.\n\n\n$ git add word_count.py\n\n\n\n\nAnd a quick status check...\n\n\n$ git status\n\n\n\n\nOn branch master\nChanges to be committed:\n  (use \"git reset HEAD <file>...\" to unstage)\n\n    modified:   word_count.py\n\n\n\n\n\nLooks good, let's commit.\n\n\n$ git commit\n\n\n\n\n[master 97fba8d] allow user input of statement to word count\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\n\n\n\nAnd now the status should be clean.\n\n\n$ git status\n\n\n\n\nOn branch master\nnothing to commit, working tree clean\n\n\n\n\nWhat does \nword_count.py\n look like now?\n\n\ncat\n it and find out!\n\n\n$ cat word_count.py \n\n\n\n\nhappy = input()\n\nwords = happy.split()\n\ncounts = {}\nfor word in words:\n    counts[word] = counts.get(word, 0) + 1\n\nprint(counts)\n\n\n\n\nThat's the state of the file on the hard drive right now. The most recent change\nwe've made is what we see.\n\n\ncommit\n helpers\n\n\nThe blank \ninput\n line might be confusing. Let's add some prompt text to help the user understand what's happening:\n\n\n$ nano word_count.py \n\n\n\n\nOk. Changes made, let's test it out.\n\n\n$ python word_count.py\nEnter a statement to word count: This is a much better user experience\n\n\n\n\n{'This': 1, 'a': 1, 'much': 1, 'is': 1, 'experience': 1, 'user': 1, 'better': 1}\n\n\n\n\nCheck \nstatus\n\n\n$ git status\n\n\n\n\nOn branch master\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n    modified:   word_count.py\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\n\n\n\nCheck the \ndiff\n\n\n$ git diff\n\n\n\n\ndiff --git a/word_count.py b/word_count.py\nindex 1ac2be0..2689774 100644\n--- a/word_count.py\n+++ b/word_count.py\n@@ -1,4 +1,4 @@\n-happy = input()\n+happy = input(\"Enter a statement to word count: \")\n\n words = happy.split()\n\n\n\n\nIf everything looks ok, then stage the file.\n\n\n$ git add word_count.py\n\n\n\n\nOne helpful shortcut that \ngit\n offers is the \n-m\n flag, which allows you to\nwrite your commit message right on the command line. This is great when you are\nmaking small, relatively simple changes.\n\n\n$ git commit -m \"add helper text to input function\"\n\n\n\n\n[master 09633c8] add helper text to input function\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\n\n\n\nSee? No text editor opened, but the commit has been made.\n\n\ngit log\n\n\nNow that we have a few \"snapshots\" of \nword_count.py\n we can take a look at its\nhistory. To do that, we use the \ngit log\n command.\n\n\n$ git log\n\n\n\n\ncommit 09633c88bb3f8b40d1c988b1df9004245320462a\nAuthor: Gil Forsyth <gilforsyth@gmail.com>\nDate:   Tue Dec 13 11:01:11 2016 -0500\n\n    add helper text to input function\n\ncommit 97fba8ddd7685e650813675f5b024267af0b94e7\nAuthor: Gil Forsyth <gilforsyth@gmail.com>\nDate:   Tue Dec 13 10:58:59 2016 -0500\n\n    allow user input of statement to word count\n\ncommit 47f748fea14e14ed84452a802dc14a5ea0829949\nAuthor: Gil Forsyth <gilforsyth@gmail.com>\nDate:   Tue Dec 13 10:53:23 2016 -0500\n\n    Add initial version of word count script\n\n\n\n\nThis is the full history of this repository. There are three commits. You can\nsee the author of each commit, a contact email, the date and time of the change\nand the commit message. This is some nice granular information!\n\n\nEach commit also has a long alphanumeric string for a header line. \nThis is the \nhash\n of that commit. It is a unique identifier for that particular commit. What can we use the hashes for? Time travel! (sort of...)\n\n\ndiff\n across time\n\n\nRemember that \ngit diff\n, by default, shows you the changes made to a specified\nfile since the most recent commit. You can also ask it to show you changes\nbetween two points in time by specifying the commit hashes to compare.\n\n\nNote\n: You don't need to type out the \nentire\n hash. Just the first 6 characters should do the trick. \n\n\n$ git diff 47f748 09633c word_count.py\n\n\n\n\ndiff --git a/word_count.py b/word_count.py\nindex 3326ac7..2689774 100644\n--- a/word_count.py\n+++ b/word_count.py\n@@ -1,4 +1,4 @@\n-happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy but I was not really happy\"\n+happy = input(\"Enter a statement to word count: \")\n\n words = happy.split()\n\n\n\n\nThat diff is a comparison between the original commit and the most recent commit. \n\n\ncheckout\n an older version of a file\n\n\ndiff\n lets us compare the changes made in the repository history, but sometimes\nwe want to restore a previous version of a file entirely. Maybe we introduced a\nmistake somewhere or just like the old way better. People change their minds.\n\n\nTo \ncheckout\n a previous version of a file, we need the commit hashes. We can pass the \n--oneline\n flag to \ngit log\n for a more compact version:\n\n\n$ git log --oneline\n\n\n\n\n09633c8 add helper text to input function\n97fba8d allow user input of statement to word count\n47f748f Add initial version of word count script\n\n\n\n\nAs an example, we will restore \nword_count.py\n to its original state, before we\nmade any edits. To do that, we \ncheckout\n to the commit hash of the first commit\nand specify the file \nword_count.py\n\n\n$ git checkout 47f748 word_count.py \n\n\n\n\nDid it work? Use \ncat\n to find out:\n\n\n$ cat word_count.py \n\n\n\n\nhappy = \"I felt happy because I saw the others were happy and because I knew I should feel happy but I was not really happy\"\n\nwords = happy.split()\n\ncounts = {}\nfor word in words:\n    counts[word] = counts.get(word, 0) + 1\n\nprint(counts)\n\n\n\n\nNow the file, as it exists in the folder \nwordcount\n, is restored to its\noriginal state. Let's check on the \nstatus\n.\n\n\n$ git status\n\n\n\n\nOn branch master\nChanges to be committed:\n  (use \"git reset HEAD <file>...\" to unstage)\n\n    modified:   word_count.py\n\n\n\n\nThis is a little different than what happened before. \ngit\n isn't saying that\nchanges have been made, it's saying that changes are \nstaged\n. We're just one\n\ngit commit\n away from completely restoring \nword_count.py\n. \n\n\nWhen you restore a file in \ngit\n, rather than eliminating the commits that were\nmade, \ngit\n creates a \nnew\n commit that changes everything back. This way, if\nyou happen to change your mind \nagain\n, you haven't lost anything. Pretty cool,\nyeah?\n\n\nIn any case, we don't really want to restore the old version permanently, the new version is much more versatile. Instead of committing the changes, we can put things back the way they were a moment ago, again using \ncheckout\n.\n\n\nConsult \ngit log\n again and this time, use \ncheckout\n to go to the most recent\ncommit.\n\n\n$ git log --oneline\n\n\n\n\n09633c8 add helper text to input function\n97fba8d allow user input of statement to word count\n47f748f Add initial version of word count script\n\n\n\n\n$ git checkout 09633c8 word_count.py \n\n\n\n\n$ git status\n\n\n\n\nOn branch master\nnothing to commit, working tree clean\n\n\n\n\nAnd we're back to the future!",
            "title": "git"
        },
        {
            "location": "/git/git/#intro-to-git-and-github",
            "text": "",
            "title": "Intro to git and GitHub"
        },
        {
            "location": "/git/git/#why-version-control",
            "text": "",
            "title": "Why version control?"
        },
        {
            "location": "/git/git/#initial-configuration",
            "text": "git config  to set editor, colors, email, name, etc... (use  nano )",
            "title": "Initial configuration"
        },
        {
            "location": "/git/git/#user-settings",
            "text": "The first time we use  git  on a new computer we need to configure a few details.\nWe want  git  to know who we are and how to reach us (we'll see why later!).  We're also going to specify a text editor to use with  git  and we want git\noutput to be colorized.  $ git config --global user.name \"Gil Forsyth\"\n$ git config --global user.email \"gilforsyth@gmail.com\"\n$ git config --global color.ui \"auto\"\n$ git config --global core.editor \"nano -w\"",
            "title": "User settings"
        },
        {
            "location": "/git/git/#create",
            "text": "Let's create a directory for our work and then move into that directory  $ mkdir wordcount  $ cd wordcount/  Now we can use  wget  to download a Python script into the  wordcount  folder.  $ wget ...  $ ls  word_count.py  Now we tell  git  to make  wordcount  a repository--a place where  git  can\nstore versions of our files:  $ git init  Initialized empty Git repository in /home/gil/wordcount/.git/  If we use  ls  to check the directory's contents, it appears that nothing has\nchanged:  $ ls  word_count.py  But if we add the  -a  flag to show everything, we can see that  git  has\ncreated a hidden directory called  .git  $ ls -a  .  ..  .git  word_count.py  This folder contains the entire history of the repository. This means that you\ncan move the repository around on your computer simply by moving the folder. It\nalso means that if you delete the  .git  folder, your history is gone.",
            "title": "Create"
        },
        {
            "location": "/git/git/#git-status",
            "text": "This is the most used command in  git .  Let's try it out!  $ git status  On branch master\n\nInitial commit\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\n    word_count.py\n\nnothing added to commit but untracked files present (use \"git add\" to track)  What is  git  telling us? Quite a bit! We're  On branch master . We'll ignore\nthat for now and come back to it later on.  We are on the  Initial commit . What's a commit? A commit is a granular change\nmade to a file (or set of files) that is logged in the history of the\nrepository.  What about that last line? We can use  git add  to track. Let's try that.",
            "title": "git status"
        },
        {
            "location": "/git/git/#git-add",
            "text": "We have a file in the new repo and we want to start tracking any changes\nmade to that file.  git  ignores files until you tell it to look after them. To\nbegin tracking, we have to  add  the file to the repository:  $ git add word_count.py  Did anything happen? Let's check! What command should we use?  $ git status  On branch master\n\nInitial commit\n\nChanges to be committed:\n  (use \"git rm --cached <file>...\" to unstage)\n\n    new file:   word_count.py  Again, let's review the information that  git status  gives us:   We are still  On branch master  (and still ignoring this)  It is still the  Initial commit  (which makes sense, we haven't made any\n  commits yet...)  There are  Changes to be committed   Note that we haven't actually made a commit yet. We haven't finalized the\nsnapshot of the repo. Right now, we have a file called  word_count.py  located in\nwhat is called the \"Staging Area\".  The \"Staging Area\" is where we stage changes. It's a place to gather changes\nbefore committing those changes to the permanent history of the repository.  We'll talk more about the staging area later, but for now, let's finalize the\naddition of our new file by creating our first commit!",
            "title": "git add"
        },
        {
            "location": "/git/git/#git-commit",
            "text": "It's time!  Let's commit the changes to the repo history.  $ git commit  This command will open up your text editor ( nano ) with the following text.  \n# Please enter the commit message for your changes. Lines starting\n# with '#' will be ignored, and an empty message aborts the commit.\n# On branch master\n#\n# Initial commit\n#\n# Changes to be committed:\n#       new file:   word_count.py\n#  Again,  git  has a bunch of helpful information. We can enter a commit message\non the first line and then save and quit.  [master (root-commit) 47f748f] Add initial version of word count script\n 1 file changed, 9 insertions(+)\n create mode 100644 word_count.py  Great! We have created a snapshot of our file in the repo history. Now, even if\nwe make changes, we'll be able to roll them back if we don't like them.  Did we miss anything? Check  git status  to find out the state of the repository\nnow.  $ git status   On branch master nothing to commit, working tree clean",
            "title": "git commit"
        },
        {
            "location": "/git/git/#improve-the-script",
            "text": "How does the script work right now? Let's run it and find out.  $ python word_count.py   {'not': 1, 'but': 1, 'because': 2, 'the': 1, 'was': 1, 'others': 1, 'happy': 4, 'I': 5, 'really': 1, 'knew': 1, 'feel': 1, 'and': 1, 'felt': 1, 'should': 1, 'saw': 1, 'were': 1}  Ok. This would be more useful if the user could decide what to input, don't you\nthink? Edit  word_count.py  and make it accept user input instead of a hardcoded\nsentence.  $ nano word_count.py   With those changes saved, let's first see if the script works as expected!  $ python word_count.py \nI can't quite tell if this is working.  Is it working?  {'tell': 1, 'is': 1, 'working.': 1, 'if': 1, 'working?': 1, \"can't\": 1, 'quite': 1, 'Is': 1, 'it': 1, 'I': 1, 'this': 1}  It is working! Time to check in with  git .  $ git status  On branch master\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n    modified:   word_count.py\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")  Ok, this is different than before. The first time we added a file, it was \"new\"\nand  git  told us that. Now we have modified an  existing  file and  git  is\ntelling us it detected changes made to that file.  Now we know what changes were made since we just made them, but what if we want to check?",
            "title": "Improve the script"
        },
        {
            "location": "/git/git/#git-diff",
            "text": "git diff  examines the  difference  between the current state of a file and the\nlast committed version of the file (by default).  $ git diff word_count.py  diff --git a/word_count.py b/word_count.py\nindex 3326ac7..1ac2be0 100644\n--- a/word_count.py\n+++ b/word_count.py\n@@ -1,4 +1,4 @@\n-happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy but I was not really happy\"\n+happy = input()\n\n words = happy.split()  Handy!  git  shows which line(s) was changed and colors the replacement text\ngreen and the old text red. This looks ready to go. Time to stage the changes.  $ git add word_count.py  And a quick status check...  $ git status  On branch master\nChanges to be committed:\n  (use \"git reset HEAD <file>...\" to unstage)\n\n    modified:   word_count.py  Looks good, let's commit.  $ git commit  [master 97fba8d] allow user input of statement to word count\n 1 file changed, 1 insertion(+), 1 deletion(-)  And now the status should be clean.  $ git status  On branch master\nnothing to commit, working tree clean",
            "title": "git diff"
        },
        {
            "location": "/git/git/#what-does-word_countpy-look-like-now",
            "text": "cat  it and find out!  $ cat word_count.py   happy = input()\n\nwords = happy.split()\n\ncounts = {}\nfor word in words:\n    counts[word] = counts.get(word, 0) + 1\n\nprint(counts)  That's the state of the file on the hard drive right now. The most recent change\nwe've made is what we see.",
            "title": "What does word_count.py look like now?"
        },
        {
            "location": "/git/git/#commit-helpers",
            "text": "The blank  input  line might be confusing. Let's add some prompt text to help the user understand what's happening:  $ nano word_count.py   Ok. Changes made, let's test it out.  $ python word_count.py\nEnter a statement to word count: This is a much better user experience  {'This': 1, 'a': 1, 'much': 1, 'is': 1, 'experience': 1, 'user': 1, 'better': 1}  Check  status  $ git status  On branch master\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n    modified:   word_count.py\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")  Check the  diff  $ git diff  diff --git a/word_count.py b/word_count.py\nindex 1ac2be0..2689774 100644\n--- a/word_count.py\n+++ b/word_count.py\n@@ -1,4 +1,4 @@\n-happy = input()\n+happy = input(\"Enter a statement to word count: \")\n\n words = happy.split()  If everything looks ok, then stage the file.  $ git add word_count.py  One helpful shortcut that  git  offers is the  -m  flag, which allows you to\nwrite your commit message right on the command line. This is great when you are\nmaking small, relatively simple changes.  $ git commit -m \"add helper text to input function\"  [master 09633c8] add helper text to input function\n 1 file changed, 1 insertion(+), 1 deletion(-)  See? No text editor opened, but the commit has been made.",
            "title": "commit helpers"
        },
        {
            "location": "/git/git/#git-log",
            "text": "Now that we have a few \"snapshots\" of  word_count.py  we can take a look at its\nhistory. To do that, we use the  git log  command.  $ git log  commit 09633c88bb3f8b40d1c988b1df9004245320462a\nAuthor: Gil Forsyth <gilforsyth@gmail.com>\nDate:   Tue Dec 13 11:01:11 2016 -0500\n\n    add helper text to input function\n\ncommit 97fba8ddd7685e650813675f5b024267af0b94e7\nAuthor: Gil Forsyth <gilforsyth@gmail.com>\nDate:   Tue Dec 13 10:58:59 2016 -0500\n\n    allow user input of statement to word count\n\ncommit 47f748fea14e14ed84452a802dc14a5ea0829949\nAuthor: Gil Forsyth <gilforsyth@gmail.com>\nDate:   Tue Dec 13 10:53:23 2016 -0500\n\n    Add initial version of word count script  This is the full history of this repository. There are three commits. You can\nsee the author of each commit, a contact email, the date and time of the change\nand the commit message. This is some nice granular information!  Each commit also has a long alphanumeric string for a header line. \nThis is the  hash  of that commit. It is a unique identifier for that particular commit. What can we use the hashes for? Time travel! (sort of...)",
            "title": "git log"
        },
        {
            "location": "/git/git/#diff-across-time",
            "text": "Remember that  git diff , by default, shows you the changes made to a specified\nfile since the most recent commit. You can also ask it to show you changes\nbetween two points in time by specifying the commit hashes to compare.  Note : You don't need to type out the  entire  hash. Just the first 6 characters should do the trick.   $ git diff 47f748 09633c word_count.py  diff --git a/word_count.py b/word_count.py\nindex 3326ac7..2689774 100644\n--- a/word_count.py\n+++ b/word_count.py\n@@ -1,4 +1,4 @@\n-happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy but I was not really happy\"\n+happy = input(\"Enter a statement to word count: \")\n\n words = happy.split()  That diff is a comparison between the original commit and the most recent commit.",
            "title": "diff across time"
        },
        {
            "location": "/git/git/#checkout-an-older-version-of-a-file",
            "text": "diff  lets us compare the changes made in the repository history, but sometimes\nwe want to restore a previous version of a file entirely. Maybe we introduced a\nmistake somewhere or just like the old way better. People change their minds.  To  checkout  a previous version of a file, we need the commit hashes. We can pass the  --oneline  flag to  git log  for a more compact version:  $ git log --oneline  09633c8 add helper text to input function\n97fba8d allow user input of statement to word count\n47f748f Add initial version of word count script  As an example, we will restore  word_count.py  to its original state, before we\nmade any edits. To do that, we  checkout  to the commit hash of the first commit\nand specify the file  word_count.py  $ git checkout 47f748 word_count.py   Did it work? Use  cat  to find out:  $ cat word_count.py   happy = \"I felt happy because I saw the others were happy and because I knew I should feel happy but I was not really happy\"\n\nwords = happy.split()\n\ncounts = {}\nfor word in words:\n    counts[word] = counts.get(word, 0) + 1\n\nprint(counts)  Now the file, as it exists in the folder  wordcount , is restored to its\noriginal state. Let's check on the  status .  $ git status  On branch master\nChanges to be committed:\n  (use \"git reset HEAD <file>...\" to unstage)\n\n    modified:   word_count.py  This is a little different than what happened before.  git  isn't saying that\nchanges have been made, it's saying that changes are  staged . We're just one git commit  away from completely restoring  word_count.py .   When you restore a file in  git , rather than eliminating the commits that were\nmade,  git  creates a  new  commit that changes everything back. This way, if\nyou happen to change your mind  again , you haven't lost anything. Pretty cool,\nyeah?  In any case, we don't really want to restore the old version permanently, the new version is much more versatile. Instead of committing the changes, we can put things back the way they were a moment ago, again using  checkout .  Consult  git log  again and this time, use  checkout  to go to the most recent\ncommit.  $ git log --oneline  09633c8 add helper text to input function\n97fba8d allow user input of statement to word count\n47f748f Add initial version of word count script  $ git checkout 09633c8 word_count.py   $ git status  On branch master\nnothing to commit, working tree clean  And we're back to the future!",
            "title": "checkout an older version of a file"
        },
        {
            "location": "/numba/1/",
            "text": "Intro to profiling\n\n\nPython's dirty little secret is that it can be made to run pretty fast.  \n\n\nThe bare-metal HPC people will be angrily tweeting at me now, or rather, they would be if they could get their wireless drivers working.\n\n\nStill, there are some things you \nreally\n don't want to do in Python.  Nested loops are usually a bad idea.  But often you won't know where your code is slowing down just by looking at it and trying to accelerate everything can be a waste of time.  (Developer time, that is, both now and in the future: you incur technical debt if you unintentionally obfuscate code to make it faster when it doesn't need to be).\n\n\nThe first step is always to find the bottlenecks in your code, via \nprofiling\n: analyzing your code by measuring the execution time of its parts.\n\n\nTools\n\n\n\n\ncProfile\n\n\nline_profiler\n\n\ntimeit\n\n\n\n\nNote\n:\nIf you haven't already installed it, you can do\n\n\nconda install line_profiler\n\n\n\n\nor\n\n\npip install line_profiler\n\n\n\n\nSome bad code\n\n\nHere's a bit of code guaranteed to perform poorly: it sleeps for 1.5 seconds after doing any work! We will profile it and see where we might be able to help.\n\n\nimport numpy\nfrom time import sleep\n\ndef bad_call(dude):\n    sleep(.5)\n\ndef worse_call(dude):\n    sleep(1)\n\ndef sumulate(foo):\n    if not isinstance(foo, int):\n        return\n\n    a = numpy.random.random((1000, 1000))\n    a @ a\n\n    ans = 0\n    for i in range(foo):\n        ans += i\n\n    bad_call(ans)\n    worse_call(ans)\n\n    return ans\n\n\n\n\nsumulate(150)\n\n\n\n\n11175\n\n\n\nusing \ncProfile\n\n\ncProfile\n is the built-in profiler in Python (available since Python 2.5).  It provides a function-by-function report of execution time. First import the module, then usage is simply a call to \ncProfile.run()\n with your code as argument. It will print out a list of all the functions that were called, with the number of calls and the time spent in each.\n\n\nimport cProfile\n\n\n\n\ncProfile.run('sumulate(150)')\n\n\n\n\n         10 function calls in 1.549 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.023    0.023    1.549    1.549 <ipython-input-1-ab37b7e7eed9>:10(sumulate)\n        1    0.000    0.000    0.501    0.501 <ipython-input-1-ab37b7e7eed9>:4(bad_call)\n        1    0.000    0.000    1.001    1.001 <ipython-input-1-ab37b7e7eed9>:7(worse_call)\n        1    0.000    0.000    1.549    1.549 <string>:1(<module>)\n        1    0.000    0.000    1.549    1.549 {built-in method builtins.exec}\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n        2    1.502    0.751    1.502    0.751 {built-in method time.sleep}\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n        1    0.024    0.024    0.024    0.024 {method 'random_sample' of 'mtrand.RandomState' objects}\n\n\n\nYou can see here that when our code \nsumulate()\n executes, it spends almost all its time in the method \ntime.sleep\n (a bit over 1.5 seconds).\n\n\nIf your program is more complicated that this cute demo, you'll have a hard time parsing the long output of \ncProfile\n. In that case, you may want a profiling visualization tool, like \nSnakeViz\n. But that is outside the scope of this tutorial.\n\n\nusing \nline_profiler\n\n\nline_profiler\n offers more granular information thatn \ncProfile\n: it will give timing information about each line of code in a profiled function.\n\n\nLoad the \nline_profiler\n extension\n\n\n%load_ext line_profiler\n\n\n\n\nFor a pop-up window with results in notebook:\n\n\nIPython has an \n%lprun\n magic to profile specific functions within an executed statement. Usage:\n\n%lprun -f func_to_profile <statement>\n (get more help by running \n%lprun?\n in IPython).\n\n\nProfiling two functions\n\n\n%lprun -f bad_call -f worse_call sumulate(13)\n\n\n\n\nWrite results to a text file\n\n\n%lprun -T timings.txt -f sumulate sumulate(12)\n\n\n\n\n*** Profile printout saved to text file 'timings.txt'.\n\n\n\n%load timings.txt\n\n\n\n\nLet's break down what these results are telling us. \n\n\nLine #\n corresponds to the line in a given script or notebook cell. To toggle line numbers in a code cell, hit \nl\n in command mode.\n\n\nHits\n shows how many times a given line was encountered as a result of running the \nsumulate\n function. You can see that most lines in \nsumulate\n were hit only once, while the lines in the \nfor\n loop were hit several times. \n\n\nTime\n is the amount of time spent, in total, on a given line. Note at the top of the profiling report that the time unit here is microseconds. \n\n\nPer hit\n is the amount of time, on average, each \nhit\n on a given line took. This is the same as the \nTime\n column for lines that were only hit once, but you can see the \nPer hit\n time has more meaning in the \nfor\n loop lines.\n\n\n% Time\n is what we are really interested in. It tells us what percentage of the total run time of \nsumulate\n was spent on a given line. There are lots of ways to optimize all sorts of operations, but you should focus your time and energy on optimizing the code that is costing you the most time. \nYou \ncould\n try to further optimize Python's builtin matrix multiplication to get the \na @ a\n to operate a little bit faster.  You might even shave off a microsecond (although probably not). But who cares? That matrix multiply takes up 2% of runtime. Focus your efforts on the expensive parts, which here are \nbad_call\n and \nworse_call\n.\n\n\nProfiling on the command line\n\n\nOpen file, add \n@profile\n decorator to any function you want to profile, then run\n\n\nkernprof -l script_to_profile.py\n\n\n\n\nwhich will generate \nscript_to_profile.py.lprof\n (pickled result).  To view the results, run\n\n\npython -m line_profiler script_to_profile.py.lprof\n\n\n\n\nfrom IPython.display import IFrame\n\n\n\n\nIFrame('http://localhost:8888/terminals/1', width=800, height=700)\n\n\n\n\n    <iframe\n        width=\"800\"\n        height=\"700\"\n        src=\"http://localhost:8888/terminals/1\"\n        frameborder=\"0\"\n        allowfullscreen\n    ></iframe>\n\n\n\ntimeit\n\n\ntimeit\n is not perfect, but it is helpful.  \n\n\nPotential concerns re: \ntimeit\n\n\n\n\nReturns minimum time of run\n\n\nOnly runs benchmark 3 times\n\n\nIt disables garbage collection\n\n\n\n\npython -m timeit -v \"print(42)\"\n\n\n\n\npython -m timeit -r 25 \"print(42)\"\n\n\n\n\npython -m timeit -s \"gc.enable()\" \"print(42)\"\n\n\n\n\nLine magic\n\n\n%timeit x = 5\n\n\n\n\n100000000 loops, best of 3: 11.3 ns per loop\n\n\n\nCell magic\n\n\n%%timeit\nx = 5\ny = 6\nx + y\n\n\n\n\n10000000 loops, best of 3: 32.9 ns per loop\n\n\n\nThe \n-q\n flag quiets output.  The \n-o\n flag allows outputting results to a variable.  The \n-q\n flag sometimes disagrees with OSX so please remove it if you're having issues.\n\n\na = %timeit -qo x = 5\n\n\n\n\nprint(a.all_runs)\n\n\n\n\n[1.1260504741221666, 1.1415640730410814, 1.1300840568728745]\n\n\n\nprint(a.best)\n\n\n\n\n1.1260504741221666e-08\n\n\n\nprint(a.worst)\n\n\n\n\n4.5797787606716156e-07",
            "title": "Profiling"
        },
        {
            "location": "/numba/1/#intro-to-profiling",
            "text": "Python's dirty little secret is that it can be made to run pretty fast.    The bare-metal HPC people will be angrily tweeting at me now, or rather, they would be if they could get their wireless drivers working.  Still, there are some things you  really  don't want to do in Python.  Nested loops are usually a bad idea.  But often you won't know where your code is slowing down just by looking at it and trying to accelerate everything can be a waste of time.  (Developer time, that is, both now and in the future: you incur technical debt if you unintentionally obfuscate code to make it faster when it doesn't need to be).  The first step is always to find the bottlenecks in your code, via  profiling : analyzing your code by measuring the execution time of its parts.",
            "title": "Intro to profiling"
        },
        {
            "location": "/numba/1/#tools",
            "text": "cProfile  line_profiler  timeit   Note :\nIf you haven't already installed it, you can do  conda install line_profiler  or  pip install line_profiler",
            "title": "Tools"
        },
        {
            "location": "/numba/1/#some-bad-code",
            "text": "Here's a bit of code guaranteed to perform poorly: it sleeps for 1.5 seconds after doing any work! We will profile it and see where we might be able to help.  import numpy\nfrom time import sleep\n\ndef bad_call(dude):\n    sleep(.5)\n\ndef worse_call(dude):\n    sleep(1)\n\ndef sumulate(foo):\n    if not isinstance(foo, int):\n        return\n\n    a = numpy.random.random((1000, 1000))\n    a @ a\n\n    ans = 0\n    for i in range(foo):\n        ans += i\n\n    bad_call(ans)\n    worse_call(ans)\n\n    return ans  sumulate(150)  11175",
            "title": "Some bad code"
        },
        {
            "location": "/numba/1/#using-cprofile",
            "text": "cProfile  is the built-in profiler in Python (available since Python 2.5).  It provides a function-by-function report of execution time. First import the module, then usage is simply a call to  cProfile.run()  with your code as argument. It will print out a list of all the functions that were called, with the number of calls and the time spent in each.  import cProfile  cProfile.run('sumulate(150)')           10 function calls in 1.549 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.023    0.023    1.549    1.549 <ipython-input-1-ab37b7e7eed9>:10(sumulate)\n        1    0.000    0.000    0.501    0.501 <ipython-input-1-ab37b7e7eed9>:4(bad_call)\n        1    0.000    0.000    1.001    1.001 <ipython-input-1-ab37b7e7eed9>:7(worse_call)\n        1    0.000    0.000    1.549    1.549 <string>:1(<module>)\n        1    0.000    0.000    1.549    1.549 {built-in method builtins.exec}\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n        2    1.502    0.751    1.502    0.751 {built-in method time.sleep}\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n        1    0.024    0.024    0.024    0.024 {method 'random_sample' of 'mtrand.RandomState' objects}  You can see here that when our code  sumulate()  executes, it spends almost all its time in the method  time.sleep  (a bit over 1.5 seconds).  If your program is more complicated that this cute demo, you'll have a hard time parsing the long output of  cProfile . In that case, you may want a profiling visualization tool, like  SnakeViz . But that is outside the scope of this tutorial.",
            "title": "using cProfile"
        },
        {
            "location": "/numba/1/#using-line_profiler",
            "text": "line_profiler  offers more granular information thatn  cProfile : it will give timing information about each line of code in a profiled function.  Load the  line_profiler  extension  %load_ext line_profiler",
            "title": "using line_profiler"
        },
        {
            "location": "/numba/1/#for-a-pop-up-window-with-results-in-notebook",
            "text": "IPython has an  %lprun  magic to profile specific functions within an executed statement. Usage: %lprun -f func_to_profile <statement>  (get more help by running  %lprun?  in IPython).",
            "title": "For a pop-up window with results in notebook:"
        },
        {
            "location": "/numba/1/#profiling-two-functions",
            "text": "%lprun -f bad_call -f worse_call sumulate(13)",
            "title": "Profiling two functions"
        },
        {
            "location": "/numba/1/#write-results-to-a-text-file",
            "text": "%lprun -T timings.txt -f sumulate sumulate(12)  *** Profile printout saved to text file 'timings.txt'.  %load timings.txt  Let's break down what these results are telling us.   Line #  corresponds to the line in a given script or notebook cell. To toggle line numbers in a code cell, hit  l  in command mode.  Hits  shows how many times a given line was encountered as a result of running the  sumulate  function. You can see that most lines in  sumulate  were hit only once, while the lines in the  for  loop were hit several times.   Time  is the amount of time spent, in total, on a given line. Note at the top of the profiling report that the time unit here is microseconds.   Per hit  is the amount of time, on average, each  hit  on a given line took. This is the same as the  Time  column for lines that were only hit once, but you can see the  Per hit  time has more meaning in the  for  loop lines.  % Time  is what we are really interested in. It tells us what percentage of the total run time of  sumulate  was spent on a given line. There are lots of ways to optimize all sorts of operations, but you should focus your time and energy on optimizing the code that is costing you the most time. \nYou  could  try to further optimize Python's builtin matrix multiplication to get the  a @ a  to operate a little bit faster.  You might even shave off a microsecond (although probably not). But who cares? That matrix multiply takes up 2% of runtime. Focus your efforts on the expensive parts, which here are  bad_call  and  worse_call .",
            "title": "Write results to a text file"
        },
        {
            "location": "/numba/1/#profiling-on-the-command-line",
            "text": "Open file, add  @profile  decorator to any function you want to profile, then run  kernprof -l script_to_profile.py  which will generate  script_to_profile.py.lprof  (pickled result).  To view the results, run  python -m line_profiler script_to_profile.py.lprof  from IPython.display import IFrame  IFrame('http://localhost:8888/terminals/1', width=800, height=700)      <iframe\n        width=\"800\"\n        height=\"700\"\n        src=\"http://localhost:8888/terminals/1\"\n        frameborder=\"0\"\n        allowfullscreen\n    ></iframe>",
            "title": "Profiling on the command line"
        },
        {
            "location": "/numba/1/#timeit",
            "text": "timeit  is not perfect, but it is helpful.    Potential concerns re:  timeit   Returns minimum time of run  Only runs benchmark 3 times  It disables garbage collection   python -m timeit -v \"print(42)\"  python -m timeit -r 25 \"print(42)\"  python -m timeit -s \"gc.enable()\" \"print(42)\"",
            "title": "timeit"
        },
        {
            "location": "/numba/1/#line-magic",
            "text": "%timeit x = 5  100000000 loops, best of 3: 11.3 ns per loop",
            "title": "Line magic"
        },
        {
            "location": "/numba/1/#cell-magic",
            "text": "%%timeit\nx = 5\ny = 6\nx + y  10000000 loops, best of 3: 32.9 ns per loop  The  -q  flag quiets output.  The  -o  flag allows outputting results to a variable.  The  -q  flag sometimes disagrees with OSX so please remove it if you're having issues.  a = %timeit -qo x = 5  print(a.all_runs)  [1.1260504741221666, 1.1415640730410814, 1.1300840568728745]  print(a.best)  1.1260504741221666e-08  print(a.worst)  4.5797787606716156e-07",
            "title": "Cell magic"
        },
        {
            "location": "/numba/2/",
            "text": "Using \njit\n\n\nWe know how to find hotspots now, how do we improve their performance?\n\n\nWe \njit\n them!\n\n\nWe'll start with a trivial example but get to some more realistic applications shortly.\n\n\nArray sum\n\n\nThe function below is a naive \nsum\n function that sums all the elements of a given array.\n\n\ndef sum_array(inp):\n    J, I = inp.shape\n\n    #this is a bad idea\n    mysum = 0\n    for j in range(J):\n        for i in range(I):\n            mysum += inp[j, i]\n\n    return mysum\n\n\n\n\nimport numpy\n\n\n\n\narr = numpy.random.random((300, 300))\n\n\n\n\nFirst hand the array \narr\n off to \nsum_array\n to make sure it works (or at least doesn't error out)\n\n\nsum_array(arr)\n\n\n\n\n45102.033677230997\n\n\n\nNow run and save \ntimeit\n results of \nsum_array\n as a baseline to compare against.\n\n\nplain = %timeit -o sum_array(arr)\n\n\n\n\n100 loops, best of 3: 14.7 ms per loop\n\n\n\nLet's get started\n\n\nfrom numba import jit\n\n\n\n\nNote\n: There are two ways to \njit\n a function. These are just two ways of doing the same thing.  You can choose whichever you prefer.\n\n\nAs a function call\n\n\nsum_array_numba = jit()(sum_array)\n\n\n\n\nWhat's up with the weird double \n()\ns?  We'll cover that in a little bit.\n\n\nNow we have a new function, called \nsum_array_numba\n which is the \njit\nted version of \nsum_array\n. \nWe can again make sure that it works (and hopefully produces the same result as \nsum_array\n).\n\n\nsum_array_numba(arr)\n\n\n\n\n45102.033677231\n\n\n\nGood, that's the same result as the first version, so nothing has gone horribly wrong.  \n\n\nNow let's time and save these results.\n\n\njitted = %timeit -o sum_array_numba(arr)\n\n\n\n\n10000 loops, best of 3: 73.9 \u00b5s per loop\n\n\n\nWow. 73.7 \u00b5s is a lot faster than 15.5 ms... How much faster?  Let's see.\n\n\nplain.best / jitted.best\n\n\n\n\n198.80740381645145\n\n\n\nSo, a factor of 210x.  Not too shabby.  But we're comparing the best runs, what about the worst runs?\n\n\nplain.worst / jitted.worst\n\n\n\n\n278.7481542534447\n\n\n\nYeah, that's still an incredible speedup.\n\n\n(more commonly) As a decorator\n\n\nThe second way to \njit\n a function is to use the \njit\n decorator.  This is a very easy syntax to handle and makes applying \njit\n to a function trivial. \n\n\nNote that the only difference in terms of the outcome (compared to the other \njit\n method) is that there will be only one function, called \nsum_array\n that is a Numba \njit\nted function. The \"original\" \nsum_array\n will no longer exist, so this method, while convenient, doesn't allow you to compare results between \"vanilla\" and \njit\nted Python.\n\n\nWhen should you use one or the other? That's up to you. If I'm investigating whether Numba can help, I use \njit\n as a function call, so I can compare results. Once I've decided to use Numba, I stick with the decorator syntax since it's much prettier (and I don't care if the \"original\" function is available).\n\n\n@jit\ndef sum_array(inp):\n    I, J = inp.shape\n\n    mysum = 0\n    for i in range(I):\n        for j in range(J):\n            mysum += inp[i, j]\n\n    return mysum\n\n\n\n\nsum_array(arr)\n\n\n\n\n45102.033677231\n\n\n\nSo again, we can see that we have the same result.  That's good.  And timing?\n\n\n%timeit sum_array(arr)\n\n\n\n\n10000 loops, best of 3: 73.8 \u00b5s per loop\n\n\n\nAs expected, more or less identical to the first \njit\n example.\n\n\nHow does this compare to NumPy?\n\n\nNumPy, of course, has built in methods for summing arrays, how does Numba stack up against those?\n\n\n%timeit arr.sum()\n\n\n\n\n10000 loops, best of 3: 33.9 \u00b5s per loop\n\n\n\nRight. Remember, NumPy has been hand-tuned over many years to be very, very good at what it does. For simple operations, Numba is not going to outperform it, but when things get more complex Numba can save the day. \n\n\nAlso, take a moment to appreciate that our \njit\nted code, which was compiled on-the-fly is offering performance in the same order of magnitude as NumPy.  That's pretty incredible.\n\n\nWhen does \nnumba\n compile things?\n\n\nnumba\n is a just-in-time (hence, \njit\n) compiler.  The very first time you run a \nnumba\n compiled function, there will be a little bit of overhead for the compilation step to take place.  In practice, this is usually not noticeable. You may get a message from \ntimeit\n that one \"run\" was much slower than most; this is due to the compilation overhead. \n\n\nYour turn!",
            "title": "Intro to JIT"
        },
        {
            "location": "/numba/2/#using-jit",
            "text": "We know how to find hotspots now, how do we improve their performance?  We  jit  them!  We'll start with a trivial example but get to some more realistic applications shortly.",
            "title": "Using jit"
        },
        {
            "location": "/numba/2/#array-sum",
            "text": "The function below is a naive  sum  function that sums all the elements of a given array.  def sum_array(inp):\n    J, I = inp.shape\n\n    #this is a bad idea\n    mysum = 0\n    for j in range(J):\n        for i in range(I):\n            mysum += inp[j, i]\n\n    return mysum  import numpy  arr = numpy.random.random((300, 300))  First hand the array  arr  off to  sum_array  to make sure it works (or at least doesn't error out)  sum_array(arr)  45102.033677230997  Now run and save  timeit  results of  sum_array  as a baseline to compare against.  plain = %timeit -o sum_array(arr)  100 loops, best of 3: 14.7 ms per loop",
            "title": "Array sum"
        },
        {
            "location": "/numba/2/#lets-get-started",
            "text": "from numba import jit  Note : There are two ways to  jit  a function. These are just two ways of doing the same thing.  You can choose whichever you prefer.",
            "title": "Let's get started"
        },
        {
            "location": "/numba/2/#as-a-function-call",
            "text": "sum_array_numba = jit()(sum_array)  What's up with the weird double  () s?  We'll cover that in a little bit.  Now we have a new function, called  sum_array_numba  which is the  jit ted version of  sum_array . \nWe can again make sure that it works (and hopefully produces the same result as  sum_array ).  sum_array_numba(arr)  45102.033677231  Good, that's the same result as the first version, so nothing has gone horribly wrong.    Now let's time and save these results.  jitted = %timeit -o sum_array_numba(arr)  10000 loops, best of 3: 73.9 \u00b5s per loop  Wow. 73.7 \u00b5s is a lot faster than 15.5 ms... How much faster?  Let's see.  plain.best / jitted.best  198.80740381645145  So, a factor of 210x.  Not too shabby.  But we're comparing the best runs, what about the worst runs?  plain.worst / jitted.worst  278.7481542534447  Yeah, that's still an incredible speedup.",
            "title": "As a function call"
        },
        {
            "location": "/numba/2/#more-commonly-as-a-decorator",
            "text": "The second way to  jit  a function is to use the  jit  decorator.  This is a very easy syntax to handle and makes applying  jit  to a function trivial.   Note that the only difference in terms of the outcome (compared to the other  jit  method) is that there will be only one function, called  sum_array  that is a Numba  jit ted function. The \"original\"  sum_array  will no longer exist, so this method, while convenient, doesn't allow you to compare results between \"vanilla\" and  jit ted Python.  When should you use one or the other? That's up to you. If I'm investigating whether Numba can help, I use  jit  as a function call, so I can compare results. Once I've decided to use Numba, I stick with the decorator syntax since it's much prettier (and I don't care if the \"original\" function is available).  @jit\ndef sum_array(inp):\n    I, J = inp.shape\n\n    mysum = 0\n    for i in range(I):\n        for j in range(J):\n            mysum += inp[i, j]\n\n    return mysum  sum_array(arr)  45102.033677231  So again, we can see that we have the same result.  That's good.  And timing?  %timeit sum_array(arr)  10000 loops, best of 3: 73.8 \u00b5s per loop  As expected, more or less identical to the first  jit  example.",
            "title": "(more commonly) As a decorator"
        },
        {
            "location": "/numba/2/#how-does-this-compare-to-numpy",
            "text": "NumPy, of course, has built in methods for summing arrays, how does Numba stack up against those?  %timeit arr.sum()  10000 loops, best of 3: 33.9 \u00b5s per loop  Right. Remember, NumPy has been hand-tuned over many years to be very, very good at what it does. For simple operations, Numba is not going to outperform it, but when things get more complex Numba can save the day.   Also, take a moment to appreciate that our  jit ted code, which was compiled on-the-fly is offering performance in the same order of magnitude as NumPy.  That's pretty incredible.",
            "title": "How does this compare to NumPy?"
        },
        {
            "location": "/numba/2/#when-does-numba-compile-things",
            "text": "numba  is a just-in-time (hence,  jit ) compiler.  The very first time you run a  numba  compiled function, there will be a little bit of overhead for the compilation step to take place.  In practice, this is usually not noticeable. You may get a message from  timeit  that one \"run\" was much slower than most; this is due to the compilation overhead.",
            "title": "When does numba compile things?"
        },
        {
            "location": "/numba/2/#your-turn",
            "text": "",
            "title": "Your turn!"
        },
        {
            "location": "/numba/3/",
            "text": "Is this just magic?  What is Numba doing to make code run quickly?\n\n\nWhen you add the \njit\n decorator (or function call), Numba examines the code in the function and then tries to compile it using the LLVM compiler. LLVM takes Numba's translation of the Python code and compiles it into something like assembly code, which is a set of very low-level and very \nfast\n instructions. \n\n\nLet's create a small, simple example function to poke around in:\n\n\nfrom numba import jit\n\n\n\n\n@jit\ndef add(a, b):\n    return a + b\n\n\n\n\nadd(1, 1)\n\n\n\n\n2\n\n\n\nNow that we've run \nadd\n once, it is now \ncompiled\n and we can check out what's happened behind the scenes.  Use the \ninspect_types\n method to see how Numba translated the function.\n\n\nadd.inspect_types()\n\n\n\n\nadd (int64, int64)\n--------------------------------------------------------------------------------\n# File: <ipython-input-2-1c683d2d00ee>\n# --- LINE 1 --- \n# label 0\n#   del b\n#   del a\n#   del $0.3\n\n@jit\n\n# --- LINE 2 ---\n\ndef add(a, b):\n\n    # --- LINE 3 --- \n    #   a = arg(0, name=a)  :: int64\n    #   b = arg(1, name=b)  :: int64\n    #   $0.3 = a + b  :: int64\n    #   $0.4 = cast(value=$0.3)  :: int64\n    #   return $0.4\n\n    return a + b\n\n\n================================================================================\n\n\n\nThat is a bit more complicated than our original line -- and in fact, there's a bunch of even more complicated stuff going on behind the scenes, but we won't go into that right now. For now, just recognize that Numba is examining the code we wrote, then translating it into a more complex representation that can be efficiently compiled into a super-fast version.\n\n\nHowever...\n\n\nThis translation business is hard and Numba isn't perfect. If it encounters something that it doesn't understand, then it will still \nwork\n, but it will operate in what is called \"Object Mode\". This is fine, except \"Object Mode\" can be really, \nreally\n slow.  \n\n\nSo what can we do to avoid object mode?\n\n\nWell, first, there's a list of supported features that Numba understands that you can browse at your leisure (but do this later): http://numba.pydata.org/numba-doc/latest/reference/pysupported.html\n\n\nForcing \nnopython\n mode\n\n\nThe opposite of the slow \"object mode\" is called \nnopython\n mode.  That's a kind of confusing name, but it is what it is. The important thing to remember is that \nnopython\n mode is when Numba is \nfast\n, so that's what we want. \n\n\nBut how do we know what \"mode\" Numba is using?  \n\n\nThat's a good question. We don't always know, and we can't know ahead of time, but we do have one helper to look out for us. \n\n\nIf we specify \nnopython=True\n, then Numba will throw an exception and \nfail\n to compile when it can't make a function work in \nnopython\n mode. Then we can try to rewrite that function until it \ncan\n compile.\n\n\nHere's a quick example.  First import \nnumpy\n and the \nlinalg\n module from \nscipy\n.\n\n\nimport numpy\nfrom scipy import linalg\n\n\n\n\nDefine a random square array:\n\n\na = numpy.random.random((5, 5))\n\n\n\n\nNow write a function to pass that array to the \nlinalq\n QR decomposition method:\n\n\ndef qr_decomposition(a):\n    return linalg.decomp_qr.qr(a)\n\n\n\n\nNow let's try it out:\n\n\nqr_decomposition(a)\n\n\n\n\n(array([[-0.61251218,  0.3080602 ,  0.61705293, -0.29224924, -0.25251496],\n        [-0.51533223, -0.15379307, -0.29646637, -0.32818401,  0.71776273],\n        [-0.55845413, -0.50433313, -0.22256529,  0.49326552, -0.37540764],\n        [-0.10076405,  0.33415965, -0.67259288, -0.44155593, -0.48044886],\n        [-0.19296921,  0.71793594, -0.1715718 ,  0.60712694,  0.22201543]]),\n array([[-1.58468704, -1.26245499, -1.01284515, -1.29478127, -0.61076935],\n        [ 0.        ,  0.62312427, -0.04924057,  0.17049891,  0.09324721],\n        [ 0.        ,  0.        , -0.77693122, -0.43097318, -0.72632735],\n        [ 0.        ,  0.        ,  0.        , -0.46093787, -0.15692113],\n        [ 0.        ,  0.        ,  0.        ,  0.        , -0.05197661]]))\n\n\n\nIt works!  Ok, now let's try to \njit\n it:\n\n\nqr_jit = jit()(qr_decomposition)\n\n\n\n\nqr_jit(a)\n\n\n\n\n(array([[-0.61251218,  0.3080602 ,  0.61705293, -0.29224924, -0.25251496],\n        [-0.51533223, -0.15379307, -0.29646637, -0.32818401,  0.71776273],\n        [-0.55845413, -0.50433313, -0.22256529,  0.49326552, -0.37540764],\n        [-0.10076405,  0.33415965, -0.67259288, -0.44155593, -0.48044886],\n        [-0.19296921,  0.71793594, -0.1715718 ,  0.60712694,  0.22201543]]),\n array([[-1.58468704, -1.26245499, -1.01284515, -1.29478127, -0.61076935],\n        [ 0.        ,  0.62312427, -0.04924057,  0.17049891,  0.09324721],\n        [ 0.        ,  0.        , -0.77693122, -0.43097318, -0.72632735],\n        [ 0.        ,  0.        ,  0.        , -0.46093787, -0.15692113],\n        [ 0.        ,  0.        ,  0.        ,  0.        , -0.05197661]]))\n\n\n\nIt works! Or did it? What if try to add the \nnopython=True\n flag?  \n\n\n(Also, remember how we talked about those super weird second set of parentheses?  Here's where they come in)\n\n\nqr_jit = jit(nopython=True)(qr_decomposition)\n\n\n\n\nPrepare for a very long error message...\n\n\nqr_jit(a)\n\n\n\n\n---------------------------------------------------------------------------\n\nUntypedAttributeError                     Traceback (most recent call last)\n\n<ipython-input-12-b8e9f2ef8dc2> in <module>()\n----> 1 qr_jit(a)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws)\n    307                                 for i, err in failed_args))\n    308                 e.patch_message(msg)\n--> 309             raise e\n    310 \n    311     def inspect_llvm(self, signature=None):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws)\n    284                 argtypes.append(self.typeof_pyval(a))\n    285         try:\n--> 286             return self.compile(tuple(argtypes))\n    287         except errors.TypingError as e:\n    288             # Intercept typing error that may be due to an argument\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/dispatcher.py in compile(self, sig)\n    530 \n    531             self._cache_misses[sig] += 1\n--> 532             cres = self._compiler.compile(args, return_type)\n    533             self.add_overload(cres)\n    534             self._cache.save_overload(sig, cres)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/dispatcher.py in compile(self, args, return_type)\n     79                                       impl,\n     80                                       args=args, return_type=return_type,\n---> 81                                       flags=flags, locals=self.locals)\n     82         # Check typing error if object mode is used\n     83         if cres.typing_error is not None and not flags.enable_pyobject:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library)\n    682     pipeline = Pipeline(typingctx, targetctx, library,\n    683                         args, return_type, flags, locals)\n--> 684     return pipeline.compile_extra(func)\n    685 \n    686\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in compile_extra(self, func)\n    346         self.lifted = ()\n    347         self.lifted_from = None\n--> 348         return self._compile_bytecode()\n    349 \n    350     def compile_ir(self, func_ir, lifted=(), lifted_from=None):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in _compile_bytecode(self)\n    647         \"\"\"\n    648         assert self.func_ir is None\n--> 649         return self._compile_core()\n    650 \n    651     def _compile_ir(self):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in _compile_core(self)\n    634 \n    635         pm.finalize()\n--> 636         res = pm.run(self.status)\n    637         if res is not None:\n    638             # Early pipeline completion\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in run(self, status)\n    233                     # No more fallback pipelines?\n    234                     if is_final_pipeline:\n--> 235                         raise patched_exception\n    236                     # Go to next fallback pipeline\n    237                     else:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in run(self, status)\n    225                 try:\n    226                     event(stage_name)\n--> 227                     stage()\n    228                 except _EarlyPipelineCompletion as e:\n    229                     return e.result\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in stage_nopython_frontend(self)\n    434                 self.args,\n    435                 self.return_type,\n--> 436                 self.locals)\n    437 \n    438         with self.fallback_context('Function \"%s\" has invalid return type'\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in type_inference_stage(typingctx, interp, args, return_type, locals)\n    783 \n    784         infer.build_constraint()\n--> 785         infer.propagate()\n    786         typemap, restype, calltypes = infer.unify()\n    787\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/typeinfer.py in propagate(self, raise_errors)\n    759         if errors:\n    760             if raise_errors:\n--> 761                 raise errors[0]\n    762             else:\n    763                 return errors\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/typeinfer.py in propagate(self, typeinfer)\n    126                                                    lineno=loc.line):\n    127                 try:\n--> 128                     constraint(typeinfer)\n    129                 except TypingError as e:\n    130                     errors.append(e)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/typeinfer.py in __call__(self, typeinfer)\n    447                 attrty = typeinfer.context.resolve_getattr(ty, self.attr)\n    448                 if attrty is None:\n--> 449                     raise UntypedAttributeError(ty, self.attr, loc=self.inst.loc)\n    450                 else:\n    451                     typeinfer.add_type(self.target, attrty, loc=self.loc)\n\n\nUntypedAttributeError: Failed at nopython (nopython frontend)\nUnknown attribute 'qr' of type Module(<module 'scipy.linalg.decomp_qr' from '/home/gil/anaconda/lib/python3.5/site-packages/scipy/linalg/decomp_qr.py'>)\nFile \"<ipython-input-7-aa69e1f11031>\", line 2\n[1] During: typing of get attribute at <ipython-input-7-aa69e1f11031> (2)\n\n\n\nAck\n\n\nYes, that's a very long and intimidating looking error message, but just focus on the last few lines, specifically \"Failed at nopython\". That's Numba telling us that it has no idea what \nscipy.linalg.decomp_qr\n is, so it can't try to accelerate it. \n\n\nIt worked the first time because it was in \"object\" mode but we just asked Numba to \nforce\n \nnopython\n mode and it tried (and failed). \n\n\nnopython\n mode is so useful, that people got tired of typing it out all of the time, so there's a shortcut!\n\n\nfrom numba import njit\n\n\n\n\nnjit\n is exactly the same as \njit\n but it always forces \nnopython=True\n.  And like \njit\n, you can use it in a function call, or as a decorator.  Let's try it out on the simple \nadd\n function we started out with:\n\n\ndef add(a, b):\n    return a + b\n\n\n\n\nFunction call:\n\n\nadd_jit = njit(add)  # no extra parentheses needed with `njit`\n\n\n\n\nadd_jit(3, 4)\n\n\n\n\n7\n\n\n\nDecorator:\n\n\n@njit\ndef add(a, b):\n    return a + b\n\n\n\n\nadd(4, 6)\n\n\n\n\n10\n\n\n\nAnd that's it! \n\n\nUnless you have very specific requirements, we recommend always using \nnjit\n over \njit\n, so you can guarantee that you're taking advantage of all of Numba's speedup power.",
            "title": "Numba Internals"
        },
        {
            "location": "/numba/3/#is-this-just-magic-what-is-numba-doing-to-make-code-run-quickly",
            "text": "When you add the  jit  decorator (or function call), Numba examines the code in the function and then tries to compile it using the LLVM compiler. LLVM takes Numba's translation of the Python code and compiles it into something like assembly code, which is a set of very low-level and very  fast  instructions.   Let's create a small, simple example function to poke around in:  from numba import jit  @jit\ndef add(a, b):\n    return a + b  add(1, 1)  2  Now that we've run  add  once, it is now  compiled  and we can check out what's happened behind the scenes.  Use the  inspect_types  method to see how Numba translated the function.  add.inspect_types()  add (int64, int64)\n--------------------------------------------------------------------------------\n# File: <ipython-input-2-1c683d2d00ee>\n# --- LINE 1 --- \n# label 0\n#   del b\n#   del a\n#   del $0.3\n\n@jit\n\n# --- LINE 2 ---\n\ndef add(a, b):\n\n    # --- LINE 3 --- \n    #   a = arg(0, name=a)  :: int64\n    #   b = arg(1, name=b)  :: int64\n    #   $0.3 = a + b  :: int64\n    #   $0.4 = cast(value=$0.3)  :: int64\n    #   return $0.4\n\n    return a + b\n\n\n================================================================================  That is a bit more complicated than our original line -- and in fact, there's a bunch of even more complicated stuff going on behind the scenes, but we won't go into that right now. For now, just recognize that Numba is examining the code we wrote, then translating it into a more complex representation that can be efficiently compiled into a super-fast version.",
            "title": "Is this just magic?  What is Numba doing to make code run quickly?"
        },
        {
            "location": "/numba/3/#however",
            "text": "This translation business is hard and Numba isn't perfect. If it encounters something that it doesn't understand, then it will still  work , but it will operate in what is called \"Object Mode\". This is fine, except \"Object Mode\" can be really,  really  slow.    So what can we do to avoid object mode?  Well, first, there's a list of supported features that Numba understands that you can browse at your leisure (but do this later): http://numba.pydata.org/numba-doc/latest/reference/pysupported.html",
            "title": "However..."
        },
        {
            "location": "/numba/3/#forcing-nopython-mode",
            "text": "The opposite of the slow \"object mode\" is called  nopython  mode.  That's a kind of confusing name, but it is what it is. The important thing to remember is that  nopython  mode is when Numba is  fast , so that's what we want.   But how do we know what \"mode\" Numba is using?    That's a good question. We don't always know, and we can't know ahead of time, but we do have one helper to look out for us.   If we specify  nopython=True , then Numba will throw an exception and  fail  to compile when it can't make a function work in  nopython  mode. Then we can try to rewrite that function until it  can  compile.  Here's a quick example.  First import  numpy  and the  linalg  module from  scipy .  import numpy\nfrom scipy import linalg  Define a random square array:  a = numpy.random.random((5, 5))  Now write a function to pass that array to the  linalq  QR decomposition method:  def qr_decomposition(a):\n    return linalg.decomp_qr.qr(a)  Now let's try it out:  qr_decomposition(a)  (array([[-0.61251218,  0.3080602 ,  0.61705293, -0.29224924, -0.25251496],\n        [-0.51533223, -0.15379307, -0.29646637, -0.32818401,  0.71776273],\n        [-0.55845413, -0.50433313, -0.22256529,  0.49326552, -0.37540764],\n        [-0.10076405,  0.33415965, -0.67259288, -0.44155593, -0.48044886],\n        [-0.19296921,  0.71793594, -0.1715718 ,  0.60712694,  0.22201543]]),\n array([[-1.58468704, -1.26245499, -1.01284515, -1.29478127, -0.61076935],\n        [ 0.        ,  0.62312427, -0.04924057,  0.17049891,  0.09324721],\n        [ 0.        ,  0.        , -0.77693122, -0.43097318, -0.72632735],\n        [ 0.        ,  0.        ,  0.        , -0.46093787, -0.15692113],\n        [ 0.        ,  0.        ,  0.        ,  0.        , -0.05197661]]))  It works!  Ok, now let's try to  jit  it:  qr_jit = jit()(qr_decomposition)  qr_jit(a)  (array([[-0.61251218,  0.3080602 ,  0.61705293, -0.29224924, -0.25251496],\n        [-0.51533223, -0.15379307, -0.29646637, -0.32818401,  0.71776273],\n        [-0.55845413, -0.50433313, -0.22256529,  0.49326552, -0.37540764],\n        [-0.10076405,  0.33415965, -0.67259288, -0.44155593, -0.48044886],\n        [-0.19296921,  0.71793594, -0.1715718 ,  0.60712694,  0.22201543]]),\n array([[-1.58468704, -1.26245499, -1.01284515, -1.29478127, -0.61076935],\n        [ 0.        ,  0.62312427, -0.04924057,  0.17049891,  0.09324721],\n        [ 0.        ,  0.        , -0.77693122, -0.43097318, -0.72632735],\n        [ 0.        ,  0.        ,  0.        , -0.46093787, -0.15692113],\n        [ 0.        ,  0.        ,  0.        ,  0.        , -0.05197661]]))  It works! Or did it? What if try to add the  nopython=True  flag?    (Also, remember how we talked about those super weird second set of parentheses?  Here's where they come in)  qr_jit = jit(nopython=True)(qr_decomposition)  Prepare for a very long error message...  qr_jit(a)  ---------------------------------------------------------------------------\n\nUntypedAttributeError                     Traceback (most recent call last)\n\n<ipython-input-12-b8e9f2ef8dc2> in <module>()\n----> 1 qr_jit(a)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws)\n    307                                 for i, err in failed_args))\n    308                 e.patch_message(msg)\n--> 309             raise e\n    310 \n    311     def inspect_llvm(self, signature=None):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws)\n    284                 argtypes.append(self.typeof_pyval(a))\n    285         try:\n--> 286             return self.compile(tuple(argtypes))\n    287         except errors.TypingError as e:\n    288             # Intercept typing error that may be due to an argument\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/dispatcher.py in compile(self, sig)\n    530 \n    531             self._cache_misses[sig] += 1\n--> 532             cres = self._compiler.compile(args, return_type)\n    533             self.add_overload(cres)\n    534             self._cache.save_overload(sig, cres)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/dispatcher.py in compile(self, args, return_type)\n     79                                       impl,\n     80                                       args=args, return_type=return_type,\n---> 81                                       flags=flags, locals=self.locals)\n     82         # Check typing error if object mode is used\n     83         if cres.typing_error is not None and not flags.enable_pyobject:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library)\n    682     pipeline = Pipeline(typingctx, targetctx, library,\n    683                         args, return_type, flags, locals)\n--> 684     return pipeline.compile_extra(func)\n    685 \n    686\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in compile_extra(self, func)\n    346         self.lifted = ()\n    347         self.lifted_from = None\n--> 348         return self._compile_bytecode()\n    349 \n    350     def compile_ir(self, func_ir, lifted=(), lifted_from=None):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in _compile_bytecode(self)\n    647         \"\"\"\n    648         assert self.func_ir is None\n--> 649         return self._compile_core()\n    650 \n    651     def _compile_ir(self):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in _compile_core(self)\n    634 \n    635         pm.finalize()\n--> 636         res = pm.run(self.status)\n    637         if res is not None:\n    638             # Early pipeline completion\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in run(self, status)\n    233                     # No more fallback pipelines?\n    234                     if is_final_pipeline:\n--> 235                         raise patched_exception\n    236                     # Go to next fallback pipeline\n    237                     else:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in run(self, status)\n    225                 try:\n    226                     event(stage_name)\n--> 227                     stage()\n    228                 except _EarlyPipelineCompletion as e:\n    229                     return e.result\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in stage_nopython_frontend(self)\n    434                 self.args,\n    435                 self.return_type,\n--> 436                 self.locals)\n    437 \n    438         with self.fallback_context('Function \"%s\" has invalid return type'\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/compiler.py in type_inference_stage(typingctx, interp, args, return_type, locals)\n    783 \n    784         infer.build_constraint()\n--> 785         infer.propagate()\n    786         typemap, restype, calltypes = infer.unify()\n    787\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/typeinfer.py in propagate(self, raise_errors)\n    759         if errors:\n    760             if raise_errors:\n--> 761                 raise errors[0]\n    762             else:\n    763                 return errors\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/typeinfer.py in propagate(self, typeinfer)\n    126                                                    lineno=loc.line):\n    127                 try:\n--> 128                     constraint(typeinfer)\n    129                 except TypingError as e:\n    130                     errors.append(e)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/numba/typeinfer.py in __call__(self, typeinfer)\n    447                 attrty = typeinfer.context.resolve_getattr(ty, self.attr)\n    448                 if attrty is None:\n--> 449                     raise UntypedAttributeError(ty, self.attr, loc=self.inst.loc)\n    450                 else:\n    451                     typeinfer.add_type(self.target, attrty, loc=self.loc)\n\n\nUntypedAttributeError: Failed at nopython (nopython frontend)\nUnknown attribute 'qr' of type Module(<module 'scipy.linalg.decomp_qr' from '/home/gil/anaconda/lib/python3.5/site-packages/scipy/linalg/decomp_qr.py'>)\nFile \"<ipython-input-7-aa69e1f11031>\", line 2\n[1] During: typing of get attribute at <ipython-input-7-aa69e1f11031> (2)",
            "title": "Forcing nopython mode"
        },
        {
            "location": "/numba/3/#ack",
            "text": "Yes, that's a very long and intimidating looking error message, but just focus on the last few lines, specifically \"Failed at nopython\". That's Numba telling us that it has no idea what  scipy.linalg.decomp_qr  is, so it can't try to accelerate it.   It worked the first time because it was in \"object\" mode but we just asked Numba to  force   nopython  mode and it tried (and failed).   nopython  mode is so useful, that people got tired of typing it out all of the time, so there's a shortcut!  from numba import njit  njit  is exactly the same as  jit  but it always forces  nopython=True .  And like  jit , you can use it in a function call, or as a decorator.  Let's try it out on the simple  add  function we started out with:  def add(a, b):\n    return a + b",
            "title": "Ack"
        },
        {
            "location": "/numba/3/#function-call",
            "text": "add_jit = njit(add)  # no extra parentheses needed with `njit`  add_jit(3, 4)  7",
            "title": "Function call:"
        },
        {
            "location": "/numba/3/#decorator",
            "text": "@njit\ndef add(a, b):\n    return a + b  add(4, 6)  10  And that's it!   Unless you have very specific requirements, we recommend always using  njit  over  jit , so you can guarantee that you're taking advantage of all of Numba's speedup power.",
            "title": "Decorator:"
        },
        {
            "location": "/numba/4/",
            "text": "Application - Pressure Poisson Equation\n\n\nThe momentum equation for the velocity field $\\vec{u}$ in a fluid is\n\n\n\n\n\\begin{equation}\n\\frac{\\partial \\vec{u}}{\\partial t}+(\\vec{u}\\cdot\\nabla)\\vec{u}=-\\frac{1}{\\rho}\\nabla p + \\nu \\nabla^2\\vec{u}\n\\end{equation}\n\n\n\n\nwhere $p$ is the pressure, $\\nu$ is the fluid viscosity and $\\rho$ is the fluid density. With three velocity components, plus the pressure, we have four unknowns but only three equations. For compressible fluids, we have an equation of state to complete the system. In the incompressible case, we don't have an equation of state and we need an additional constraint from somewhere else. \n\n\nThis is what we do: take the divergence of the momentum equation, apply the incompressibility constraint to cancel some terms, and get an equation for the pressure. It's a pretty cool trick.\n\n\nConservation of mass for an incompressible fluid requires that the divergence of $\\vec{u}$ must be zero:\n\n\n\n\n\\nabla \\cdot \\vec{u} = 0\n\n\n\n\nWriting out the momentum equation in $x$ and $y$ components (for two-dimensional flow), we get\n\n\n\n\n\\frac{\\partial u}{\\partial t}+u\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y} = -\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\\nu \\left(\\frac{\\partial^2 u}{\\partial x^2}+\\frac{\\partial^2 u}{\\partial y^2} \\right) \n\n\n\n\n\n\n\\frac{\\partial v}{\\partial t}+u\\frac{\\partial v}{\\partial x}+v\\frac{\\partial v}{\\partial y} = -\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}+\\nu\\left(\\frac{\\partial^2 v}{\\partial x^2}+\\frac{\\partial^2 v}{\\partial y^2}\\right) \n\n\n\n\nWe take the divergence of the momentum equation and then apply the incompressibility constraint.  After some wrangling and cancellations, this leaves us with the pressure Poisson equation:\n\n\n\n\n\\frac{\\partial^2 p}{\\partial x^2}+\\frac{\\partial^2 p}{\\partial y^2} = -\\rho\\left(\\frac{\\partial u}{\\partial x}\\frac{\\partial u}{\\partial x}+2\\frac{\\partial u}{\\partial y}\\frac{\\partial v}{\\partial x}+\\frac{\\partial v}{\\partial y}\\frac{\\partial v}{\\partial y} \\right)\n\n\n\n\nWhich is an equation of the form\n\n\n\n\n\\frac{\\partial ^2 p}{\\partial x^2} + \\frac{\\partial ^2 p}{\\partial y^2} = b\n\n\n\n\nImagine we discretize a domain using a uniform mesh of points in each spatial direction, as in the figure below:\n\n\n\n\nThen the left-hand side of the Poisson equation, i.e., the Laplacian differential operator applied to $p$, is discretized using 2nd-order central differences as follows\n\n\n\n\n\\frac{p^n_{i+1, j} - 2p^n_{i,j} + p^n_{i - 1, j}}{\\Delta x ^2} + \\frac{p^n_{i, j+1} - 2p^n_{i,j} + p^n_{i, j-1}}{\\Delta y ^2}\n\n\n\n\nwhere subscripts $i,j$ denote the spatial location on a Cartesian coordinate system and superscripts $n$ denote a point in time.\n\n\nWe apply an appropriate finite-difference discretization to the momentum equation (forward-time, backward-space for the 1st-order terms) and also assume a uniform mesh, so $\\Delta x = \\Delta y$.\n\n\nUsing this discretized form in the Poisson equation, we will leave only the $p_{i,j}$ terms in the left-hand side, and move the other terms to the right. Then we say that we can update all the values of $p_{i,j}$ using the values at the neighboring points for both $p$ and $u, v$. This update, repeated many times, happens to converge to the solution of Poisson's equation.\n\n\nSolution procedure\n\n\nInitial velocity field\n\n\nWe start with a velocity field in $u$ and $v$ at some timestep $n$. \n\n\nCalculate pressure\n\n\nThen, we iteratively solve the Poisson equation for pressure, as described above. Starting with an initial guess, the values $p_{i,j}$ are updated using the neighboring values of $p$, $u$ and $v$ at $(i+1,j)$ and $(i,j+1)$. The updates can be written as follows, where the $k$ superscript denotes an iteration in 'pseudo-time':\n\n\n\n\n\\begin{align}\np_{i,j}^{k+1} &= \\frac{1}{4}\\left(p_{i+1,j}^{k}+p_{i-1,j}^{k}+p_{i,j+1}^{k}+p_{i,j-1}^{k}\\right) \\\\\n&-\\frac{\\rho \\Delta x}{16} \\left( \\frac{2}{\\Delta t} \\left(u_{i+1,j} - u_{i-1,j} + v_{i,j+1} - v_{i,j-1}\\right) \\right . \\\\\n&-\\frac{2}{\\Delta x}\\left(u_{i,j+1} - u_{i,j-1} \\right) \\left(v_{i+1,j} - v_{i-1,j} \\right) \\\\\n&- \\left . \\frac{\\left(u_{i+1,j} - u_{i-1,j} \\right)^2}{\\Delta x} \n- \\frac{ \\left(v_{i,j+1} - v_{i,j-1} \\right)^2 }{\\Delta x} \\right) \\\\\n\\end{align}\n\n\n\n\nIn other words, we repeatedly apply the Poisson equation until the pressure reaches a quasi-steady state.\n\n\nUpdate the velocity\n\n\nOnce the pressure field reaches its quasi-steady state via the Poisson equation, we use that field for the current time step, $p^n$, to solve for the velocity components $u$ and $v$ at the next timestep, $n+1$.\n\n\nThe momentum equation in the $u$ direction:\n\n\n\n\n\\begin{align}\nu_{i,j}^{n+1} = u_{i,j}^{n} &- \\frac{\\Delta t}{\\Delta x} \\left( u_{i,j}^{n}(u_{i,j}^{n}-u_{i-1,j}^{n})\n+ v_{i,j}^{n} (u_{i,j}^{n}-u_{i,j-1}^{n}) + \\frac{1}{2 \\rho}(p_{i+1,j}^{n}-p_{i-1,j}^{n}) \\right) \\\\\n&+\\frac{\\nu \\Delta t}{\\Delta x^2}\\left(u_{i+1,j}^{n} + u_{i-1,j}^{n} + u_{i,j+1}^{n} + u_{i,j-1}^{n} -4u_{i,j}^{n}\\right)\n\\end{align}\n\n\n\n\nThe momentum equation in the $v$ direction:\n\n\n\n\n\\begin{align}\nv_{i,j}^{n+1} = v_{i,j}^{n} &- \\frac{\\Delta t}{\\Delta x} \\left( u_{i,j}^{n}(v_{i,j}^{n}-v_{i-1,j}^{n})\n+ v_{i,j}^{n} (v_{i,j}^{n}-v_{i,j-1}^{n}) + \\frac{1}{2 \\rho}(p_{i,j+1}^{n}-p_{i,j-1}^{n}) \\right) \\\\\n&+\\frac{\\nu \\Delta t}{\\Delta x^2}\\left(v_{i+1,j}^{n} + v_{i-1,j}^{n} + v_{i,j+1}^{n} + v_{i,j-1}^{n} -4v_{i,j}^{n}\\right)\n\\end{align}\n\n\n\n\nThen, rinse and repeat.\n\n\nWhat we left out\n\n\nThere are various subtleties that we left out here, to get quickly to the equations we need in the code. First, there are some variations on the form of the pressure Poisson equation, depending on what terms involving $\\nabla\\cdot\\vec{u}$ one chooses to cancel (this has caused long arguments in the literature!). Second, we say nothing about the boundary conditions, which can cause some trouble (and more arguments!). And third, we show only the simplest iterative method for solving the Poisson equation, which also happens to be the slowest to converge. This is just meant to be a pedagogical example and discussion of these subtleties would be part of a full-fledged CFD course.",
            "title": "CFD Intro"
        },
        {
            "location": "/numba/4/#application-pressure-poisson-equation",
            "text": "The momentum equation for the velocity field $\\vec{u}$ in a fluid is   \\begin{equation}\n\\frac{\\partial \\vec{u}}{\\partial t}+(\\vec{u}\\cdot\\nabla)\\vec{u}=-\\frac{1}{\\rho}\\nabla p + \\nu \\nabla^2\\vec{u}\n\\end{equation}   where $p$ is the pressure, $\\nu$ is the fluid viscosity and $\\rho$ is the fluid density. With three velocity components, plus the pressure, we have four unknowns but only three equations. For compressible fluids, we have an equation of state to complete the system. In the incompressible case, we don't have an equation of state and we need an additional constraint from somewhere else.   This is what we do: take the divergence of the momentum equation, apply the incompressibility constraint to cancel some terms, and get an equation for the pressure. It's a pretty cool trick.  Conservation of mass for an incompressible fluid requires that the divergence of $\\vec{u}$ must be zero:   \\nabla \\cdot \\vec{u} = 0   Writing out the momentum equation in $x$ and $y$ components (for two-dimensional flow), we get   \\frac{\\partial u}{\\partial t}+u\\frac{\\partial u}{\\partial x}+v\\frac{\\partial u}{\\partial y} = -\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x}+\\nu \\left(\\frac{\\partial^2 u}{\\partial x^2}+\\frac{\\partial^2 u}{\\partial y^2} \\right)     \\frac{\\partial v}{\\partial t}+u\\frac{\\partial v}{\\partial x}+v\\frac{\\partial v}{\\partial y} = -\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y}+\\nu\\left(\\frac{\\partial^2 v}{\\partial x^2}+\\frac{\\partial^2 v}{\\partial y^2}\\right)    We take the divergence of the momentum equation and then apply the incompressibility constraint.  After some wrangling and cancellations, this leaves us with the pressure Poisson equation:   \\frac{\\partial^2 p}{\\partial x^2}+\\frac{\\partial^2 p}{\\partial y^2} = -\\rho\\left(\\frac{\\partial u}{\\partial x}\\frac{\\partial u}{\\partial x}+2\\frac{\\partial u}{\\partial y}\\frac{\\partial v}{\\partial x}+\\frac{\\partial v}{\\partial y}\\frac{\\partial v}{\\partial y} \\right)   Which is an equation of the form   \\frac{\\partial ^2 p}{\\partial x^2} + \\frac{\\partial ^2 p}{\\partial y^2} = b   Imagine we discretize a domain using a uniform mesh of points in each spatial direction, as in the figure below:   Then the left-hand side of the Poisson equation, i.e., the Laplacian differential operator applied to $p$, is discretized using 2nd-order central differences as follows   \\frac{p^n_{i+1, j} - 2p^n_{i,j} + p^n_{i - 1, j}}{\\Delta x ^2} + \\frac{p^n_{i, j+1} - 2p^n_{i,j} + p^n_{i, j-1}}{\\Delta y ^2}   where subscripts $i,j$ denote the spatial location on a Cartesian coordinate system and superscripts $n$ denote a point in time.  We apply an appropriate finite-difference discretization to the momentum equation (forward-time, backward-space for the 1st-order terms) and also assume a uniform mesh, so $\\Delta x = \\Delta y$.  Using this discretized form in the Poisson equation, we will leave only the $p_{i,j}$ terms in the left-hand side, and move the other terms to the right. Then we say that we can update all the values of $p_{i,j}$ using the values at the neighboring points for both $p$ and $u, v$. This update, repeated many times, happens to converge to the solution of Poisson's equation.",
            "title": "Application - Pressure Poisson Equation"
        },
        {
            "location": "/numba/4/#solution-procedure",
            "text": "",
            "title": "Solution procedure"
        },
        {
            "location": "/numba/4/#initial-velocity-field",
            "text": "We start with a velocity field in $u$ and $v$ at some timestep $n$.",
            "title": "Initial velocity field"
        },
        {
            "location": "/numba/4/#calculate-pressure",
            "text": "Then, we iteratively solve the Poisson equation for pressure, as described above. Starting with an initial guess, the values $p_{i,j}$ are updated using the neighboring values of $p$, $u$ and $v$ at $(i+1,j)$ and $(i,j+1)$. The updates can be written as follows, where the $k$ superscript denotes an iteration in 'pseudo-time':   \\begin{align}\np_{i,j}^{k+1} &= \\frac{1}{4}\\left(p_{i+1,j}^{k}+p_{i-1,j}^{k}+p_{i,j+1}^{k}+p_{i,j-1}^{k}\\right) \\\\\n&-\\frac{\\rho \\Delta x}{16} \\left( \\frac{2}{\\Delta t} \\left(u_{i+1,j} - u_{i-1,j} + v_{i,j+1} - v_{i,j-1}\\right) \\right . \\\\\n&-\\frac{2}{\\Delta x}\\left(u_{i,j+1} - u_{i,j-1} \\right) \\left(v_{i+1,j} - v_{i-1,j} \\right) \\\\\n&- \\left . \\frac{\\left(u_{i+1,j} - u_{i-1,j} \\right)^2}{\\Delta x} \n- \\frac{ \\left(v_{i,j+1} - v_{i,j-1} \\right)^2 }{\\Delta x} \\right) \\\\\n\\end{align}   In other words, we repeatedly apply the Poisson equation until the pressure reaches a quasi-steady state.",
            "title": "Calculate pressure"
        },
        {
            "location": "/numba/4/#update-the-velocity",
            "text": "Once the pressure field reaches its quasi-steady state via the Poisson equation, we use that field for the current time step, $p^n$, to solve for the velocity components $u$ and $v$ at the next timestep, $n+1$.  The momentum equation in the $u$ direction:   \\begin{align}\nu_{i,j}^{n+1} = u_{i,j}^{n} &- \\frac{\\Delta t}{\\Delta x} \\left( u_{i,j}^{n}(u_{i,j}^{n}-u_{i-1,j}^{n})\n+ v_{i,j}^{n} (u_{i,j}^{n}-u_{i,j-1}^{n}) + \\frac{1}{2 \\rho}(p_{i+1,j}^{n}-p_{i-1,j}^{n}) \\right) \\\\\n&+\\frac{\\nu \\Delta t}{\\Delta x^2}\\left(u_{i+1,j}^{n} + u_{i-1,j}^{n} + u_{i,j+1}^{n} + u_{i,j-1}^{n} -4u_{i,j}^{n}\\right)\n\\end{align}   The momentum equation in the $v$ direction:   \\begin{align}\nv_{i,j}^{n+1} = v_{i,j}^{n} &- \\frac{\\Delta t}{\\Delta x} \\left( u_{i,j}^{n}(v_{i,j}^{n}-v_{i-1,j}^{n})\n+ v_{i,j}^{n} (v_{i,j}^{n}-v_{i,j-1}^{n}) + \\frac{1}{2 \\rho}(p_{i,j+1}^{n}-p_{i,j-1}^{n}) \\right) \\\\\n&+\\frac{\\nu \\Delta t}{\\Delta x^2}\\left(v_{i+1,j}^{n} + v_{i-1,j}^{n} + v_{i,j+1}^{n} + v_{i,j-1}^{n} -4v_{i,j}^{n}\\right)\n\\end{align}   Then, rinse and repeat.",
            "title": "Update the velocity"
        },
        {
            "location": "/numba/4/#what-we-left-out",
            "text": "There are various subtleties that we left out here, to get quickly to the equations we need in the code. First, there are some variations on the form of the pressure Poisson equation, depending on what terms involving $\\nabla\\cdot\\vec{u}$ one chooses to cancel (this has caused long arguments in the literature!). Second, we say nothing about the boundary conditions, which can cause some trouble (and more arguments!). And third, we show only the simplest iterative method for solving the Poisson equation, which also happens to be the slowest to converge. This is just meant to be a pedagogical example and discussion of these subtleties would be part of a full-fledged CFD course.",
            "title": "What we left out"
        },
        {
            "location": "/numba/5/",
            "text": "Application: Cavity Flow\n\n\nOne of the most common validation cases in CFD is the lid-driven cavity flow.  We take a square cavity filled with a fluid and set the velocity of the lid to some constant value.  The flow within the cavity is driven by the lid, a spiral flow pattern develops and two distinctive pressure zones are visible in the upper corners against the lid.\n\n\n\n\nimport numpy\n\n\n\n\nThe Poisson equation is an elliptic PDE which almost always means using an iterative solver.  We're going to use the Jacobi method.  There are better ways, but that's beside the point.  \n\n\nHere's the pressure Poisson equation:\n\n\n\n\n\\begin{align}\np_{i,j}^{n+1} &= \\frac{1}{4}\\left(p_{i+1,j}^{n}+p_{i-1,j}^{n}+p_{i,j+1}^{n}+p_{i,j-1}^{n}\\right) \\\\\n&-\\frac{\\rho \\Delta x}{16} \\left( \\frac{2}{\\Delta t} \\left(u_{i+1,j} - u_{i-1,j} + v_{i,j+1} - v_{i,j-1}\\right) \\right . \\\\\n&-\\frac{2}{\\Delta x}\\left(u_{i,j+1} - u_{i,j-1} \\right) \\left(v_{i+1,j} - v_{i-1,j} \\right) \\\\\n&- \\left . \\frac{\\left(u_{i+1,j} - u_{i-1,j} \\right)^2}{\\Delta x} \n- \\frac{ \\left(v_{i,j+1} - v_{i,j-1} \\right)^2 }{\\Delta x} \\right) \\\\\n\\end{align}\n\n\n\n\nThat looks a little nasty, but we only care about the top line when we iterate, since the bottom three lines depend only on values that don't change when we're correcting the pressure field.  Because it doesn't change, we break it out into a separate function.\n\n\ndef velocity_term(b, rho, dt, u, v, dx):\n    b[1:-1, 1:-1] = (\n        rho * dx / 16 *\n        (2 / dt * (u[1:-1, 2:] -\n                    u[1:-1, :-2] +\n                    v[2:, 1:-1] -\n                    v[:-2, 1:-1]) -\n        2 / dx * (u[2:, 1:-1] - u[:-2, 1:-1]) *\n                 (v[1:-1, 2:] - v[1:-1, :-2]) -\n        (u[1:-1, 2:] - u[1:-1, :-2])**2 / dx -\n        (v[2:, 1:-1] - v[:-2, 1:-1])**2 / dx)\n                     )\n\n    return b\n\n\n\n\nNow, to calculate the pressure field, we pass in the original pressure field, the value \nb\n (which is the result of the \nvelocity_term\n function above) and a target value for difference between two iterates.  We repeatedly update the pressure field until the difference of the L2 norm between two successive iterations is less than that target value.\n\n\ndef pressure_poisson(p, b, l2_target):\n    iter_diff = l2_target + 1\n    n = 0\n    while iter_diff > l2_target and n <= 500:\n\n        pn = p.copy()\n        p[1:-1,1:-1] = (.25 * (pn[1:-1, 2:] +\n                               pn[1:-1, :-2] +\n                               pn[2:, 1:-1] +\n                               pn[:-2, 1:-1]) -\n                               b[1:-1, 1:-1])\n\n        p[:, 0] = p[:, 1]   #dp/dx = 0 at x = 0\n        p[:, -1] = p[:, -2] #dp/dx = 0 at x = 2\n        p[0, :] = p[1, :]   #dp/dy = 0 at y = 0\n        p[-1, :] = 0        #p = 0 at y = 2\n\n        if n % 10 == 0:\n            iter_diff = numpy.sqrt(numpy.sum((p - pn)**2)/numpy.sum(pn**2))\n\n        n += 1\n\n    return p\n\n\n\n\nIn the interests of brevity, we're only going to worry about the pressure Poisson solver.  The rest of the 2D Navier-Stokes solution is encapsulated in the function \ncavity_flow\n, which we've prepared ahead of time and saved in a helper file. If you want to dig deeper into how the \ncavity_flow\n function works, check out \"The 12 Steps to Navier-Stokes\" at \nCFD Python\n.\n\n\nFor now, though, we just need to import the function:\n\n\nfrom snippets.ns_helper import cavity_flow\n\n\n\n\nWe'll also load up \npickled\n initial conditions, so we can reliably compare final solutions.\n\n\nimport pickle\n\n\n\n\ndef run_cavity():\n    nx = 41\n    ny = 41\n    with open('IC.pickle', 'rb') as f:\n        u, v, p, b = pickle.load(f)\n\n    dx = 2 / (nx - 1)\n    dt = .005\n    nt = 1000\n\n    u, v, p = cavity_flow(u, v, p, nt, dt, dx, \n                         velocity_term, \n                         pressure_poisson, \n                         rtol=1e-4)\n\n    return u, v, p\n\n\n\n\nSo what does this all do?  Let's check it out.\n\n\nu, v, p = run_cavity()\n\n\n\n\n%matplotlib inline\nfrom snippets.ns_helper import quiver_plot\n\n\n\n\nquiver_plot(u, v, p)\n\n\n\n\n\n\nSave NumPy answers for comparison\n\n\nThis will create a binary file, saved to disk as \nnumpy_ans.pickle\n that contains the values of \nu\n, \nv\n, and \np\n. \n\n\nwith open('numpy_ans.pickle', 'wb') as f:\n    pickle.dump((u, v, p), f)\n\n\n\n\nLet's profile the \ncavity_flow\n function and see if there's a specific place that's really hurting our performance.\n\n\n%timeit run_cavity()\n\n\n\n\n1 loop, best of 3: 462 ms per loop\n\n\n\nRemember that we need to load the \nline_profiler\n extension before we can use the \nlprun\n magic.\n\n\n%load_ext line_profiler\n\n\n\n\n%lprun -f cavity_flow run_cavity()\n\n\n\n\nWhere is the bottleneck?\n\n\nClearly the PPE is the problem here, so let's use \nnumba\n to rewrite it.  \n\n\nExercise: Speed up the PPE\n\n\nfrom numba import jit\n\n\n\n\n%load snippets/ppe_numba.py\n\n\n\n\nSince we have redefined the \npressure_poisson\n function, we can run \nrun_cavity\n again and we'll be using the new and improved \njit\nted PPE. \n\n\nWe don't want to overwrite our results, so we can choose different variable names to store the final velocity and pressure fields.\n\n\nu_numba, v_numba, p_numba = run_cavity()\n\n\n\n\nWe use \nnumpy.allclose\n to check that each value of the Python and Numba fields match to within a specified tolerance (the default tolerance is 1$\\tt{E}^-$08).\n\n\nassert numpy.allclose(p, p_numba)\nassert numpy.allclose(u, u_numba)\nassert numpy.allclose(v, v_numba)\n\n\n\n\nIf there were no errors raised by the previous cell, then the two answers match.  Hooray! \nIf the answers match, we should see the same plot as above.  If they don't match, we can also check the plot to see if we're just a little bit off or completely wrong (although that can be hard to judge sometimes).\n\n\nquiver_plot(u_numba, v_numba, p_numba)\n\n\n\n\n\n\nAnd now we can check to see how much the performance has been improved:\n\n\n%timeit run_cavity()\n\n\n\n\n1 loop, best of 3: 460 ms per loop\n\n\n\nNot as spectacular as some of the other examples, but remember, we started off using NumPy arrays, not regular nested Python loops, so this is still a very respectable speedup.  \n\n\nNow if we re-profile the code, we can see how the runtime percentages have shifted around the improved PPE.  It's almost certainly going to remain the most expensive part of the solve, but it should be a smaller percentage overall.\n\n\n%lprun -f cavity_flow run_cavity()\n\n\n\n\nOne more bit of optimization?\n\n\nAs we improve the performance of the Pressure Poisson function, the profiling results will change and indicate other possible hotspots that we want to improve. It can be hard to know when to \nstop\n improving, to recognize that the gains are not worth what you are investing in rewriting code. \n\n\nIn the profile above (after rewriting the PPE) you'll notice that the \nvelocity_term\n now occupies a larger percentage of the total run time. Here's a rewritten version of \nvelocity_term\n that makes use of Numba so you can compare how much more performance we might be able to eke out of this simple cavity flow solver.\n\n\n@jit(nopython=True)\ndef velocity_term(b, rho, dt, u, v, dx):\n    J, I = b.shape\n\n    for i in range(1, I):\n        for j in range(1, J):\n            b[j, i] = (\n            rho * dx / 16 * \n            (2 / dt * (u[j, i + 1] - \n                      u[j, i - 1] + \n                      v[j + 1, i] - \n                      v[j - 1, i]) - \n            2 / dx * (u[j + 1, i] - u[j - 1, i]) * \n                     (v[j, i + 1] - v[j, i - 1]) - \n            (u[j, i + 1] - u[j, i - 1])**2 / dx - \n            (v[j + 1, i] - v[j - 1, i])**2 / dx)\n            )\n    return b\n\n\n\n\n%timeit run_cavity()\n\n\n\n\n1 loop, best of 3: 415 ms per loop",
            "title": "Cavity Flow"
        },
        {
            "location": "/numba/5/#application-cavity-flow",
            "text": "One of the most common validation cases in CFD is the lid-driven cavity flow.  We take a square cavity filled with a fluid and set the velocity of the lid to some constant value.  The flow within the cavity is driven by the lid, a spiral flow pattern develops and two distinctive pressure zones are visible in the upper corners against the lid.   import numpy  The Poisson equation is an elliptic PDE which almost always means using an iterative solver.  We're going to use the Jacobi method.  There are better ways, but that's beside the point.    Here's the pressure Poisson equation:   \\begin{align}\np_{i,j}^{n+1} &= \\frac{1}{4}\\left(p_{i+1,j}^{n}+p_{i-1,j}^{n}+p_{i,j+1}^{n}+p_{i,j-1}^{n}\\right) \\\\\n&-\\frac{\\rho \\Delta x}{16} \\left( \\frac{2}{\\Delta t} \\left(u_{i+1,j} - u_{i-1,j} + v_{i,j+1} - v_{i,j-1}\\right) \\right . \\\\\n&-\\frac{2}{\\Delta x}\\left(u_{i,j+1} - u_{i,j-1} \\right) \\left(v_{i+1,j} - v_{i-1,j} \\right) \\\\\n&- \\left . \\frac{\\left(u_{i+1,j} - u_{i-1,j} \\right)^2}{\\Delta x} \n- \\frac{ \\left(v_{i,j+1} - v_{i,j-1} \\right)^2 }{\\Delta x} \\right) \\\\\n\\end{align}   That looks a little nasty, but we only care about the top line when we iterate, since the bottom three lines depend only on values that don't change when we're correcting the pressure field.  Because it doesn't change, we break it out into a separate function.  def velocity_term(b, rho, dt, u, v, dx):\n    b[1:-1, 1:-1] = (\n        rho * dx / 16 *\n        (2 / dt * (u[1:-1, 2:] -\n                    u[1:-1, :-2] +\n                    v[2:, 1:-1] -\n                    v[:-2, 1:-1]) -\n        2 / dx * (u[2:, 1:-1] - u[:-2, 1:-1]) *\n                 (v[1:-1, 2:] - v[1:-1, :-2]) -\n        (u[1:-1, 2:] - u[1:-1, :-2])**2 / dx -\n        (v[2:, 1:-1] - v[:-2, 1:-1])**2 / dx)\n                     )\n\n    return b  Now, to calculate the pressure field, we pass in the original pressure field, the value  b  (which is the result of the  velocity_term  function above) and a target value for difference between two iterates.  We repeatedly update the pressure field until the difference of the L2 norm between two successive iterations is less than that target value.  def pressure_poisson(p, b, l2_target):\n    iter_diff = l2_target + 1\n    n = 0\n    while iter_diff > l2_target and n <= 500:\n\n        pn = p.copy()\n        p[1:-1,1:-1] = (.25 * (pn[1:-1, 2:] +\n                               pn[1:-1, :-2] +\n                               pn[2:, 1:-1] +\n                               pn[:-2, 1:-1]) -\n                               b[1:-1, 1:-1])\n\n        p[:, 0] = p[:, 1]   #dp/dx = 0 at x = 0\n        p[:, -1] = p[:, -2] #dp/dx = 0 at x = 2\n        p[0, :] = p[1, :]   #dp/dy = 0 at y = 0\n        p[-1, :] = 0        #p = 0 at y = 2\n\n        if n % 10 == 0:\n            iter_diff = numpy.sqrt(numpy.sum((p - pn)**2)/numpy.sum(pn**2))\n\n        n += 1\n\n    return p  In the interests of brevity, we're only going to worry about the pressure Poisson solver.  The rest of the 2D Navier-Stokes solution is encapsulated in the function  cavity_flow , which we've prepared ahead of time and saved in a helper file. If you want to dig deeper into how the  cavity_flow  function works, check out \"The 12 Steps to Navier-Stokes\" at  CFD Python .  For now, though, we just need to import the function:  from snippets.ns_helper import cavity_flow  We'll also load up  pickled  initial conditions, so we can reliably compare final solutions.  import pickle  def run_cavity():\n    nx = 41\n    ny = 41\n    with open('IC.pickle', 'rb') as f:\n        u, v, p, b = pickle.load(f)\n\n    dx = 2 / (nx - 1)\n    dt = .005\n    nt = 1000\n\n    u, v, p = cavity_flow(u, v, p, nt, dt, dx, \n                         velocity_term, \n                         pressure_poisson, \n                         rtol=1e-4)\n\n    return u, v, p  So what does this all do?  Let's check it out.  u, v, p = run_cavity()  %matplotlib inline\nfrom snippets.ns_helper import quiver_plot  quiver_plot(u, v, p)",
            "title": "Application: Cavity Flow"
        },
        {
            "location": "/numba/5/#save-numpy-answers-for-comparison",
            "text": "This will create a binary file, saved to disk as  numpy_ans.pickle  that contains the values of  u ,  v , and  p .   with open('numpy_ans.pickle', 'wb') as f:\n    pickle.dump((u, v, p), f)  Let's profile the  cavity_flow  function and see if there's a specific place that's really hurting our performance.  %timeit run_cavity()  1 loop, best of 3: 462 ms per loop  Remember that we need to load the  line_profiler  extension before we can use the  lprun  magic.  %load_ext line_profiler  %lprun -f cavity_flow run_cavity()",
            "title": "Save NumPy answers for comparison"
        },
        {
            "location": "/numba/5/#where-is-the-bottleneck",
            "text": "Clearly the PPE is the problem here, so let's use  numba  to rewrite it.",
            "title": "Where is the bottleneck?"
        },
        {
            "location": "/numba/5/#exercise-speed-up-the-ppe",
            "text": "from numba import jit  %load snippets/ppe_numba.py  Since we have redefined the  pressure_poisson  function, we can run  run_cavity  again and we'll be using the new and improved  jit ted PPE.   We don't want to overwrite our results, so we can choose different variable names to store the final velocity and pressure fields.  u_numba, v_numba, p_numba = run_cavity()  We use  numpy.allclose  to check that each value of the Python and Numba fields match to within a specified tolerance (the default tolerance is 1$\\tt{E}^-$08).  assert numpy.allclose(p, p_numba)\nassert numpy.allclose(u, u_numba)\nassert numpy.allclose(v, v_numba)  If there were no errors raised by the previous cell, then the two answers match.  Hooray! \nIf the answers match, we should see the same plot as above.  If they don't match, we can also check the plot to see if we're just a little bit off or completely wrong (although that can be hard to judge sometimes).  quiver_plot(u_numba, v_numba, p_numba)   And now we can check to see how much the performance has been improved:  %timeit run_cavity()  1 loop, best of 3: 460 ms per loop  Not as spectacular as some of the other examples, but remember, we started off using NumPy arrays, not regular nested Python loops, so this is still a very respectable speedup.    Now if we re-profile the code, we can see how the runtime percentages have shifted around the improved PPE.  It's almost certainly going to remain the most expensive part of the solve, but it should be a smaller percentage overall.  %lprun -f cavity_flow run_cavity()",
            "title": "Exercise: Speed up the PPE"
        },
        {
            "location": "/numba/5/#one-more-bit-of-optimization",
            "text": "As we improve the performance of the Pressure Poisson function, the profiling results will change and indicate other possible hotspots that we want to improve. It can be hard to know when to  stop  improving, to recognize that the gains are not worth what you are investing in rewriting code.   In the profile above (after rewriting the PPE) you'll notice that the  velocity_term  now occupies a larger percentage of the total run time. Here's a rewritten version of  velocity_term  that makes use of Numba so you can compare how much more performance we might be able to eke out of this simple cavity flow solver.  @jit(nopython=True)\ndef velocity_term(b, rho, dt, u, v, dx):\n    J, I = b.shape\n\n    for i in range(1, I):\n        for j in range(1, J):\n            b[j, i] = (\n            rho * dx / 16 * \n            (2 / dt * (u[j, i + 1] - \n                      u[j, i - 1] + \n                      v[j + 1, i] - \n                      v[j - 1, i]) - \n            2 / dx * (u[j + 1, i] - u[j - 1, i]) * \n                     (v[j, i + 1] - v[j, i - 1]) - \n            (u[j, i + 1] - u[j, i - 1])**2 / dx - \n            (v[j + 1, i] - v[j - 1, i])**2 / dx)\n            )\n    return b  %timeit run_cavity()  1 loop, best of 3: 415 ms per loop",
            "title": "One more bit of optimization?"
        },
        {
            "location": "/numba/6/",
            "text": "Defining \nufuncs\n using \nvectorize\n\n\nYou have been able to define your own NumPy \nufuncs\n for quite some time, but it's a little involved.  \n\n\nYou can read through the \ndocumentation\n, the example they post there is a ufunc to perform \n\n\n\n\nf(a) = \\log \\left(\\frac{a}{1-a}\\right)\n\n\n\n\nIt looks like this:\n\n\nstatic void double_logit(char **args, npy_intp *dimensions,\n                            npy_intp* steps, void* data)\n{\n    npy_intp i;\n    npy_intp n = dimensions[0];\n    char *in = args[0], *out = args[1];\n    npy_intp in_step = steps[0], out_step = steps[1];\n\n    double tmp;\n\n    for (i = 0; i < n; i++) {\n        /*BEGIN main ufunc computation*/\n        tmp = *(double *)in;\n        tmp /= 1-tmp;\n        *((double *)out) = log(tmp);\n        /*END main ufunc computation*/\n\n        in += in_step;\n        out += out_step;\n    }\n}\n\n\n\n\nAnd \nnote\n, that's just for a \ndouble\n.  If you want \nfloats\n, \nlong doubles\n, etc... you have to write all of those, too.  And then create a \nsetup.py\n file to install it.  And I left out a bunch of boilerplate stuff to set up the import hooks, etc...\n\n\nSay \"thank you\" to the NumPy devs\n\n\nWe can use Numba to define ufuncs without all of the pain.\n\n\nimport numpy\nimport math\n\n\n\n\nLet's define a function that operates on two inputs\n\n\ndef trig(a, b):\n    return math.sin(a**2) * math.exp(b)\n\n\n\n\ntrig(1, 1)\n\n\n\n\n2.2873552871788423\n\n\n\nSeems reasonable.  However, the \nmath\n library only works on scalars.  If we try to pass in arrays, we'll get an error.\n\n\na = numpy.ones((5,5))\nb = numpy.ones((5,5))\n\n\n\n\ntrig(a, b)\n\n\n\n\n---------------------------------------------------------------------------\n\nTypeError                                 Traceback (most recent call last)\n\n<ipython-input-5-6bc62cd8d328> in <module>()\n----> 1 trig(a, b)\n\n\n<ipython-input-2-27083e35e9e9> in trig(a, b)\n      1 def trig(a, b):\n----> 2     return math.sin(a**2) * math.exp(b)\n\n\nTypeError: only length-1 arrays can be converted to Python scalars\n\n\n\nfrom numba import vectorize\n\n\n\n\nvec_trig = vectorize()(trig)\n\n\n\n\nvec_trig(a, b)\n\n\n\n\narray([[ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529],\n       [ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529],\n       [ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529],\n       [ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529],\n       [ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529]])\n\n\n\nAnd just like that, the scalar function \ntrig\n is now a NumPy \nufunc\n called \nvec_trig\n\n\nNote that this is a \"Dynamic UFunc\" with no signature given.  \n\n\nHow does it compare to just using NumPy?  Let's check\n\n\ndef numpy_trig(a, b):\n    return numpy.sin(a**2) * numpy.exp(b)\n\n\n\n\na = numpy.random.random((1000, 1000))\nb = numpy.random.random((1000, 1000))\n\n\n\n\n%timeit vec_trig(a, b)\n\n\n\n\n10 loops, best of 3: 29.4 ms per loop\n\n\n\n%timeit numpy_trig(a, b)\n\n\n\n\n10 loops, best of 3: 32.5 ms per loop\n\n\n\nWhat happens if we do specify a signature?  Is there a speed boost?\n\n\nvec_trig = vectorize('float64(float64, float64)')(trig)\n\n\n\n\n%timeit vec_trig(a, b)\n\n\n\n\n10 loops, best of 3: 29.5 ms per loop\n\n\n\nNo, not really.  But(!), if we have a signature, then we can add the target \nkwarg\n.\n\n\nvec_trig = vectorize('float64(float64, float64)', target='parallel')(trig)\n\n\n\n\n%timeit vec_trig(a, b)\n\n\n\n\n100 loops, best of 3: 6.24 ms per loop\n\n\n\nAutomatic multicore operations!\n\n\nNote\n: \ntarget='parallel'\n is not always the best option.  There is overhead in setting up the threading, so if the individual scalar operations that make up a \nufunc\n are simple you'll probably get better performance in serial.  If the individual operations are more expensive (like trig!) then parallel is (usually) a good option.\n\n\nPassing multiple signatures\n\n\nIf you use multiple signatures, they have to be listed in order of most specific -> least specific\n\n\n@vectorize(['int32(int32, int32)',\n            'int64(int64, int64)',\n            'float32(float32, float32)',\n            'float64(float64, float64)'])\ndef trig(a, b):\n    return math.sin(a**2) * math.exp(b)\n\n\n\n\ntrig(1, 1)\n\n\n\n\n2\n\n\n\ntrig(1., 1.)\n\n\n\n\n2.2873552871788423\n\n\n\ntrig.ntypes\n\n\n\n\n4\n\n\n\nExercise: Clipping an array\n\n\nYes, NumPy has a \nclip\n ufunc already, but let's pretend it doesn't.  \n\n\nCreate a Numba vectorized ufunc that takes a vector \na\n, a lower limit \namin\n and an upper limit \namax\n.  It should return the vector \na\n with all values clipped such that $a_{min} < a < a_{max}$:\n\n\n# %load snippets/clip.py\n\n\n\n\na = numpy.random.random((5000))\n\n\n\n\namin = .2\namax = .6\n\n\n\n\n%timeit vec_truncate_serial(a, amin, amax)\n\n\n\n\n---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-24-1221b70b3424> in <module>()\n----> 1 get_ipython().magic('timeit vec_truncate_serial(a, amin, amax)')\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in magic(self, arg_s)\n   2156         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2157         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2158         return self.run_line_magic(magic_name, magic_arg_s)\n   2159 \n   2160     #-------------------------------------------------------------------------\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_line_magic(self, magic_name, line)\n   2077                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2078             with self.builtin_trap:\n-> 2079                 result = fn(*args,**kwargs)\n   2080             return result\n   2081\n\n\n<decorator-gen-58> in timeit(self, line, cell)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k)\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n    189 \n    190         if callable(arg):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, line, cell)\n   1042             number = 1\n   1043             for _ in range(1, 10):\n-> 1044                 time_number = timer.timeit(number)\n   1045                 worst_tuning = max(worst_tuning, time_number / number)\n   1046                 if time_number >= 0.2:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, number)\n    137         gc.disable()\n    138         try:\n--> 139             timing = self.inner(it, self.timer)\n    140         finally:\n    141             if gcold:\n\n\n<magic-timeit> in inner(_it, _timer)\n\n\nNameError: name 'vec_truncate_serial' is not defined\n\n\n\n%timeit vec_truncate_par(a, amin, amax)\n\n\n\n\n---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-25-a1fc14977f98> in <module>()\n----> 1 get_ipython().magic('timeit vec_truncate_par(a, amin, amax)')\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in magic(self, arg_s)\n   2156         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2157         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2158         return self.run_line_magic(magic_name, magic_arg_s)\n   2159 \n   2160     #-------------------------------------------------------------------------\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_line_magic(self, magic_name, line)\n   2077                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2078             with self.builtin_trap:\n-> 2079                 result = fn(*args,**kwargs)\n   2080             return result\n   2081\n\n\n<decorator-gen-58> in timeit(self, line, cell)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k)\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n    189 \n    190         if callable(arg):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, line, cell)\n   1042             number = 1\n   1043             for _ in range(1, 10):\n-> 1044                 time_number = timer.timeit(number)\n   1045                 worst_tuning = max(worst_tuning, time_number / number)\n   1046                 if time_number >= 0.2:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, number)\n    137         gc.disable()\n    138         try:\n--> 139             timing = self.inner(it, self.timer)\n    140         finally:\n    141             if gcold:\n\n\n<magic-timeit> in inner(_it, _timer)\n\n\nNameError: name 'vec_truncate_par' is not defined\n\n\n\n%timeit numpy.clip(a, amin, amax)\n\n\n\n\n100000 loops, best of 3: 4.78 \u00b5s per loop\n\n\n\na = numpy.random.random((100000))\n\n\n\n\n%timeit vec_truncate_serial(a, amin, amax)\n\n\n\n\n---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-28-1221b70b3424> in <module>()\n----> 1 get_ipython().magic('timeit vec_truncate_serial(a, amin, amax)')\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in magic(self, arg_s)\n   2156         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2157         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2158         return self.run_line_magic(magic_name, magic_arg_s)\n   2159 \n   2160     #-------------------------------------------------------------------------\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_line_magic(self, magic_name, line)\n   2077                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2078             with self.builtin_trap:\n-> 2079                 result = fn(*args,**kwargs)\n   2080             return result\n   2081\n\n\n<decorator-gen-58> in timeit(self, line, cell)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k)\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n    189 \n    190         if callable(arg):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, line, cell)\n   1042             number = 1\n   1043             for _ in range(1, 10):\n-> 1044                 time_number = timer.timeit(number)\n   1045                 worst_tuning = max(worst_tuning, time_number / number)\n   1046                 if time_number >= 0.2:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, number)\n    137         gc.disable()\n    138         try:\n--> 139             timing = self.inner(it, self.timer)\n    140         finally:\n    141             if gcold:\n\n\n<magic-timeit> in inner(_it, _timer)\n\n\nNameError: name 'vec_truncate_serial' is not defined\n\n\n\n%timeit vec_truncate_par(a, amin, amax)\n\n\n\n\n---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-29-a1fc14977f98> in <module>()\n----> 1 get_ipython().magic('timeit vec_truncate_par(a, amin, amax)')\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in magic(self, arg_s)\n   2156         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2157         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2158         return self.run_line_magic(magic_name, magic_arg_s)\n   2159 \n   2160     #-------------------------------------------------------------------------\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_line_magic(self, magic_name, line)\n   2077                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2078             with self.builtin_trap:\n-> 2079                 result = fn(*args,**kwargs)\n   2080             return result\n   2081\n\n\n<decorator-gen-58> in timeit(self, line, cell)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k)\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n    189 \n    190         if callable(arg):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, line, cell)\n   1042             number = 1\n   1043             for _ in range(1, 10):\n-> 1044                 time_number = timer.timeit(number)\n   1045                 worst_tuning = max(worst_tuning, time_number / number)\n   1046                 if time_number >= 0.2:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, number)\n    137         gc.disable()\n    138         try:\n--> 139             timing = self.inner(it, self.timer)\n    140         finally:\n    141             if gcold:\n\n\n<magic-timeit> in inner(_it, _timer)\n\n\nNameError: name 'vec_truncate_par' is not defined\n\n\n\n%timeit numpy.clip(a, amin, amax)\n\n\n\n\n1000 loops, best of 3: 212 \u00b5s per loop\n\n\n\nExercise: Create \nlogit\n ufunc\n\n\nRecall from above that this is a ufunc which performs this operation:\n\n\n\n\nf(a) = \\log \\left(\\frac{a}{1-a}\\right)\n\n\n\n\n# %load snippets/logit.py\n\n\n\n\nlogit(a)\n\n\n\n\n---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-32-43208ff16126> in <module>()\n----> 1 logit(a)\n\n\nNameError: name 'logit' is not defined\n\n\n\nPerformance of \nvectorize\n vs. regular array-wide operations\n\n\n@vectorize\ndef discriminant(a, b, c):\n    return b**2 - 4 * a * c\n\n\n\n\na = numpy.arange(10000)\nb = numpy.arange(10000)\nc = numpy.arange(10000)\n\n\n\n\n%timeit discriminant(a, b, c)\n\n\n\n\nThe slowest run took 3182.90 times longer than the fastest. This could mean that an intermediate result is being cached.\n100000 loops, best of 3: 11.7 \u00b5s per loop\n\n\n\n%timeit b**2 - 4 * a * c\n\n\n\n\nThe slowest run took 5.46 times longer than the fastest. This could mean that an intermediate result is being cached.\n10000 loops, best of 3: 39.4 \u00b5s per loop\n\n\n\nWhat's going on?\n\n\n\n\nEach array operation creates a temporary copy\n\n\nEach of these arrays are loaded into and out of cache a whole bunch\n\n\n\n\ndel a, b, c",
            "title": "vectorize"
        },
        {
            "location": "/numba/6/#defining-ufuncs-using-vectorize",
            "text": "You have been able to define your own NumPy  ufuncs  for quite some time, but it's a little involved.    You can read through the  documentation , the example they post there is a ufunc to perform    f(a) = \\log \\left(\\frac{a}{1-a}\\right)   It looks like this:  static void double_logit(char **args, npy_intp *dimensions,\n                            npy_intp* steps, void* data)\n{\n    npy_intp i;\n    npy_intp n = dimensions[0];\n    char *in = args[0], *out = args[1];\n    npy_intp in_step = steps[0], out_step = steps[1];\n\n    double tmp;\n\n    for (i = 0; i < n; i++) {\n        /*BEGIN main ufunc computation*/\n        tmp = *(double *)in;\n        tmp /= 1-tmp;\n        *((double *)out) = log(tmp);\n        /*END main ufunc computation*/\n\n        in += in_step;\n        out += out_step;\n    }\n}  And  note , that's just for a  double .  If you want  floats ,  long doubles , etc... you have to write all of those, too.  And then create a  setup.py  file to install it.  And I left out a bunch of boilerplate stuff to set up the import hooks, etc...",
            "title": "Defining ufuncs using vectorize"
        },
        {
            "location": "/numba/6/#say-thank-you-to-the-numpy-devs",
            "text": "We can use Numba to define ufuncs without all of the pain.  import numpy\nimport math  Let's define a function that operates on two inputs  def trig(a, b):\n    return math.sin(a**2) * math.exp(b)  trig(1, 1)  2.2873552871788423  Seems reasonable.  However, the  math  library only works on scalars.  If we try to pass in arrays, we'll get an error.  a = numpy.ones((5,5))\nb = numpy.ones((5,5))  trig(a, b)  ---------------------------------------------------------------------------\n\nTypeError                                 Traceback (most recent call last)\n\n<ipython-input-5-6bc62cd8d328> in <module>()\n----> 1 trig(a, b)\n\n\n<ipython-input-2-27083e35e9e9> in trig(a, b)\n      1 def trig(a, b):\n----> 2     return math.sin(a**2) * math.exp(b)\n\n\nTypeError: only length-1 arrays can be converted to Python scalars  from numba import vectorize  vec_trig = vectorize()(trig)  vec_trig(a, b)  array([[ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529],\n       [ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529],\n       [ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529],\n       [ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529],\n       [ 2.28735529,  2.28735529,  2.28735529,  2.28735529,  2.28735529]])  And just like that, the scalar function  trig  is now a NumPy  ufunc  called  vec_trig  Note that this is a \"Dynamic UFunc\" with no signature given.    How does it compare to just using NumPy?  Let's check  def numpy_trig(a, b):\n    return numpy.sin(a**2) * numpy.exp(b)  a = numpy.random.random((1000, 1000))\nb = numpy.random.random((1000, 1000))  %timeit vec_trig(a, b)  10 loops, best of 3: 29.4 ms per loop  %timeit numpy_trig(a, b)  10 loops, best of 3: 32.5 ms per loop  What happens if we do specify a signature?  Is there a speed boost?  vec_trig = vectorize('float64(float64, float64)')(trig)  %timeit vec_trig(a, b)  10 loops, best of 3: 29.5 ms per loop  No, not really.  But(!), if we have a signature, then we can add the target  kwarg .  vec_trig = vectorize('float64(float64, float64)', target='parallel')(trig)  %timeit vec_trig(a, b)  100 loops, best of 3: 6.24 ms per loop  Automatic multicore operations!  Note :  target='parallel'  is not always the best option.  There is overhead in setting up the threading, so if the individual scalar operations that make up a  ufunc  are simple you'll probably get better performance in serial.  If the individual operations are more expensive (like trig!) then parallel is (usually) a good option.",
            "title": "Say \"thank you\" to the NumPy devs"
        },
        {
            "location": "/numba/6/#passing-multiple-signatures",
            "text": "If you use multiple signatures, they have to be listed in order of most specific -> least specific  @vectorize(['int32(int32, int32)',\n            'int64(int64, int64)',\n            'float32(float32, float32)',\n            'float64(float64, float64)'])\ndef trig(a, b):\n    return math.sin(a**2) * math.exp(b)  trig(1, 1)  2  trig(1., 1.)  2.2873552871788423  trig.ntypes  4",
            "title": "Passing multiple signatures"
        },
        {
            "location": "/numba/6/#exercise-clipping-an-array",
            "text": "Yes, NumPy has a  clip  ufunc already, but let's pretend it doesn't.    Create a Numba vectorized ufunc that takes a vector  a , a lower limit  amin  and an upper limit  amax .  It should return the vector  a  with all values clipped such that $a_{min} < a < a_{max}$:  # %load snippets/clip.py  a = numpy.random.random((5000))  amin = .2\namax = .6  %timeit vec_truncate_serial(a, amin, amax)  ---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-24-1221b70b3424> in <module>()\n----> 1 get_ipython().magic('timeit vec_truncate_serial(a, amin, amax)')\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in magic(self, arg_s)\n   2156         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2157         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2158         return self.run_line_magic(magic_name, magic_arg_s)\n   2159 \n   2160     #-------------------------------------------------------------------------\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_line_magic(self, magic_name, line)\n   2077                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2078             with self.builtin_trap:\n-> 2079                 result = fn(*args,**kwargs)\n   2080             return result\n   2081\n\n\n<decorator-gen-58> in timeit(self, line, cell)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k)\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n    189 \n    190         if callable(arg):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, line, cell)\n   1042             number = 1\n   1043             for _ in range(1, 10):\n-> 1044                 time_number = timer.timeit(number)\n   1045                 worst_tuning = max(worst_tuning, time_number / number)\n   1046                 if time_number >= 0.2:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, number)\n    137         gc.disable()\n    138         try:\n--> 139             timing = self.inner(it, self.timer)\n    140         finally:\n    141             if gcold:\n\n\n<magic-timeit> in inner(_it, _timer)\n\n\nNameError: name 'vec_truncate_serial' is not defined  %timeit vec_truncate_par(a, amin, amax)  ---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-25-a1fc14977f98> in <module>()\n----> 1 get_ipython().magic('timeit vec_truncate_par(a, amin, amax)')\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in magic(self, arg_s)\n   2156         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2157         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2158         return self.run_line_magic(magic_name, magic_arg_s)\n   2159 \n   2160     #-------------------------------------------------------------------------\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_line_magic(self, magic_name, line)\n   2077                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2078             with self.builtin_trap:\n-> 2079                 result = fn(*args,**kwargs)\n   2080             return result\n   2081\n\n\n<decorator-gen-58> in timeit(self, line, cell)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k)\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n    189 \n    190         if callable(arg):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, line, cell)\n   1042             number = 1\n   1043             for _ in range(1, 10):\n-> 1044                 time_number = timer.timeit(number)\n   1045                 worst_tuning = max(worst_tuning, time_number / number)\n   1046                 if time_number >= 0.2:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, number)\n    137         gc.disable()\n    138         try:\n--> 139             timing = self.inner(it, self.timer)\n    140         finally:\n    141             if gcold:\n\n\n<magic-timeit> in inner(_it, _timer)\n\n\nNameError: name 'vec_truncate_par' is not defined  %timeit numpy.clip(a, amin, amax)  100000 loops, best of 3: 4.78 \u00b5s per loop  a = numpy.random.random((100000))  %timeit vec_truncate_serial(a, amin, amax)  ---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-28-1221b70b3424> in <module>()\n----> 1 get_ipython().magic('timeit vec_truncate_serial(a, amin, amax)')\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in magic(self, arg_s)\n   2156         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2157         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2158         return self.run_line_magic(magic_name, magic_arg_s)\n   2159 \n   2160     #-------------------------------------------------------------------------\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_line_magic(self, magic_name, line)\n   2077                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2078             with self.builtin_trap:\n-> 2079                 result = fn(*args,**kwargs)\n   2080             return result\n   2081\n\n\n<decorator-gen-58> in timeit(self, line, cell)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k)\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n    189 \n    190         if callable(arg):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, line, cell)\n   1042             number = 1\n   1043             for _ in range(1, 10):\n-> 1044                 time_number = timer.timeit(number)\n   1045                 worst_tuning = max(worst_tuning, time_number / number)\n   1046                 if time_number >= 0.2:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, number)\n    137         gc.disable()\n    138         try:\n--> 139             timing = self.inner(it, self.timer)\n    140         finally:\n    141             if gcold:\n\n\n<magic-timeit> in inner(_it, _timer)\n\n\nNameError: name 'vec_truncate_serial' is not defined  %timeit vec_truncate_par(a, amin, amax)  ---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-29-a1fc14977f98> in <module>()\n----> 1 get_ipython().magic('timeit vec_truncate_par(a, amin, amax)')\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in magic(self, arg_s)\n   2156         magic_name, _, magic_arg_s = arg_s.partition(' ')\n   2157         magic_name = magic_name.lstrip(prefilter.ESC_MAGIC)\n-> 2158         return self.run_line_magic(magic_name, magic_arg_s)\n   2159 \n   2160     #-------------------------------------------------------------------------\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_line_magic(self, magic_name, line)\n   2077                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2078             with self.builtin_trap:\n-> 2079                 result = fn(*args,**kwargs)\n   2080             return result\n   2081\n\n\n<decorator-gen-58> in timeit(self, line, cell)\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k)\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n    189 \n    190         if callable(arg):\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, line, cell)\n   1042             number = 1\n   1043             for _ in range(1, 10):\n-> 1044                 time_number = timer.timeit(number)\n   1045                 worst_tuning = max(worst_tuning, time_number / number)\n   1046                 if time_number >= 0.2:\n\n\n/home/gil/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py in timeit(self, number)\n    137         gc.disable()\n    138         try:\n--> 139             timing = self.inner(it, self.timer)\n    140         finally:\n    141             if gcold:\n\n\n<magic-timeit> in inner(_it, _timer)\n\n\nNameError: name 'vec_truncate_par' is not defined  %timeit numpy.clip(a, amin, amax)  1000 loops, best of 3: 212 \u00b5s per loop",
            "title": "Exercise: Clipping an array"
        },
        {
            "location": "/numba/6/#exercise-create-logit-ufunc",
            "text": "Recall from above that this is a ufunc which performs this operation:   f(a) = \\log \\left(\\frac{a}{1-a}\\right)   # %load snippets/logit.py  logit(a)  ---------------------------------------------------------------------------\n\nNameError                                 Traceback (most recent call last)\n\n<ipython-input-32-43208ff16126> in <module>()\n----> 1 logit(a)\n\n\nNameError: name 'logit' is not defined",
            "title": "Exercise: Create logit ufunc"
        },
        {
            "location": "/numba/6/#performance-of-vectorize-vs-regular-array-wide-operations",
            "text": "@vectorize\ndef discriminant(a, b, c):\n    return b**2 - 4 * a * c  a = numpy.arange(10000)\nb = numpy.arange(10000)\nc = numpy.arange(10000)  %timeit discriminant(a, b, c)  The slowest run took 3182.90 times longer than the fastest. This could mean that an intermediate result is being cached.\n100000 loops, best of 3: 11.7 \u00b5s per loop  %timeit b**2 - 4 * a * c  The slowest run took 5.46 times longer than the fastest. This could mean that an intermediate result is being cached.\n10000 loops, best of 3: 39.4 \u00b5s per loop  What's going on?   Each array operation creates a temporary copy  Each of these arrays are loaded into and out of cache a whole bunch   del a, b, c",
            "title": "Performance of vectorize vs. regular array-wide operations"
        }
    ]
}